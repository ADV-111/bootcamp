{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Najważniejszą rzeczą do zrozumienia jest to, że ten kod w rzeczywistości nie wykonuje żadnych obliczeń, nawet jeśli wygląda na to (szczególnie na ostatniej linii). Po prostu tworzy graf obliczeniowy. \n",
    "\n",
    "W rzeczywistości nawet zmienne nie zostały jeszcze zainicjowane. Aby wykonać ten graf, należy otworzyć sesję TensorFlow i użyć jej do zainicjowania zmiennych i wyliczenia $f$. \n",
    "\n",
    "Sesja TensorFlow zajmuje się umieszczaniem operacji na urządzeniach takich jak procesory i GPU oraz ich uruchomieniem i przechowuje wszystkie wartości zmiennych:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciągłe powtarzanie sesji **sess.run()** jest nieco uciążliwe, ale na szczęście jest lepszy sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamiast ręcznie uruchamiać inicjalizator dla każdej zmiennej, można użyć skrótu\n",
    "Funkcja **global_variables_initializer()**. Zauważ, że nie wykonuje on natychmiastowej nitlizacji, lecz tworzy na wykresie węzeł, który inicjalizuje wszystkie zmienne podczas działania:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # prepare an init node\n",
    "with tf.Session() as sess:\n",
    "    init.run() # actually initialize all the variables\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program TensorFlow dzieli się zazwyczaj na dwie części: pierwsza część tworzy graf obliczeniowy (nazywa się to fazą konstrukcyjną), a druga część uruchamia go (jest to faza wykonania)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tworzeniw grfów\n",
    "Każdy utworzony węzeł jest automatycznie dodawany do domyślnego grafu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W większości przypadków jest to w porządku, ale czasami możesz chcieć zarządzać wieloma niezależnymi grafami. Możesz to zrobić, tworząc nowy graf i tymczasowo ustawiając go jako domyślny wykres wewnątrz bloku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "\n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W Jupyter (lub w powłoce Pythona) często używa się tych samych poleceń więcej niż raz podczas eksperymentowania. W rezultacie może pojawić się domyślny wykres zawierający wiele zduplikowanych węzłów. Jednym z rozwiązań jest ponowne uruchomienie jądra Jupytera (lub powłoki Pythona), ale wygodniejszym rozwiązaniem jest przywrócenie domyślnego wykresu poprzez uruchomienie **tf.reset_default_graph()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podczas inicjalizacji węzła TensorFlow automatycznie określa zestaw węzłów, od których zależy i najpierw inicjalizuje te węzły. Rozważmy na przykład następujący kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) \n",
    "    print(z.eval()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weźmy dane housing oraz wykonajmy regresję liniową za pomocą rozwiązania układu równań liniowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20640 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "print(m, n)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "housing_data_scaled=scaler.fit_transform(housing.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą NumPy wyglądało by to tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 9)\n"
     ]
    }
   ],
   "source": [
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing_data_scaled]\n",
    "print(housing_data_plus_bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "X = housing_data_plus_bias\n",
    "y = housing.target.reshape(-1, 1)\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "\n",
    "print(theta_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Za pomocą Scikit-Learn można to zrobić tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06855817]\n",
      " [ 0.8296193 ]\n",
      " [ 0.11875165]\n",
      " [-0.26552688]\n",
      " [ 0.30569623]\n",
      " [-0.004503  ]\n",
      " [-0.03932627]\n",
      " [-0.89988565]\n",
      " [-0.870541  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_data_scaled, housing.target.reshape(-1, 1))\n",
    "\n",
    "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tensorflow możemy to zrobić tak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.06856298]\n",
      " [ 0.82961965]\n",
      " [ 0.11875178]\n",
      " [-0.26552707]\n",
      " [ 0.30569667]\n",
      " [-0.00450281]\n",
      " [-0.03932635]\n",
      " [-0.8998825 ]\n",
      " [-0.87053877]]\n"
     ]
    }
   ],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Wykonaj regresje na poniższych danych oraz narysuj wykres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212d7e945c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "data = np.loadtxt(\"life_satisfaction.csv\",\n",
    "                  dtype=np.float32,\n",
    "                  delimiter=\",\",\n",
    "                  skiprows=1,\n",
    "                  usecols=[1, 2])\n",
    "X_train = data[:, 0:1] / 10000 # feature scaling\n",
    "y_train = data[:, 1:2]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 2)\n",
      "[[ 4.85305166]\n",
      " [ 0.49115562]]\n"
     ]
    }
   ],
   "source": [
    "data_plus_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "print(data_plus_bias.shape)\n",
    "\n",
    "X = tf.constant(data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(y_train.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4lOW5x/HvnZAACZvsawgIgiwBNYIsVq11wX3BUz1p\nrUsPauty2opIaa3LwbVHa2urplZb29hWA7giVi0telxBIWFfw74jYQlLkrnPHxMUYiALk3lnJr/P\ndeWamXfevHPPDPx4eN57njF3R0REEktS0AWIiEjkKdxFRBKQwl1EJAEp3EVEEpDCXUQkASncRUQS\nkMJdRCQBKdxFRBKQwl1EJAE1CuqB27Zt65mZmUE9vIhIXJo1a9YWd29X3X6BhXtmZiYzZ84M6uFF\nROKSma2syX6alhERSUAKdxGRBKRwFxFJQAp3EZEEpHAXEUlA1Ya7mfUxs9kH/ewws/+utM/pZlZ8\n0D531V/JIiKRk5cHmZmQlBS+zMur2X2xrtpWSHdfBAwGMLNkYC0wpYpd33P3CyJbnohI/cnLgzFj\noKQkfHvlyvDtAw53X05OdOusi9r2uZ8JLHP3GvVZiojEsgkTvgrvA0pKwtsPXK/qvngI99rOuV8J\n/PUw9w03swIze9PM+le1g5mNMbOZZjZz8+bNtXxoEZHIWrXq8NuPdF88qHG4m1kqcBHwUhV3fwZk\nuHsW8Bvg5aqO4e657p7t7tnt2lX76VkRkXqVkXH47Ue6Lx7UZuQ+CvjM3TdWvsPdd7j7rorrU4EU\nM2sboRpFROrFxImQlnbotrS08PYj3RcPajPnfhWHmZIxs47ARnd3MxtC+B+NrRGoT0Sk3hyYO58w\nITzdkpERDu+D59SPdF8sM3evfiezdGAV0NPdiyu23Qjg7k+Z2c3ATUAZsAf4sbt/cKRjZmdnuxYO\nExGpHTOb5e7Z1e1Xo2kZd9/t7m0OBHvFtqfc/amK60+4e393H+Tup1QX7CJSN7HWdx1r9chXAlvy\nV0Rq50g92UFMFcRaPXKoGk3L1AdNy4jUTmZmOEAr694dioqiXU3s1dNQRHRaRkSCF2t917FWjxxK\n4S4SJ2Kt7zrW6pFDKdxF4kSs9V3HWj1yKIW7SJzIyYHc3PCctln4Mjc3uJOXsVaPHErhLhJHcnLC\nJytDofBlVUEazfbE6urJy4O2bcPhbxa+HmvtkonazqlWSJEEEkvtiXl5cO21UFr61batW+G664Kp\n54APlm5h/vodfP/UnjH1ekWaWiFFEkgstScerhYIpp6de0u5f+pC/vrJKnq1b8brt4ykb+/kmHm9\naqqmrZAauYskkFhqTzzSY0a7nn8t2sT4yYVs3LGX/zq1Bz8+qw9NUpJj6vWKNIW7SALJyKh6tBxE\ne+LhajlwXzQUl5Ry3xvzyZ+1hmPbpZN/03BOzDim2hoToZ1TJ1RFEkgstSdOnAgpKV/fnpoanXre\nmb+Rsx77N1M+X8sPTj+WN2499ZBgP1BjrLxekaZwF0kgsdSemJMDzz0Hbdp8ta1NG3j22fqt54vd\n+7ntb5/z/edn0jo9lZd/MII7zu1Lk5TkKmuMldcr0nRCVUQSxpuF6/n5K3PZXlLKD87oxc1n9CK1\nUXgMm5cX/NrskahBJ1RFpMHYsmsfv3hlHm8Urqd/5xY8f91Q+nVu8eX9sdDyGO0aNHIXkbjl7rxW\nsJ67X53Hrr1l3HpmL2447VhSkg+dcY6FFtFI1aCRu4gktE079jLh5bm8PX8jg7q25JErBnFch+ZV\n7hsLLY/RrkHhLiJxxd2Z/Nla7n19PntKyxk/qi/Xj+xBo+TD94fEQstjtGtQt4yIxI31xXu47o+f\n8pOX5tCrfTPevO1Ubjjt2CMGO8RGy2O0a9DIXURinrvz909XM/GNBZSGQtx1QT++NzyT5CSr0e8f\nOGEZZLdMtGvQCVURiWlrvihh/ORC3luyhaE9WvPw6Cy6t0kPuqzA6ISqiMS1UMjJ+2QVD05dgAP3\nXdyfnKHdSarhaL2hU7iLSMxZuXU34yYV8NHybYzs1ZYHLhtIt9Zp1f+ifEnhLiIxIxRy/vhBEY+8\ntYhGScaDlw3k2yd3w0yj9dpSuItITFi+eRd35Bcwc+UXnN6nHfdfOpDOrZoGXVbcUriLSKDKQ84z\n7y3n0bcX07hREv97xSAuO7GLRutHSeEuIoFZsnEnt+cXMGf1ds7q14GJlwygfYsmQZeVEKoNdzPr\nA/z9oE09gbvc/VcH7WPA48B5QAlwjbt/FuFaRSRBlJaHyJ2xnMffWUJ642Qev3IwFw3qrNF6BFX7\nCVV3X+Tug919MHAS4fCeUmm3UUDvip8xwJORLlREgpWXF178KikpfJmXV7fjLFi/g0t/93888tYi\nzurXgX/86DQuHhz8NEyknl+sqO20zJnAMnevvELCxcDzHv5E1Edm1srMOrn7+ohUKSKBisRytfvL\nQvx2+lJ+O30prdJSeDLnREYN7FQ/BddSLCwJHGm1XVvmSuCvVWzvAqw+6Paaim0ikgAmTPgq+A4o\nKQlvr4nCNcVc9MT7PP7uEs7P6sQ/fnRazAQ7HP3zi0U1HrmbWSpwETC+rg9mZmMIT9uQkQjfQCvS\nQNR1udp9ZeU8/s4Snp6xnDbpqfz+6mzO6tch8gUepVhYEjjSajMtMwr4zN03VnHfWqDbQbe7Vmw7\nhLvnArkQXlumFo8tIgGqy3K1n6/6grH5BSzdtIvRJ3Xl5+f3o2VaFd+YHQNiYUngSKvNtMxVVD0l\nA/AqcLWFnQIUa75dJHHUZrnavaXl3D91AZc/+QG795Xx3LUn88srBsVssENsLAkcaTUauZtZOnAW\ncMNB224EcPengKmE2yCXEu6muTbilYpIYGq6XO2nRdu4I7+AFVt2c9WQDMaf15cWTWI31A+IhSWB\nI01L/orI1+Tl1S7oSvaX8fC0RfzpwyK6tGrKQ5dnMaJX2zofTw5PS/6KSJ3Uti3wg2VbuHNSIau2\nlXD1sO6MO7cv6Y0b1fl4EhkauYvIITIzqz652L07FBV9dXvXvjIemLqAvI9X0b1NGg9dnsUpPdvU\n+XhSMxq5i0id1KQtcMbizYyfXMi64j1cP7IHt5/dh6apyXU+nkSewl1EDnGktsAde0uZ+PoC/j5z\nNT3bpZN/4zBO6t66zseT+lPbT6iKSII7XFvgd8dt5OxHZ/DSrNXccFpPpt56arXBfqTjxXObYTzQ\nyF1EDvG1tsBe+xl83Xz+vHItx3VoxtPfHcGgbq3qfjx1y0SFRu4i8jU5OeGTnW8WbqDd92ZQuGMd\nt3yzF6/dMrJWwS7B0chdRL5m66593P3afF6bs47jO7XguWtOZkCXlnU6llohg6FWSBH5krvzRuF6\nfvHKPHbsLeWWb/bmptOPJSW57v/JVytkZKkVUkRqZfPOffz85blMm7eBrK4tyRs9lL4dWxz1cdUK\nGQyFu0gD5+68Mnsdd782j5L95Yw7ty//dWoPGh3FaP1gaoUMhsJdpAHbULyXn71cyDsLNnFCRise\nGZ1Fr/bNI/oYEyceOucOaoWMBoW7SAPk7rw0aw33vT6f/WUhfnb+8Vw7ogfJSZH/HlO1QgZD4S7S\nwKzdvofxkwuZsXgzQzJb89DoLHq0Ta/Xx8zJUZhHm8JdpIFwd174ZBUPTF1IyJ17LurPd0/pTlI9\njNYleAp3kQZg9bYSxk0q4INlWxl+bBseujyLbq3Tqv9FiVsKd5EEFgo5f/5oJQ9NW0iSGfdfOpCr\nhnTDTKP1RKdwF0lQK7bsZlx+AZ8UbeMbx7XjgcsG0qVV06DLkihRuIskmPKQ89z/reCX/1hESnIS\nD4/O4oqTumq03sAo3EUSyNJNOxmbX8Dnq7ZzZt/2TLx0IB1bNgm6LAmAwl0kAZSVh8h9bzm/emcJ\naanJ/Orbg7l4cGeN1hswhbtInFu4YQd35BdQsKaYc/t35N5L+tO+uUbrDZ3CXSROlZaH+N30ZTwx\nfQktmqTw2/88kfMGdtRoXQCFu0hcmru2mLH5BSxYv4MLB3Xm7gv70aZZ46DLkhiicBeJI/vKynni\nn0t58l/LaJWWytPfPYlz+ncMuiyJQQp3kTgxZ/V2xubPYfHGXVx2YhfuuqAfrdJSgy5LYpTCXSTG\n7S0t57F3FvP7Gctp37wJz16TzTf7dgi6LIlxCneRGDZr5TbG5hewfPNuvp3djQkXHE+LJilBlyVx\noEZftWJmrcws38wWmtkCMxtW6f7TzazYzGZX/NxVP+WK1E5eXvg7PJOSwpd5eUFXVDN79pdz3+vz\nGf3Uh+wrDfH8dUN4aHRWnYI9Xl8DOTo1Hbk/Dkxz99FmlgpUtZzce+5+QeRKEzk6eXmHfgPQypXh\n2xDba4t/tHwr4yYVsHJrCd85JYM7Rx1Ps8Z1+092vL4GcvTM3Y+8g1lLYDbQ0w+zs5mdDtxem3DP\nzs72mTNn1qJUkdrJzKz6uzu7d4eiomhXU73d+8p4aNpCnv9wJRmt03jw8oEMP7btUR0z3l4DqZ6Z\nzXL37Or2q8lwoAewGXjOzAYBs4Db3H13pf2Gm1kBsJZw0M+roqgxwBiADH07rtSzVatqtz1I/7d0\nC+MmFbB2+x6uHZHJ2HP6kJZ69KfE4uk1kMiqyZx7I+BE4El3PwHYDdxZaZ/PgAx3zwJ+A7xc1YHc\nPdfds909u127dkdRtkj1Djd+iKVxxY69pYyfXEjOMx+TmpzEizcM4xcX9o9IsEN8vAZSP2oS7muA\nNe7+ccXtfMJh/yV33+HuuyquTwVSzOzo/j8pcpQmToS0SmeH0tLC22PBvxZt4pzHZvD3T1cx5hs9\nmXrbqZyc2TqijxHrr4HUn2rD3d03AKvNrE/FpjOB+QfvY2YdrWJBCzMbUnHcrRGuVaRWcnIgNzc8\nv2wWvszNDf5EYnFJKbe/NIdrnvuUZo0bMemm4fz0vONpkpIc8ceK1ddA6l+1J1QBzGww8AyQCiwH\nrgW+DeDuT5nZzcBNQBmwB/ixu39wpGPqhKo0RG/P38iEKYVs3b2fG0/rya1n9qZxo8iHuiSump5Q\nrVG41weFuzQkX+zez92vzeOV2evo27E5v7xiEAO6tAy6LIlDkeyWEZGj8Gbhen7+yly2l5Ty39/q\nzQ9O70Vqoxp9flCkzhTuIvVky6593PXKXKYWbmBAlxb8+fqhHN+pRdBlSQOhcBeJMHfn1TnruPvV\neezeV87Yc/ow5hs9SUnWaF2iR+EuEkGbduxlwstzeXv+RgZ3a8Ujo7Po3aF50GVJA6RwF4kAd2fS\nZ2u597V57CsL8dPz+nL9yJ4kJ+kr7yQYCneRo7S+eA8/nVzI9EWbye5+DA+PzqJnu2ZBlyUNnMJd\npI7cnb9/upqJbyygLOT84sJ+fG9YJkkarUsMULiL1MHqbSWMn1zI+0u3cErP1jx0eRbd26QHXZbI\nlxTuIrUQCjl5H6/kwTcXAnDfJQPIGZKh0brEHIW7SA2t3LqbcZMK+Gj5Nk7t3ZYHLhtI12Oq+t4a\nkeAp3EWqUR5y/vhBEY+8tZCUpCQeunwg/5HdjYq18kRiksJd5AiWbd7FHfkFzFr5BWf0acf9lw2k\nU8umQZclUi2Fu0gVykPOM+8t59G3F9MkJZlH/2MQl57QRaN1iRsKd5FKFm/cydj8Auas3s7Z/Trw\nP5cMoH2LJkGXJVIrCneRCqXlIZ7+9zJ+/e5S0hsn8+urTuDCrE4arUtcUriLAPPX7WBs/hzmrdvB\n+VmduOei/rRt1jjoskTqTOEuDdr+shC/nb6U305fSqu0FJ76zomcO6BT0GWJHDWFuzRYhWuKGZs/\nh4UbdnLJ4M784sL+HJOeGnRZIhGhcJcGZ29pOb9+dwlPz1hO22apPHN1Nt/q1yHoskQiSuEuDcrn\nq75gbH4BSzft4oqTuvKzC/rRsmlK0GWJRJzCXRqEvaXl/O8/FvGH91fQsUUT/njtyZzep33QZYnU\nG33vl3wpLw8yMyEpKXyZlxd0RZHxadE2Rj3+Hr9/bwVXDsngrR99Q8EuCU8jdwHCQT5mDJSUhG+v\nXBm+DZCTE1xdR6NkfxkPT1vEnz4sokurpuR9fygjerUNuiyRqDB3D+SBs7OzfebMmYE8tnxdZmY4\n0Cvr3h2KiqJdzdH7YNkWxk0qYPW2PVwzPJOx5/QhvbHGMhL/zGyWu2dXt5/+tAsAq1bVbnus2rWv\njAemLiDv41VktknjxRuGMaRH66DLEok6hbsAkJFR9cg9IyP6tdTVjMWbGT+5kHXFe/j+yB785Ow+\nNE1NDroskUDohKoAMHEipFX63om0tPD2WFe8p5Q78udw9bOf0CQliUk3DednF/RTsEuDVqNwN7NW\nZpZvZgvNbIGZDat0v5nZr81sqZkVmNmJ9VOu1JecHMjNDc+xm4Uvc3Nj/2TqPxdu5JzHZpA/aw03\nnX4sb9x6KidmHBN0WSKBq+nI/XFgmrv3BQYBCyrdPwroXfEzBngyYhUmoFhtOczJCZ88DYXCl7Ec\n7NtL9vOjv8/muj/OpGXTFF7+4QjGnduXJinRGa3H6nsockC1c+5m1hL4BnANgLvvB/ZX2u1i4HkP\nt958VDHS7+Tu6yNcb9xLxJbDaJs2dwM/e3ku20v2c+uZvfnhGcfSuFH0pmD0Hko8qMnIvQewGXjO\nzD43s2fMLL3SPl2A1QfdXlOxTSqZMOGrUDigpCS8XY5s66593PzCZ9z4l1m0b96YV24ewY/POi6q\nwQ56DyU+1CTcGwEnAk+6+wnAbuDOujyYmY0xs5lmNnPz5s11OUTcS5SWw2hyd16bs46zHpvBW/M2\n8JOzjuOVm0fQv3PLQOrReyjxoCbhvgZY4+4fV9zOJxz2B1sLdDvodteKbYdw91x3z3b37Hbt2tWl\n3rh3uNbCeGo5jKZNO/dy419mcctfP6fbMU15/ZZTueXM3qQkB9fopfdQ4kG1f0PcfQOw2sz6VGw6\nE5hfabdXgasrumZOAYo13161eG45jCZ3Z8rnazj7sRlMX7SZO0f1ZdJNw+nTsXnQpek9lLhQ0w8x\n3QLkmVkqsBy41sxuBHD3p4CpwHnAUqAEuLYeak0IB064TZgQ/m98RkY4FHQi7isbivcyYUoh7y7c\nxIkZrXh49CB6tW8WdFlf0nso8UBry0jMcHdemrmG+96YT2l5iNvP7sO1I3qQnJRYX1Cdl6d/GKTu\ntLaMxJW12/cwfnIhMxZvZkiP1jx8eRaZbSs3ZcU/tVFKtGjkLoEKhZy/frqKB6YuJOTOnaP68p2h\n3UlKsNH6AYm2+qZEn0buEvNWbS1h3KQCPly+lRG92vDgZVl0a51W/S/GMbVRSrQo3CXqQiHn+Q+L\neGjaIpKTjAcuG8iVJ3fDLDFH6wdLhNU3JT4o3CWqVmzZzbj8Aj4p2sZpx7XjgcsG0rlV06DLipqJ\nEw+dcwe1UUr9ULhLVJSHnGffX8Ev/7GIxo2SeGR0FqNP6togRusHUxulRIvCXerd0k07GZtfwOer\ntvOt4zsw8dIBdGjRJOiyApOTozCX+qcv64hzsbz0bFl5iN/9aynn/fp9VmzZzeNXDub3V58UU8Ee\ny6+fyNHQyD2OxXLP9MINOxj7UgGFa4sZNaAj9148gHbNGwdbVCWx/PqJHC31ucexWOyZLi0P8bvp\ny3hi+hJaNEnhvksGcN7ATsEUU41YfP1EqqM+9wYg1nqm564tZmx+AQvW7+CiQZ25+6L+tE5PDaaY\nGoi1108kkhTucSxWeqb3lZXzm3eX8uS/l9E6PZXc757E2f07RreIOoiV10+kPuiEahyLhaVnZ6/e\nzoW/eZ8npi/lksFdeOdHp8VFsENsvH4i9UUj9zgWZM/03tJyHnt7Mb9/bzkdWjThuWtO5oy+7ev/\ngSNIPeeSyHRCVWpt1sptjM0vYPnm3Vw1pBvjzzueFk1SavS7Wu5W5OjohKpE3J795Tzy1iKe+2AF\nnVs25S/XD2Vk77Y1/n21HopEj0buUiMfLd/KuEkFrNxawtXDunPHuX1p1rh2YwO1HoocPY3cJSJ2\n7yvjwTcX8uePVtK9TRp/G3MKp/RsU6djqfVQJHoU7nJY7y/ZwrhJBawr3sN1I3pw+znHkZZa9z8y\naj0UiR61QsrX7NhbyvjJBXznDx/TuFESL90wjLsu7HdUwQ5qPRSJJo3c5RDTF23ip5ML2bhjLzec\n1pMffes4mqQkR+TYaj0UiR6N3AMUSysSFpeU8pMX53Dtc5/SrHEjJv9gBONHHf9lsEeq1pyc8MnT\nUCh8qWAXqR8auQckltoC356/kQlTCtm6ez83n9GLW87sReNGX43WY6lWEakZtUIGJBbaArft3s89\nr83jldnrOL5TCx4ZncWALi2/tl8s1CoiYWqFjHFBtwVOLVzPXa/MpXhPKT/61nHcdPqxpDaqepYu\n6FpFpPYU7gEJqi1wy6593PXKXKYWbmBgl5b85ftD6duxxRF/Ry2MIvFHJ1QDEu22QHfnldlrOevR\nf/PO/E2MPacPU34wvNpgD6JWETl6GrkHJJptgZt27OWnU+byzoKNnJDRikdGZ9GrffOYrFVEIqNG\nJ1TNrAjYCZQDZZUn883sdOAVYEXFpsnufu+RjtnQT6hGg7sz6bO13PvaPPaVhbj97D5cN7IHyUkW\ndGkiUkf1cUL1DHffcoT733P3C2pxPKlH64v3MH5yIf9atJmTM4/hocuz6NmuWdBliUiUaFomwbg7\nf/t0Nfe/sYCykHP3hf24elgmSRqtizQoNQ13B94xs3LgaXfPrWKf4WZWAKwFbnf3eZEqUmpm9bYS\nxk8u5P2lWxjWsw0PXZ5FRpu06n9RRBJOTcN9pLuvNbP2wNtmttDdZxx0/2dAhrvvMrPzgJeB3pUP\nYmZjgDEAGeqji5hQyPnLxyt58M2FGPA/lwzgP4dkaLQu0oDV+hOqZnY3sMvdf3mEfYqA7CPN0euE\namQUbdnNuEkFfLxiG6f2bsuDl2fRpVXToMsSkXoSsROqZpYOJLn7zorrZwP3VtqnI7DR3d3MhhDu\nn99at9KlJspDzh8/KOKRtxaSkpzEw5dncUV2V8w0WheRmk3LdACmVIRGI+AFd59mZjcCuPtTwGjg\nJjMrA/YAV3pQi9Y0AMs27+KO/AJmrfyCb/Ztz/2XDqRjyyZBlyUiMaTacHf35cCgKrY/ddD1J4An\nIluaVFZWHuKZ91fw6NuLaZqSzGPfHsQlg7totC4iX6NWyDixeONOxr40hzlrijmnfwfuu2QA7Ztr\ntC4iVVO4x7jS8hBP/WsZv/7nEpo3SeGJ/zyB8wd20mhdRI5I4R7D5q/bwdj8Ocxbt4MLsjpxz0X9\nadOscdBliUgcULjHoP1lIZ6YvpTfTV9Kq7RUnvrOSZw7oGPQZYlIHFG4x5iCNdsZ+1IBizbu5LIT\nunDXhf1olZYadFkiEmcU7jFib2k5j7+7hNwZy2nbLJU/fC+bM4/vEHRZIhKnFO4x4LNVX3BHfgFL\nN+3i29nd+On5x9OyaUrQZYlIHFO4B2jP/nIefXsRf3h/BZ1aNuX564bwjePaBV2WiCQAhXtAPlmx\njTvy51C0tYScoRncOaovzZtotC4ikaFwj7KS/WU8PG0Rf/qwiK7HNOWF7w9leK+2QZclIglG4R5F\nHyzdwrjJBaz5Yg/fG5bJ2HP6kN5Yb4GIRJ6SJQp27i3lgTcX8sLHq+jRNp0XbxjGyZmtgy5LRBKY\nwr2e/XvxZsZPKmDDjr3816k9+PFZfWiamhx0WSKS4BTu9aR4TykT35jPizPX0Kt9M/JvGs6JGccE\nXZaINBAK93rw7oKN/HRKIVt27ecHpx/LrWf2pkmKRusiEj0K9wjaXrKfe16bz5TP19K3Y3Oeufpk\nBnZtGXRZItIAKdwjZNrcDfzs5blsL9nPrWf25uYzepHaKCnoskSkgVK4H6Wtu/Zx16vzeKNgPf07\nt+D564bQr3OLoMsSkQZO4V5H7s7rBev5xavz2LW3jNvPPo4bTjuWlGSN1kUkeAr3Oti0cy8/f3ku\nb83byKCuLXnkikEc16F50GWJiHxJ4V4L7s6Uz9dyz2vz2VNazvhRfbl+ZA8aabQuIjFGqVRDG4r3\n8v0/zeTHL86hV/tmvHnbqdxw2rEK9kry8iAzE5KSwpd5eUFXJNIwaeReDXfnxZmr+Z/XF1AaCnHX\nBf343vBMkpP0BdWV5eXBmDFQUhK+vXJl+DZATk5wdYk0RObugTxwdna2z5w5M5DHrqm12/dw56QC\n3luyhaE9WvPw6Cy6t0kPuqyYlZkZDvTKuneHoqJoVyOSmMxslrtnV7efRu5VCIWcFz5ZxQNTF+DA\nfRf3J2dod5I0Wj+iVatqt11E6o/CvZJVW0sYN6mAD5dvZWSvtjxw2UC6tU4Luqy4kJFR9cg9IyP6\ntYg0dAr3CqGQ86cPi3h42iIaJRkPXjaQb5/cDTON1mtq4sRD59wB0tLC20UkuhTuwIotu7kjfw6f\nFn3B6X3acf+lA+ncqmnQZcWdAydNJ0wIT8VkZISDXSdTRaKvRuFuZkXATqAcKKs8mW/h4e3jwHlA\nCXCNu38W2VIjrzzkPPv+Cn75j0U0bpTE/14xiMtO7KLR+lHIyVGYi8SC2ozcz3D3LYe5bxTQu+Jn\nKPBkxWXMWrJxJ2PzC5i9ejtn9evAxEsG0L5Fk6DLEhGJiEhNy1wMPO/hvsqPzKyVmXVy9/UROn7E\nlJWHeHrGch5/ZwnpjZN5/MrBXDSos0brIpJQahruDrxjZuXA0+6eW+n+LsDqg26vqdh2SLib2Rhg\nDEBGAC0UCzfsYOxLBRSuLeb8gZ245+L+tG3WOOp1iIjUt5qG+0h3X2tm7YG3zWyhu8+o7YNV/KOQ\nC+EPMdX29+tqf1mIJ/+1jCemL6Fl0xSezDmRUQM7RevhRUSirkbh7u5rKy43mdkUYAhwcLivBbod\ndLtrxbbAzV1bzO0vzWHhhp1cMrgzd13Yn9bpqUGXJSJSr6oNdzNLB5LcfWfF9bOBeyvt9ipws5n9\njfCJ1OKg59v3lZXzm3eX8uS/l9EmPZXfX53NWf06BFmSiEjU1GTk3gGYUnHCsRHwgrtPM7MbAdz9\nKWAq4TZPwLCvAAAEvklEQVTIpYRbIa+tn3JrZvbq7Yx9aQ5LNu1i9Eld+fn5/WiZlhJkSSIiUVVt\nuLv7cmBQFdufOui6Az+MbGm1t7e0nMfeXszv31tOhxZNeO7akzmjT/ugy6oXeXn6sJCIHF7CfEJ1\n1sptjH2pgOVbdnPVkAzGn9eXFk0Sc7SupXVFpDpxv+Rvyf4yfvnWYp77YAVdWjXlocuzGNGrbQQq\njF1aWlek4WoQS/5+uGwrd04uYOXWEq4e1p1x5/YlvXFcP6Ua0dK6IlKduEzCXfvKeOjNhfz5o5V0\nb5PG38ecwtCebYIuK2q0tK6IVCfuwn1m0TZu+9ts1hXv4fqRPbj97D40TU0Ouqyo0tK6IlKduAv3\nJinJNGvciPwbh3FS99ZBlxMILa0rItWJyxOqoZDrK+8CplZMkWAk9AlVBXuw1IopEvuSgi5A4s+E\nCYfO90P49oQJwdQjIl+ncJdaUyumSOxTuEutHa7lUq2YIrFD4S61NnFiuPXyYGrFFIktCneptZwc\nyM0NL3dgFr7MzdXJVJFYEpfdMhK8nByFuUgs08hdRCQBKdxFRBKQwl1EJAEp3EVEEpDCXUQkAQW2\ncJiZbQaqWJW8RtoCWyJYTixJ1OeWqM8L9NziUTw/r+7u3q66nQIL96NhZjNrsipaPErU55aozwv0\n3OJRoj6vg2laRkQkASncRUQSULyGe27QBdSjRH1uifq8QM8tHiXq8/pSXM65i4jIkcXryF1ERI4g\n7sLdzM41s0VmttTM7gy6nkgxs2fNbJOZzQ26lkgys25mNt3M5pvZPDO7LeiaIsXMmpjZJ2Y2p+K5\n3RN0TZFkZslm9rmZvR50LZFkZkVmVmhms82sbl/kHAfialrGzJKBxcBZwBrgU+Aqd58faGERYGbf\nAHYBz7v7gKDriRQz6wR0cvfPzKw5MAu4JEHeMwPS3X2XmaUA7wO3uftHAZcWEWb2YyAbaOHuFwRd\nT6SYWRGQ7e7x2udeI/E2ch8CLHX35e6+H/gbcHHANUWEu88AtgVdR6S5+3p3/6zi+k5gAdAl2Koi\nw8N2VdxMqfiJn9HSEZhZV+B84Jmga5G6ibdw7wKsPuj2GhIkKBoCM8sETgA+DraSyKmYupgNbALe\ndvdEeW6/Au4AQkEXUg8ceMfMZpnZmKCLqS/xFu4Sp8ysGTAJ+G933xF0PZHi7uXuPhjoCgwxs7if\nUjOzC4BN7j4r6FrqyciK92wU8MOKKdGEE2/hvhbodtDtrhXbJIZVzEdPAvLcfXLQ9dQHd98OTAfO\nDbqWCBgBXFQxN/034Jtm9pdgS4ocd19bcbkJmEJ4ujfhxFu4fwr0NrMeZpYKXAm8GnBNcgQVJx3/\nACxw90eDrieSzKydmbWquN6U8In+hcFWdfTcfby7d3X3TMJ/x/7p7t8JuKyIMLP0ihP7mFk6cDaQ\nUB1qB8RVuLt7GXAz8BbhE3Mvuvu8YKuKDDP7K/Ah0MfM1pjZ9UHXFCEjgO8SHv3Nrvg5L+iiIqQT\nMN3MCggPPN5294RqG0xAHYD3zWwO8AnwhrtPC7imehFXrZAiIlIzcTVyFxGRmlG4i4gkIIW7iEgC\nUriLiCQghbuISAJSuIuIJCCFu4hIAlK4i4gkoP8HBkFDF1MyWWoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x240c6547dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train, y_train, \"bo\")\n",
    "#plt.plot([0, 60000], [theta_value[1][0], w[0][0] * (60000 / 10000) + theta_value[1][0]])\n",
    "plt.plot([0, 5], [theta_value[0][0],theta_value[1][0]*5+theta_value[0][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Gradient Descent\n",
    "Możemy zminimalizować funkcję kosztu gradientowo wykorzystując gradient:\n",
    "```python\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "[[  2.06855226e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845096e-01]\n",
      " [  1.64778158e-01]\n",
      " [  7.44080753e-04]\n",
      " [ -3.91945168e-02]\n",
      " [ -8.61356616e-01]\n",
      " [ -8.23479712e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też użyć gradientu wyliczonego za pomocą automatycznego różniczkowania\n",
    "```python\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciekwaostka\n",
    "\n",
    "Jak można znaleźć pochodne cząstkowe poniższej funkcji w odniesieniu do a i b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21253923284754914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z\n",
    "\n",
    "my_func(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.212537\n",
      "[-1.1388494, 0.19671395]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z = a * tf.cos(z + i) + z * tf.sin(b - i)\n",
    "\n",
    "grads = tf.gradients(z, [a, b])\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(z.eval())\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimizer\n",
    "\n",
    "Możemy również użyć wbudowanej funkcji do optymalizacji\n",
    "\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.75443\n",
      "Epoch 100 MSE = 0.632222\n",
      "Epoch 200 MSE = 0.57278\n",
      "Epoch 300 MSE = 0.558501\n",
      "Epoch 400 MSE = 0.549069\n",
      "Epoch 500 MSE = 0.542288\n",
      "Epoch 600 MSE = 0.537379\n",
      "Epoch 700 MSE = 0.533822\n",
      "Epoch 800 MSE = 0.531243\n",
      "Epoch 900 MSE = 0.529371\n",
      "Best theta:\n",
      "[[  2.06855249e+00]\n",
      " [  7.74078071e-01]\n",
      " [  1.31192386e-01]\n",
      " [ -1.17845066e-01]\n",
      " [  1.64778143e-01]\n",
      " [  7.44078017e-04]\n",
      " [ -3.91945094e-02]\n",
      " [ -8.61356676e-01]\n",
      " [ -8.23479772e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest wiele różnych metod optymalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.06855798]\n",
      " [ 0.82961673]\n",
      " [ 0.11875112]\n",
      " [-0.26552212]\n",
      " [ 0.30569226]\n",
      " [-0.00450316]\n",
      " [-0.03932616]\n",
      " [-0.89989167]\n",
      " [-0.87054664]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warstwa typu placeholder\n",
    "Warstwa typu placeholder pozwala na dynamiczne dostarczanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "W naszym przypadku mamy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.07001591]\n",
      " [ 0.82045609]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.31134021]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.87950081]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  \n",
    "    indices = np.random.randint(m, size=batch_size)  \n",
    "    X_batch = housing_data_plus_bias[indices] \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] \n",
    "    return X_batch, y_batch\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    \n",
    "print(\"Best theta:\")\n",
    "print(best_theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/tmp/my_model_final.ckpt\")\n",
    "    best_theta_restored = theta.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.07001591]\n",
      " [ 0.82045609]\n",
      " [ 0.1173173 ]\n",
      " [-0.22739051]\n",
      " [ 0.31134021]\n",
      " [ 0.00353193]\n",
      " [-0.01126994]\n",
      " [-0.91643935]\n",
      " [-0.87950081]]\n"
     ]
    }
   ],
   "source": [
    "print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Zad.\n",
    "Wykonaj regresje powyższym sposobem na danych life_satisfaction.csv oraz narysuj wykres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Proszę wykonać regresję za pomocą sieci neuronowej złożonej z dwóch warstw fully connected z warstwą aktywacji relu na poniższych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x212d9c58f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
    "n_samples=200\n",
    "X_train = np.sort(np.random.rand(n_samples))\n",
    "y_train = true_fun(X_train) + np.random.randn(n_samples) * 0.1\n",
    "X_train=np.vstack(X_train)\n",
    "y_train=np.vstack(y_train)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 1\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_outputs), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystamy sieć typu fully_connected z funkcją aktywacji relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        if activation==\"relu\":\n",
    "            return tf.nn.relu(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", activation=\"relu\")\n",
    "    y_pred = neuron_layer(hidden2, n_outputs, \"outputs\")\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    error = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "        \n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mse: 0.680168\n",
      "1 mse: 0.51699\n",
      "2 mse: 0.517969\n",
      "3 mse: 0.540715\n",
      "4 mse: 0.451885\n",
      "5 mse: 0.495775\n",
      "6 mse: 0.514625\n",
      "7 mse: 0.553069\n",
      "8 mse: 0.456015\n",
      "9 mse: 0.495072\n",
      "10 mse: 0.421656\n",
      "11 mse: 0.403392\n",
      "12 mse: 0.45833\n",
      "13 mse: 0.340813\n",
      "14 mse: 0.424725\n",
      "15 mse: 0.461757\n",
      "16 mse: 0.459273\n",
      "17 mse: 0.578472\n",
      "18 mse: 0.437523\n",
      "19 mse: 0.462084\n",
      "20 mse: 0.555569\n",
      "21 mse: 0.401292\n",
      "22 mse: 0.462257\n",
      "23 mse: 0.547026\n",
      "24 mse: 0.431849\n",
      "25 mse: 0.571251\n",
      "26 mse: 0.38564\n",
      "27 mse: 0.48312\n",
      "28 mse: 0.417996\n",
      "29 mse: 0.450639\n",
      "30 mse: 0.346238\n",
      "31 mse: 0.425565\n",
      "32 mse: 0.451266\n",
      "33 mse: 0.520871\n",
      "34 mse: 0.50113\n",
      "35 mse: 0.426592\n",
      "36 mse: 0.51071\n",
      "37 mse: 0.332352\n",
      "38 mse: 0.407134\n",
      "39 mse: 0.384953\n",
      "40 mse: 0.369592\n",
      "41 mse: 0.391967\n",
      "42 mse: 0.349266\n",
      "43 mse: 0.406341\n",
      "44 mse: 0.445132\n",
      "45 mse: 0.434196\n",
      "46 mse: 0.427399\n",
      "47 mse: 0.459091\n",
      "48 mse: 0.432256\n",
      "49 mse: 0.378392\n",
      "50 mse: 0.479644\n",
      "51 mse: 0.392218\n",
      "52 mse: 0.476005\n",
      "53 mse: 0.273046\n",
      "54 mse: 0.356897\n",
      "55 mse: 0.392738\n",
      "56 mse: 0.353598\n",
      "57 mse: 0.374164\n",
      "58 mse: 0.390764\n",
      "59 mse: 0.289405\n",
      "60 mse: 0.417612\n",
      "61 mse: 0.34621\n",
      "62 mse: 0.317894\n",
      "63 mse: 0.310637\n",
      "64 mse: 0.341615\n",
      "65 mse: 0.37265\n",
      "66 mse: 0.351001\n",
      "67 mse: 0.320792\n",
      "68 mse: 0.308593\n",
      "69 mse: 0.299495\n",
      "70 mse: 0.324817\n",
      "71 mse: 0.32406\n",
      "72 mse: 0.340826\n",
      "73 mse: 0.210882\n",
      "74 mse: 0.318756\n",
      "75 mse: 0.20857\n",
      "76 mse: 0.233402\n",
      "77 mse: 0.261567\n",
      "78 mse: 0.29291\n",
      "79 mse: 0.22348\n",
      "80 mse: 0.167286\n",
      "81 mse: 0.211174\n",
      "82 mse: 0.223072\n",
      "83 mse: 0.192019\n",
      "84 mse: 0.221865\n",
      "85 mse: 0.226532\n",
      "86 mse: 0.173059\n",
      "87 mse: 0.176173\n",
      "88 mse: 0.203027\n",
      "89 mse: 0.199499\n",
      "90 mse: 0.16722\n",
      "91 mse: 0.160601\n",
      "92 mse: 0.135713\n",
      "93 mse: 0.139121\n",
      "94 mse: 0.13143\n",
      "95 mse: 0.158013\n",
      "96 mse: 0.128259\n",
      "97 mse: 0.131012\n",
      "98 mse: 0.107282\n",
      "99 mse: 0.140171\n",
      "100 mse: 0.113873\n",
      "101 mse: 0.0938015\n",
      "102 mse: 0.130276\n",
      "103 mse: 0.0881529\n",
      "104 mse: 0.104583\n",
      "105 mse: 0.0868869\n",
      "106 mse: 0.0884797\n",
      "107 mse: 0.0814812\n",
      "108 mse: 0.0979066\n",
      "109 mse: 0.0743414\n",
      "110 mse: 0.0879603\n",
      "111 mse: 0.0626981\n",
      "112 mse: 0.0802316\n",
      "113 mse: 0.0799534\n",
      "114 mse: 0.0658225\n",
      "115 mse: 0.0653331\n",
      "116 mse: 0.0651244\n",
      "117 mse: 0.0567664\n",
      "118 mse: 0.0580965\n",
      "119 mse: 0.0474567\n",
      "120 mse: 0.0633625\n",
      "121 mse: 0.0548279\n",
      "122 mse: 0.0495466\n",
      "123 mse: 0.0456618\n",
      "124 mse: 0.0518813\n",
      "125 mse: 0.0553038\n",
      "126 mse: 0.0671608\n",
      "127 mse: 0.0549241\n",
      "128 mse: 0.0742342\n",
      "129 mse: 0.0342195\n",
      "130 mse: 0.0443868\n",
      "131 mse: 0.0607725\n",
      "132 mse: 0.0526066\n",
      "133 mse: 0.0715754\n",
      "134 mse: 0.0543423\n",
      "135 mse: 0.0389254\n",
      "136 mse: 0.0446206\n",
      "137 mse: 0.0482004\n",
      "138 mse: 0.0319674\n",
      "139 mse: 0.0443978\n",
      "140 mse: 0.0328956\n",
      "141 mse: 0.0457944\n",
      "142 mse: 0.0340335\n",
      "143 mse: 0.0553896\n",
      "144 mse: 0.0439372\n",
      "145 mse: 0.0367942\n",
      "146 mse: 0.0389531\n",
      "147 mse: 0.0393637\n",
      "148 mse: 0.0435249\n",
      "149 mse: 0.0498874\n",
      "150 mse: 0.0519922\n",
      "151 mse: 0.0472424\n",
      "152 mse: 0.0515186\n",
      "153 mse: 0.0482753\n",
      "154 mse: 0.0460921\n",
      "155 mse: 0.0457338\n",
      "156 mse: 0.0317743\n",
      "157 mse: 0.0409814\n",
      "158 mse: 0.0368527\n",
      "159 mse: 0.0593043\n",
      "160 mse: 0.0249667\n",
      "161 mse: 0.0320683\n",
      "162 mse: 0.0408812\n",
      "163 mse: 0.0385477\n",
      "164 mse: 0.0395746\n",
      "165 mse: 0.0244729\n",
      "166 mse: 0.0298691\n",
      "167 mse: 0.0399521\n",
      "168 mse: 0.0301278\n",
      "169 mse: 0.0252833\n",
      "170 mse: 0.0644104\n",
      "171 mse: 0.044138\n",
      "172 mse: 0.0525762\n",
      "173 mse: 0.0221747\n",
      "174 mse: 0.0287196\n",
      "175 mse: 0.0563877\n",
      "176 mse: 0.0355618\n",
      "177 mse: 0.0319713\n",
      "178 mse: 0.0243876\n",
      "179 mse: 0.0580775\n",
      "180 mse: 0.0301737\n",
      "181 mse: 0.0352048\n",
      "182 mse: 0.0679983\n",
      "183 mse: 0.0375404\n",
      "184 mse: 0.0503498\n",
      "185 mse: 0.0324741\n",
      "186 mse: 0.0488096\n",
      "187 mse: 0.0352593\n",
      "188 mse: 0.0292063\n",
      "189 mse: 0.0206846\n",
      "190 mse: 0.0343889\n",
      "191 mse: 0.0355375\n",
      "192 mse: 0.0403591\n",
      "193 mse: 0.0443864\n",
      "194 mse: 0.0202615\n",
      "195 mse: 0.0322095\n",
      "196 mse: 0.029819\n",
      "197 mse: 0.0350227\n",
      "198 mse: 0.031781\n",
      "199 mse: 0.0417455\n",
      "200 mse: 0.0212136\n",
      "201 mse: 0.0643183\n",
      "202 mse: 0.0297186\n",
      "203 mse: 0.035285\n",
      "204 mse: 0.0365119\n",
      "205 mse: 0.0475888\n",
      "206 mse: 0.0504914\n",
      "207 mse: 0.0326311\n",
      "208 mse: 0.0374651\n",
      "209 mse: 0.0255079\n",
      "210 mse: 0.0245758\n",
      "211 mse: 0.0293243\n",
      "212 mse: 0.0406297\n",
      "213 mse: 0.0746852\n",
      "214 mse: 0.03179\n",
      "215 mse: 0.0339777\n",
      "216 mse: 0.0264996\n",
      "217 mse: 0.0368489\n",
      "218 mse: 0.020928\n",
      "219 mse: 0.042306\n",
      "220 mse: 0.0327455\n",
      "221 mse: 0.0340047\n",
      "222 mse: 0.0511577\n",
      "223 mse: 0.0483332\n",
      "224 mse: 0.0417189\n",
      "225 mse: 0.0421089\n",
      "226 mse: 0.0344202\n",
      "227 mse: 0.0445004\n",
      "228 mse: 0.0477098\n",
      "229 mse: 0.0334799\n",
      "230 mse: 0.0324353\n",
      "231 mse: 0.0501468\n",
      "232 mse: 0.0357833\n",
      "233 mse: 0.0249083\n",
      "234 mse: 0.0278223\n",
      "235 mse: 0.0333659\n",
      "236 mse: 0.0387609\n",
      "237 mse: 0.0355572\n",
      "238 mse: 0.0366424\n",
      "239 mse: 0.0376741\n",
      "240 mse: 0.0256932\n",
      "241 mse: 0.0298702\n",
      "242 mse: 0.0272141\n",
      "243 mse: 0.0359358\n",
      "244 mse: 0.0356752\n",
      "245 mse: 0.0292193\n",
      "246 mse: 0.0452739\n",
      "247 mse: 0.0356976\n",
      "248 mse: 0.0345936\n",
      "249 mse: 0.042883\n",
      "250 mse: 0.0427471\n",
      "251 mse: 0.0235977\n",
      "252 mse: 0.0308523\n",
      "253 mse: 0.0518318\n",
      "254 mse: 0.0538114\n",
      "255 mse: 0.0389607\n",
      "256 mse: 0.0240286\n",
      "257 mse: 0.0231353\n",
      "258 mse: 0.0416068\n",
      "259 mse: 0.0519487\n",
      "260 mse: 0.031962\n",
      "261 mse: 0.0404429\n",
      "262 mse: 0.0373487\n",
      "263 mse: 0.0283414\n",
      "264 mse: 0.0331325\n",
      "265 mse: 0.0415243\n",
      "266 mse: 0.0430427\n",
      "267 mse: 0.0482263\n",
      "268 mse: 0.0281162\n",
      "269 mse: 0.0367655\n",
      "270 mse: 0.0467755\n",
      "271 mse: 0.0294044\n",
      "272 mse: 0.0383634\n",
      "273 mse: 0.0349614\n",
      "274 mse: 0.0338842\n",
      "275 mse: 0.0391035\n",
      "276 mse: 0.038907\n",
      "277 mse: 0.0246069\n",
      "278 mse: 0.035323\n",
      "279 mse: 0.0353269\n",
      "280 mse: 0.0367767\n",
      "281 mse: 0.0266751\n",
      "282 mse: 0.0351707\n",
      "283 mse: 0.0508044\n",
      "284 mse: 0.0206938\n",
      "285 mse: 0.0258341\n",
      "286 mse: 0.0479293\n",
      "287 mse: 0.0532542\n",
      "288 mse: 0.032346\n",
      "289 mse: 0.034241\n",
      "290 mse: 0.0357982\n",
      "291 mse: 0.036394\n",
      "292 mse: 0.0457941\n",
      "293 mse: 0.0256222\n",
      "294 mse: 0.0177155\n",
      "295 mse: 0.07563\n",
      "296 mse: 0.0513033\n",
      "297 mse: 0.0342011\n",
      "298 mse: 0.036496\n",
      "299 mse: 0.0361977\n",
      "300 mse: 0.0303422\n",
      "301 mse: 0.0371308\n",
      "302 mse: 0.0257735\n",
      "303 mse: 0.025874\n",
      "304 mse: 0.0343965\n",
      "305 mse: 0.0395767\n",
      "306 mse: 0.0331029\n",
      "307 mse: 0.0358636\n",
      "308 mse: 0.0370435\n",
      "309 mse: 0.0565076\n",
      "310 mse: 0.0191305\n",
      "311 mse: 0.0285408\n",
      "312 mse: 0.0470641\n",
      "313 mse: 0.0414977\n",
      "314 mse: 0.0606451\n",
      "315 mse: 0.0456412\n",
      "316 mse: 0.04172\n",
      "317 mse: 0.0359552\n",
      "318 mse: 0.0451951\n",
      "319 mse: 0.0248674\n",
      "320 mse: 0.0561274\n",
      "321 mse: 0.0376343\n",
      "322 mse: 0.0429114\n",
      "323 mse: 0.0303468\n",
      "324 mse: 0.0203595\n",
      "325 mse: 0.0211188\n",
      "326 mse: 0.0330405\n",
      "327 mse: 0.0241663\n",
      "328 mse: 0.0413532\n",
      "329 mse: 0.0330618\n",
      "330 mse: 0.0449489\n",
      "331 mse: 0.0307628\n",
      "332 mse: 0.0526259\n",
      "333 mse: 0.0277292\n",
      "334 mse: 0.0415478\n",
      "335 mse: 0.0447171\n",
      "336 mse: 0.0479787\n",
      "337 mse: 0.0275873\n",
      "338 mse: 0.05112\n",
      "339 mse: 0.0315614\n",
      "340 mse: 0.041287\n",
      "341 mse: 0.032096\n",
      "342 mse: 0.045951\n",
      "343 mse: 0.0228573\n",
      "344 mse: 0.0273677\n",
      "345 mse: 0.0289244\n",
      "346 mse: 0.0622121\n",
      "347 mse: 0.0456043\n",
      "348 mse: 0.0330636\n",
      "349 mse: 0.0486272\n",
      "350 mse: 0.0563448\n",
      "351 mse: 0.0476038\n",
      "352 mse: 0.023749\n",
      "353 mse: 0.0311753\n",
      "354 mse: 0.0331625\n",
      "355 mse: 0.0253385\n",
      "356 mse: 0.0374997\n",
      "357 mse: 0.0328093\n",
      "358 mse: 0.0451609\n",
      "359 mse: 0.0222541\n",
      "360 mse: 0.0326327\n",
      "361 mse: 0.0305731\n",
      "362 mse: 0.0290026\n",
      "363 mse: 0.0332354\n",
      "364 mse: 0.035603\n",
      "365 mse: 0.0448218\n",
      "366 mse: 0.0338149\n",
      "367 mse: 0.0248709\n",
      "368 mse: 0.0466732\n",
      "369 mse: 0.0316747\n",
      "370 mse: 0.0374763\n",
      "371 mse: 0.0274006\n",
      "372 mse: 0.0252482\n",
      "373 mse: 0.0414544\n",
      "374 mse: 0.0236487\n",
      "375 mse: 0.0409759\n",
      "376 mse: 0.0238916\n",
      "377 mse: 0.0194345\n",
      "378 mse: 0.0444124\n",
      "379 mse: 0.040281\n",
      "380 mse: 0.0322225\n",
      "381 mse: 0.0232961\n",
      "382 mse: 0.0389458\n",
      "383 mse: 0.0410348\n",
      "384 mse: 0.0385858\n",
      "385 mse: 0.0339556\n",
      "386 mse: 0.0463343\n",
      "387 mse: 0.0221076\n",
      "388 mse: 0.0232272\n",
      "389 mse: 0.0503133\n",
      "390 mse: 0.0619042\n",
      "391 mse: 0.0717987\n",
      "392 mse: 0.0240687\n",
      "393 mse: 0.0337295\n",
      "394 mse: 0.0259409\n",
      "395 mse: 0.0488204\n",
      "396 mse: 0.0375502\n",
      "397 mse: 0.0334464\n",
      "398 mse: 0.0196971\n",
      "399 mse: 0.0433958\n"
     ]
    }
   ],
   "source": [
    "x_dom = np.vstack(np.arange(0,1,0.01))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 400\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size, X,  y):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(X.shape[0], size=batch_size)  # not shown\n",
    "    X_batch = X[indices] # not shown\n",
    "    y_batch = y[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size, X_train, y_train)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        #acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,y: mnist.validation.labels})\n",
    "        print(epoch, \"mse:\", acc_train)#, \"Val accuracy:\", acc_val)\n",
    "    x_dom_pred = y_pred.eval(feed_dict={X: x_dom})\n",
    "    #save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(X_train, y_train, \"bo\")\n",
    "plt.plot(x_dom, x_dom_pred, color='red',linewidth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Proszę wykonać regresję za pomocą sieci neuronowej złożonej z dwóch warstw fully connected z warstwą aktywacji relu na danych \n",
    "housing ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
