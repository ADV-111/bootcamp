{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przekształcenie Tf-Idf\n",
    "\n",
    "Przekształcenie to mierzy jak ważne są poszczególne słowa w poszczególnych dokumentach.\n",
    "\n",
    "Tf - term frequency - częstość słowa w dokumencie.\n",
    "\n",
    "Idf - inverse document frequency - odwrotność częstości słowa w zbiorze dokumentów.\n",
    "\n",
    "Wartość ważności słowa $w$ w dokumencie $d$ to:\n",
    "\n",
    "$$TFIDF(w,d) = tf(w,d) \\cdot idf(w).$$\n",
    "\n",
    "Istnieje wiele różnych wariantów tej miary. Podstawowa to:\n",
    "\n",
    "**tf(w,d)** - liczba wystąpień słowa $w$ w dokumencie $d$ podzielona przez liczbę wszystkich słów w dokumencie $d$;\n",
    "\n",
    "**idf(w)** - logarytm z liczby dokumentów w korpusie podzielonej przez liczbę dokumentów, w których wystąpiło słowo $w$.\n",
    "\n",
    "### https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Podzielmy zdania na słowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. Smith, how are you doing today?', 'The weather is great, and Python is awesome.', 'The sky is pinkish-blue.', \"You shouldn't eat cardboard.\", \"I'm 20 years old.\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "EXAMPLE_TEXT = \"Hello Mr. Smith, how are you doing today? The weather is great, and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard. I'm 20 years old.\"\n",
    "sentences = sent_tokenize(EXAMPLE_TEXT)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Wykonajmy transformatę Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 9, 'mr': 12, 'smith': 18, 'how': 10, 'are': 2, 'you': 23, 'doing': 6, 'today': 20, 'the': 19, 'weather': 21, 'is': 11, 'great': 8, 'and': 1, 'python': 15, 'awesome': 3, 'sky': 17, 'pinkish': 14, 'blue': 4, 'shouldn': 16, 'eat': 7, 'cardboard': 5, '20': 0, 'years': 22, 'old': 13}\n",
      "----\n",
      "(5, 24)\n",
      "[[0.         0.         0.36152912 0.         0.         0.\n",
      "  0.36152912 0.         0.         0.36152912 0.36152912 0.\n",
      "  0.36152912 0.         0.         0.         0.         0.\n",
      "  0.36152912 0.         0.36152912 0.         0.         0.29167942]\n",
      " [0.         0.3480587  0.         0.3480587  0.         0.\n",
      "  0.         0.         0.3480587  0.         0.         0.56162314\n",
      "  0.         0.         0.         0.3480587  0.         0.\n",
      "  0.         0.28081157 0.         0.3480587  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.48214012 0.\n",
      "  0.         0.         0.         0.         0.         0.38898761\n",
      "  0.         0.         0.48214012 0.         0.         0.48214012\n",
      "  0.         0.38898761 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.52335825\n",
      "  0.         0.52335825 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.52335825 0.\n",
      "  0.         0.         0.         0.         0.         0.42224214]\n",
      " [0.57735027 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.57735027 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.57735027 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "print( tfidf_vectorizer.vocabulary_ )\n",
    "print(\"----\")\n",
    "print(tfidf_matrix.todense().shape)\n",
    "print(tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Porównaj wynik Tf-Idf i reprezentacji bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 9, 'mr': 12, 'smith': 18, 'how': 10, 'are': 2, 'you': 23, 'doing': 6, 'today': 20, 'the': 19, 'weather': 21, 'is': 11, 'great': 8, 'and': 1, 'python': 15, 'awesome': 3, 'sky': 17, 'pinkish': 14, 'blue': 4, 'shouldn': 16, 'eat': 7, 'cardboard': 5, '20': 0, 'years': 22, 'old': 13}\n",
      "----\n",
      "(5, 24)\n",
      "[[0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [0 1 0 1 0 0 0 0 1 0 0 2 0 0 0 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "cv_matrix = vectorizer.fit_transform(sentences)\n",
    "print( vectorizer.vocabulary_ )\n",
    "print(\"----\")\n",
    "print(cv_matrix.todense().shape)\n",
    "print(cv_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "Wypisz 5 najważniejszych sów w każdym, zdaniu względem Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20',\n",
       " 'and',\n",
       " 'are',\n",
       " 'awesome',\n",
       " 'blue',\n",
       " 'cardboard',\n",
       " 'doing',\n",
       " 'eat',\n",
       " 'great',\n",
       " 'hello',\n",
       " 'how',\n",
       " 'is',\n",
       " 'mr',\n",
       " 'old',\n",
       " 'pinkish',\n",
       " 'python',\n",
       " 'shouldn',\n",
       " 'sky',\n",
       " 'smith',\n",
       " 'the',\n",
       " 'today',\n",
       " 'weather',\n",
       " 'years',\n",
       " 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix.getrow(i).todense().argsort().A.flatten()[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello' 'today' 'are' 'smith' 'doing']\n",
      "['is' 'weather' 'and' 'awesome' 'python']\n",
      "['sky' 'blue' 'pinkish' 'is' 'the']\n",
      "['cardboard' 'shouldn' 'eat' 'you' 'how']\n",
      "['20' 'old' 'years' 'how' 'and']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(len(sentences)):\n",
    "    print(np.array(tfidf_vectorizer.get_feature_names())[\n",
    "        tfidf_matrix.getrow(i).todense().argsort().A.flatten()[-5:][::-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pytanie: do czego innego można zastosować TFIDF niż ważności słów w tekście?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Porównaj wyniki z najczęstszymi słowami w kolejnych zdaniach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you' 'hello' 'today' 'are' 'smith']\n",
      "['is' 'weather' 'and' 'the' 'awesome']\n",
      "['is' 'the' 'sky' 'blue' 'pinkish']\n",
      "['you' 'cardboard' 'shouldn' 'eat' 'how']\n",
      "['20' 'old' 'years' 'how' 'and']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(len(sentences)):\n",
    "    print(np.array(vectorizer.get_feature_names())[\n",
    "        cv_matrix.getrow(i).todense().argsort().A.flatten()[-5:][::-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Odległość między wektorami\n",
    "\n",
    "* Znaczenia wyrazów w semantyce dystrybucyjnej są reprezentowane przez wektory liczbowe.\n",
    "\n",
    "* Odległość między wektorami będziemy interpretować jako stopień podobieństwa reprezentowanych przez nie wyrazów.\n",
    "\n",
    "* Najpopularniejszą miarą odległości dla reprezentacji wektorowej jest miara kosinusowa. \n",
    "\n",
    "* Wyrazy podobne, tzn. takie, które opisują ściśle związane ze sobą pojęcia, powinny odpowiadać wektorom leżącym blisko siebie, co oznacza, że kąt pomiędzy nimi powinien być jak najmniejszy, a co za tym idzie, kosinus tego kąta powinien być bliski 1.\n",
    "\n",
    "* Wyrazy, które nie są ze sobą powiązane semantycznie powinny być reprezentowane przez wektory ortogonalne, a więc kosinus kąta pomiędzy nimi powinien być bliski 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Różne odległości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# euclidean\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.euclidean.html#scipy.spatial.distance.euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = []\n",
    "for i in np.linspace(-2.0, 2.0, num=100):\n",
    "    for j in np.linspace(-2.0, 2.0, num=100):\n",
    "        if( dis.euclidean([0,0],[i,j]) < 1 ):\n",
    "            data.append( [i,j] )\n",
    "data = np.array(data)   \n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cityblock\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cityblock.html#scipy.spatial.distance.cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for i in np.linspace(-2.0, 2.0, num=100):\n",
    "    for j in np.linspace(-2.0, 2.0, num=100):\n",
    "        if( dis.cityblock([0,0],[i,j]) < 1 ): ########### zmien p = 1,2,3\n",
    "            data.append( [i,j] )\n",
    "data = np.array(data)   \n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-3,3)\n",
    "plt.ylim(-3,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cosine.html#scipy.spatial.distance.cosine\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "\n",
    "Miarą, która wydaje się być lepiej dopasowana do naszego przypadku jest ***podobieństwo cosinusowe***. Definiujemy je następująco:\n",
    "\n",
    "$$ sim(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} = \\frac{\\sum_{i=1}^{n}A_i B_i}{\\sqrt{\\sum_{i=1}^{n}A_i^2}\\sqrt{\\sum_{i=1}^{n}B_i^2}} $$\n",
    "\n",
    "Oczywiście łatwo wyprowadzić wzór na odległość:\n",
    "\n",
    "$$ dist(A, B) = 1 - sim(A, B) $$\n",
    "\n",
    "\n",
    "Mierzy ona podobieństwo wektorów na podstawie rozkładu wartości elementów (proporcji), a nie wartości bewzględnych. Matematycznie: podobieństwo jest określane na podstawie kąta pomiędzy wektorami (wartości cosinusa tego kąta), a nie na podstawie długości wektorów.\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "data1 = []\n",
    "for i in np.linspace(-1., 1.0, num=10):\n",
    "    for j in np.linspace(-1., 1.0, num=10):\n",
    "        if( dis.cosine([0,1],[i,j]) < 1 ):\n",
    "            data.append( [i,j] )\n",
    "#         print(dis.cosine([0.1,0.1],[i,j]))\n",
    "        else:\n",
    "            data1.append( [i,j] )\n",
    "#             print(1)\n",
    "data = np.array(data)   \n",
    "data1 = np.array(data1)   \n",
    "\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.scatter(data1[:,0], data1[:,1])\n",
    "V = np.array([[0,1]])\n",
    "origin = [0], [0] # origin point\n",
    "\n",
    "plt.quiver(*origin, V[:,0], V[:,1], angles='xy', scale_units='xy', scale=1)\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Jednym z zadań NLP jest wyszukiwanie dokumentów podobnych dla danego zapytania (wyszukiwarki internetowe).\n",
    "\n",
    "* Weźmy korpus dokumentów, jak poniżej. \n",
    "\n",
    "* Zadajemy zapytanie złorzone z \"dies, dagger\". \n",
    "\n",
    "* Prosze uszeregować dokumenty w kolejności od najbardziej pasujących. \n",
    "\n",
    "* Transformujemy query do naszej reprezentacji i liczymy odległość kosinusową (mnożenie wektorów i sumowanie)\n",
    "\n",
    "Policz odległość między zdaniami: \n",
    " * \"I eat an apple.\"\n",
    " * \"I ate the apple.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I eat an apple.', 'I eat an apple I eat an apple.', 'I eat an apple apple apple.']\n",
      "{'eat': 2, 'an': 0, 'apple': 1}\n",
      "[[1 1 1]\n",
      " [2 2 2]\n",
      " [1 3 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = [\"I eat an apple.\", \"I eat an apple I eat an apple.\", \"I eat an apple apple apple.\"]\n",
    "\n",
    "\n",
    "print(sentences)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences)\n",
    "print( vectorizer.vocabulary_ )\n",
    "bag_of_words = vectorizer.transform(sentences)\n",
    "print(bag_of_words.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "[2 2 2]\n",
      "[1 3 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t1 = np.array(bag_of_words[0].todense()).flatten()\n",
    "t2 = np.array(bag_of_words[1].todense()).flatten()\n",
    "t3 = np.array(bag_of_words[2].todense()).flatten()\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.1296117202215108\n",
      "----\n",
      "1.7320508075688772\n",
      "2.0\n",
      "----\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print(cosine(t1,t2))\n",
    "print(cosine(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.euclidean(t1,t2))\n",
    "print(dis.euclidean(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.cityblock(t1,t2))\n",
    "print(dis.cityblock(t1,t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eat': 2, 'an': 0, 'apple': 1}\n",
      "----\n",
      "[[0.57735027 0.57735027 0.57735027]\n",
      " [0.57735027 0.57735027 0.57735027]\n",
      " [0.30151134 0.90453403 0.30151134]]\n",
      "[0.57735027 0.57735027 0.57735027]\n",
      "[0.57735027 0.57735027 0.57735027]\n",
      "[0.30151134 0.90453403 0.30151134]\n",
      "0.0\n",
      "0.1296117202215108\n",
      "----\n",
      "0.0\n",
      "0.5091399026230626\n",
      "----\n",
      "0.0\n",
      "0.8788616137673895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "print( tfidf_vectorizer.vocabulary_ )\n",
    "print(\"----\")\n",
    "print(tfidf_matrix.todense())\n",
    "\n",
    "t1 = np.array(tfidf_matrix[0].todense()).flatten()\n",
    "t2 = np.array(tfidf_matrix[1].todense()).flatten()\n",
    "t3 = np.array(tfidf_matrix[2].todense()).flatten()\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "print(cosine(t1,t2))\n",
    "print(cosine(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.euclidean(t1,t2))\n",
    "print(dis.euclidean(t1,t3))\n",
    "print(\"----\")\n",
    "print(dis.cityblock(t1,t2))\n",
    "print(dis.cityblock(t1,t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek: Odległość cosinsusowa jest typową odległością na tekstach - ważny jest tylko kąt a nie długość.\n",
    "\n",
    "# Zad\n",
    "Znajdź najbliższe zdanie z korpusu do zestwu słów:\n",
    "\n",
    "```python\n",
    "query = [\"dies\", \"dagger\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"Romeo and Juliet died\",\n",
    "         \"Juliet: O happy dagger\",\n",
    "         \"Romeo died by dagger\",\n",
    "         \"'Live free or die', that’s the New-Hampshire’s motto\",\n",
    "         \"Did you know, New-Hampshire is in New-England\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = [\"dies\", \"dagger\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformuje corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'romeo': 10, 'juliet': 5, 'die': 2, 'happi': 4, 'dagger': 1, \"'live\": 0, 'free': 3, '’': 11, 'new-hampshir': 9, 'motto': 7, 'know': 6, 'new-england': 8}\n",
      "[[0.         0.         0.50620441 0.         0.         0.60981846\n",
      "  0.         0.         0.         0.         0.60981846 0.        ]\n",
      " [0.         0.53177225 0.         0.         0.659118   0.53177225\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.60981846 0.50620441 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.60981846 0.        ]\n",
      " [0.35137655 0.         0.23532097 0.35137655 0.         0.\n",
      "  0.         0.35137655 0.         0.28348839 0.         0.70275311]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.61418897 0.         0.61418897 0.49552379 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def my_tokenizer(sent):\n",
    "    tokens = word_tokenize(sent)\n",
    "    stemmer = PorterStemmer()\n",
    "    res = [stemmer.stem(word) for word in tokens]\n",
    "    return res \n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, stop_words=stopwords.words('english') + list(string.punctuation))\n",
    "vectorizer.fit(corpus)\n",
    "print(vectorizer.vocabulary_)\n",
    "data = vectorizer.transform(corpus)\n",
    "print(data.todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformuje query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "query_data = vectorizer.transform(query)\n",
    "print(query_data.todense())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczymy odległość kosinusową )(tak naprawdę odległość to 1 - cos)\n",
    "\n",
    "http://mlwiki.org/index.php/Cosine_Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.50620441, 0.        ],\n",
       "        [0.        , 0.53177225],\n",
       "        [0.50620441, 0.60981846],\n",
       "        [0.23532097, 0.        ],\n",
       "        [0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.dot(data, query_data.T).todense()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wniosek: zapytanie \"dies, dagger\" najbardziej pasuje do \"Romeo died by dagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
