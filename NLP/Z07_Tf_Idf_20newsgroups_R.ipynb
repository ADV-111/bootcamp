{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad. \n",
    "\n",
    "Otagować (czyli wskazać słowa \"kluczowe\") teksty korpusu 20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wypisz pierwszy tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(len(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wypisz tagi (numery) i ich nazwy (napisy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 4 4 ... 3 1 8]\n",
      "11314\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.target)\n",
    "print(len(newsgroups_train.target))\n",
    "print(len( set( newsgroups_train.target ) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(newsgroups_train.target_names))\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Można sczytać dane bez nagłówków i stopek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove= ('headers', 'footers', 'quotes')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='all', shuffle=True, remove = to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  3 17 ...  3  1  7]\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for j in range(len(newsgroups_train.target_names)):\n",
    "    data.append([newsgroups_train.data[i] for i in range(newsgroups_train.target.shape[0]) if newsgroups_train.target[i] == j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biore okreslona ilosc danych z kazdej klasy\n",
    "\n",
    "categories = 5\n",
    "num=50\n",
    "X_set = []\n",
    "Y_set =[]\n",
    "for i in range(categories):\n",
    "    X_set = X_set + data[i][:num]\n",
    "    Y_set = Y_set + [i]*num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "\n",
    "Proszę wykonać podstawową tekenizację biorąc pod uwagę:\n",
    "\n",
    " * bierzemy kolejne artykuły i dzieli go na tokeny\n",
    " * bierzemy listę tokenów i usuwamy punktory\n",
    " * bierzemy listę tokenów i usuwa liczby\n",
    " * bierzemy listę tokenów i zamieniamy na małe litery\n",
    "\n",
    "a następnie stworzyć reprezentację **Tf-Idf**.\n",
    "\n",
    "Użyj:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    remove_list = list(string.punctuation) + [\"--\", \"\\\"\", \"``\" , \"...\", \"''\", \"'\" ]\n",
    "    return [w for w in words if not w in set(remove_list)]\n",
    "\n",
    "def remove_nummbers(words):\n",
    "    return [w for w in words if not w.isdigit()]\n",
    "\n",
    "def to_lower(words):\n",
    "    return [w.lower() for w in words]\n",
    "\n",
    "\n",
    "def my_tokenizer(sent):\n",
    "    tokens = word_tokenize(sent)\n",
    "    tokens = remove_punctuation(tokens)\n",
    "    tokens = remove_nummbers(tokens)\n",
    "    tokens = to_lower(tokens)\n",
    "    stemmer = PorterStemmer()\n",
    "    res = [stemmer.stem(word) for word in tokens]\n",
    "    return res \n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, stop_words=stopwords.words('english') + list(string.punctuation))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(X_set)\n",
    "# print( tfidf_vectorizer.vocabulary_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "(250, 4479)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"----\")\n",
    "print(tfidf_matrix.todense().shape)\n",
    "print(tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Wypisz 10 słów kluczowych dla dwóch pierwszych tekstów i sprawdź czy są sensowne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heliocentr' 'galacticentr' 'notion' 'either' 'even' '~330m' 'dream'\n",
      " 'dragon' 'dram' 'draw']\n",
      "['moral' 'ask' 'motiv' 'posit' 'correct' 'right' 'percept' 'wrong'\n",
      " 'question' 'certainli']\n",
      "['bobbi' 'allah' 'mozumd' 'prove' 'exist' 'mom' 'wisdom' 'men' \"'s\"\n",
      " 'contradict']\n",
      "['possibl' 'lunat' 'liar' 'wa' 'bibl' 'lie' 'die' 'mussolini' 'thousand'\n",
      " 'unbias']\n",
      "['bookstor' 'list' 'book' 'find' 'pittsburgh' 'largest' '_any_' 'altern'\n",
      " 'section' 'area']\n",
      "['technolog' 'everi' 'must' 'realli' 'etc' 'believ' 'thing' 'crusad'\n",
      " '-really-' 'troop']\n",
      "['jim' 'faith' 'sorri' 'bummin' 'flintston' 'denial' 'chewabl' 'iii'\n",
      " 'jimmi' 'bye-by']\n",
      "['yesterday' 'street' 'tien' 'wing' 'einstein' 'lunch' 'fu' 'castro'\n",
      " 'cooki' 'fortun']\n",
      "['law' 'islam' 'land' 'religion' 'live' 'life' 'zakat' 'non-muslim'\n",
      " 'secular' 'popul']\n",
      "['pope' 'bear' 'wood' 'cathol' 'shit' 'alway' 'thought' 'littl' 'say'\n",
      " 'becaus']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(10):\n",
    "    print(np.array(tfidf_vectorizer.get_feature_names())[\n",
    "        tfidf_matrix.getrow(i).todense().argsort().A.flatten()[-10:][::-1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\tThere is no notion of heliocentric, or even galacticentric either.\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(X_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ . . .]\n",
      "\n",
      "I am a relativist who would like to answer your question, but the way you\n",
      "phrase the question makes it unanswerable.  The concepts of \"right\"\n",
      "and \"wrong\" (or \"correct/incorrect\" or \"true/false\") belong to the\n",
      "domain of epistemological rather than moral questions.  It makes no\n",
      "sense to ask if a moral position is right or wrong, although it is\n",
      "legitimate to ask if it is good (or better than another position).\n",
      "\n",
      "Let me illustrate this point by looking at the psychological derivatives\n",
      "of epistemology and ethics:  perception and motivation, respectively.\n",
      "One can certainly ask if a percept is \"right\" (correct, true,\n",
      "veridical) or \"wrong\" (incorrect, false, illusory).  But it makes little\n",
      "sense to ask if a motive is true or false.  On the other hand, it is\n",
      "strange to ask whether a percept is morally good or evil, but one can\n",
      "certainly ask that question about motives.\n",
      "\n",
      "Therefore, your suggested answers (a)-(c) simply can't be considered:\n",
      "they assume you can judge the correctness of a moral judgment.\n",
      "\n",
      "Now the problem with (d) is that it is double-barrelled:  I agree with\n",
      "the first part (that the \"rightness\" of a moral position is a\n",
      "meaningless question), for the reasons stated above.  But that is\n",
      "irrelevant to the alleged implication (not an implication at all) that\n",
      "one cannot feel peace is better than war.  I certainly can make\n",
      "value judgments (bad, better, best) without asserting the \"correctness\"\n",
      "of the position.\n",
      "\n",
      "Sorry for the lengthy dismissal of (a)-(d).  My short (e) answer is\n",
      "that when two individuals grotesquely disagree on a moral issue,\n",
      "neither is right (correct) or wrong (incorrect).  They simply hold\n",
      "different moral values (feelings).\n"
     ]
    }
   ],
   "source": [
    "print(X_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
