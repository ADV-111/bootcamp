{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad. \n",
    "\n",
    "Otagować (czyli wskazać słowa \"kluczowe\", Latent Dirichlet Allocation) teksty korpusu 20newsgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Można sczytać dane bez nagłówków i stopek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  And i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  Touch me gently ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  Why I had to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Burning My Bridges</td>\n",
       "      <td>/a/abba/burning+my+bridges_20003011.html</td>\n",
       "      <td>Well, you hoot and you holler and you make me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Cassandra</td>\n",
       "      <td>/a/abba/cassandra_20002811.html</td>\n",
       "      <td>Down in the street they're all singing and sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Chiquitita</td>\n",
       "      <td>/a/abba/chiquitita_20002978.html</td>\n",
       "      <td>Chiquitita, tell me what's wrong  You're encha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Crazy World</td>\n",
       "      <td>/a/abba/crazy+world_20003013.html</td>\n",
       "      <td>I was out with the morning sun  Couldn't sleep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Crying Over You</td>\n",
       "      <td>/a/abba/crying+over+you_20177611.html</td>\n",
       "      <td>I'm waitin' for you baby  I'm sitting all alon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "5   ABBA     Burning My Bridges    /a/abba/burning+my+bridges_20003011.html   \n",
       "6   ABBA              Cassandra             /a/abba/cassandra_20002811.html   \n",
       "7   ABBA             Chiquitita            /a/abba/chiquitita_20002978.html   \n",
       "8   ABBA            Crazy World           /a/abba/crazy+world_20003013.html   \n",
       "9   ABBA        Crying Over You       /a/abba/crying+over+you_20177611.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  And i...  \n",
       "1  Take it easy with me, please  Touch me gently ...  \n",
       "2  I'll never know why I had to go  Why I had to ...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  \n",
       "5  Well, you hoot and you holler and you make me ...  \n",
       "6  Down in the street they're all singing and sho...  \n",
       "7  Chiquitita, tell me what's wrong  You're encha...  \n",
       "8  I was out with the morning sun  Couldn't sleep...  \n",
       "9  I'm waitin' for you baby  I'm sitting all alon...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('songdata.csv')\n",
    "df['text'] = df['text'].str.replace('\\n', '')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"artist\"].values[:1000]\n",
    "X_set = df[\"text\"].values[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Wykonaj przekształcenie Tf-Idf\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    remove_list =  stopwords.words('english') + list(string.punctuation) + [\"'s\",'′','--', '.\"', '!\"', '?\"', ',\"', '``', \"''\", \"\\\\\\\\\",'⁄',\"n't\",\"'ll\",\"'m\"]\n",
    "    return [w for w in words if not w in set(remove_list)]\n",
    "\n",
    "def remove_nummbers(words):\n",
    "    return [w for w in words if not w.isdigit()]\n",
    "\n",
    "def to_lower(words):\n",
    "    return [w.lower() for w in words]\n",
    "\n",
    "\n",
    "def my_tokenizer(sent):\n",
    "    tokens = word_tokenize(sent)\n",
    "    tokens = to_lower(tokens)    \n",
    "    tokens = remove_punctuation(tokens)\n",
    "    tokens = remove_nummbers(tokens)\n",
    "    stemmer = PorterStemmer()\n",
    "    res = [stemmer.stem(word) for word in tokens]\n",
    "    return res \n",
    "\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=my_tokenizer, stop_words=stopwords.words('english') + list(string.punctuation))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(X_set)\n",
    "# print( tfidf_vectorizer.vocabulary_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "(1000, 7123)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"----\")\n",
    "print(tfidf_matrix.todense().shape)\n",
    "print(tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "Stwórz model języka w bibliotece **gensim** na podstawie reprezentacji **Tf-Idf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sparse = matutils.Sparse2Corpus(tfidf_matrix, documents_columns=False)\n",
    "dictionary_list = tfidf_vectorizer.get_feature_names()\n",
    "dictionary_sparse_dict = {i:j for i,j in enumerate(dictionary_list)}\n",
    "dictionary = corpora.Dictionary.from_corpus(corpus_sparse, id2word=dictionary_sparse_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "Stwórz model **Lda** (Latent Dirichlet Allocation) z\n",
    "* **num_topics=20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LdaModel(corpus=corpus_sparse, id2word=dictionary, num_topics=2)#, alpha='auto', eta='auto', iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wizualizacja modelu LDA:\n",
    "\n",
    "pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.gensim.prepare(model, corpus_sparse, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
