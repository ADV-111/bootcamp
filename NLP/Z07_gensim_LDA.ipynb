{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documents = [\"Human machine interface for lab abc computer applications\",\n",
    "#              \"A survey of user opinion of computer system response time\",\n",
    "#              \"The EPS user interface management system\",\n",
    "#              \"System and human system engineering testing of EPS\",\n",
    "#              \"Relation of user perceived response time to error measurement\",\n",
    "#              \"The generation of random binary unordered trees\",\n",
    "#              \"The intersection graph of paths in trees\",\n",
    "#              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "#               \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used files generated from first tutorial\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists(\"tmp/deerwester.dict\")):\n",
    "    dictionary = corpora.Dictionary.load('tmp/deerwester.dict')\n",
    "    corpus = corpora.MmCorpus('tmp/deerwester.mm')\n",
    "    print(\"Used files generated from first tutorial\")\n",
    "else:\n",
    "    print(\"Please run first tutorial to generate data set\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0), (1, 1.0), (2, 1.0)]\n",
      "[(0, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(2, 1.0), (5, 1.0), (7, 1.0), (8, 1.0)]\n",
      "[(1, 1.0), (5, 2.0), (8, 1.0)]\n",
      "[(3, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(9, 1.0)]\n",
      "[(9, 1.0), (10, 1.0)]\n",
      "[(9, 1.0), (10, 1.0), (11, 1.0)]\n",
      "[(4, 1.0), (10, 1.0), (11, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "for d in corpus:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "scipy_csc_matrix = matutils.corpus2csc(corpus)\n",
    "print(scipy_csc_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budujemy model LDA\n",
    "Budujemy model LDA i transformujemy dane\n",
    "\n",
    "* **num_topics=2** oznacza ilość modelowanych tematów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.83729), (1, 0.16271001)]\n",
      "[(0, 0.90050095), (1, 0.09949899)]\n",
      "[(0, 0.19252324), (1, 0.80747676)]\n",
      "[(0, 0.12373279), (1, 0.8762672)]\n",
      "[(0, 0.8622306), (1, 0.13776943)]\n",
      "[(0, 0.3121528), (1, 0.6878472)]\n",
      "[(0, 0.19222331), (1, 0.8077767)]\n",
      "[(0, 0.14043865), (1, 0.8595613)]\n",
      "[(0, 0.15467012), (1, 0.8453299)]\n"
     ]
    }
   ],
   "source": [
    "model = models.LdaModel(corpus, id2word=dictionary, num_topics=2)\n",
    "corpus_lda = model[corpus] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
    "for d in corpus_lda:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dla każdego dokumentu dostajemy prawdopodobieństwo przynależności dokumentu do danego tematu.\n",
    "\n",
    "Możemy też zobaczyć z czego składają się tematy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.124*\"user\" + 0.122*\"computer\" + 0.120*\"response\" + 0.115*\"time\" + 0.082*\"system\" + 0.082*\"interface\" + 0.078*\"survey\" + 0.077*\"human\" + 0.076*\"trees\" + 0.050*\"graph\"'),\n",
       " (1,\n",
       "  '0.157*\"system\" + 0.139*\"graph\" + 0.116*\"trees\" + 0.108*\"eps\" + 0.103*\"minors\" + 0.074*\"user\" + 0.070*\"human\" + 0.069*\"survey\" + 0.066*\"interface\" + 0.037*\"time\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Chcemy postortowac słowa każdego tematu i wybrać 5 najważniejszych - co można powiedzieć o tematach?\n",
    "\n",
    "Proszę zobaczyć na funkcje typu get_topics(), get_term_topics(...): https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "computer\n",
      "response\n",
      "time\n",
      "system\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "topics = np.argsort(model.get_topics()[0,:])[::-1] #::-1 sortowanie w odwrotnej kolejności\n",
    "for x in topics[:5]:\n",
    "    print(dictionary[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 0.124267705),\n",
       " (0, 0.12216605),\n",
       " (3, 0.12027098),\n",
       " (6, 0.11450522),\n",
       " (5, 0.08195062),\n",
       " (2, 0.081943735),\n",
       " (4, 0.078475155),\n",
       " (1, 0.077084005),\n",
       " (9, 0.07631046),\n",
       " (10, 0.050397925)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_topic_terms(topicid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 0.124267705),\n",
       " ('computer', 0.12216605),\n",
       " ('response', 0.12027098),\n",
       " ('time', 0.11450522),\n",
       " ('system', 0.08195062),\n",
       " ('interface', 0.081943735),\n",
       " ('survey', 0.078475155),\n",
       " ('human', 0.077084005),\n",
       " ('trees', 0.07631046),\n",
       " ('graph', 0.050397925)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic2_terms = model.get_topic_terms(topicid=0)\n",
    "topic2_words = [\n",
    "    (dictionary.get(i), j)\n",
    "    for i,j in topic2_terms\n",
    "]\n",
    "topic2_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('user', 0.124267705),\n",
       " ('computer', 0.12216605),\n",
       " ('response', 0.12027098),\n",
       " ('time', 0.11450522),\n",
       " ('system', 0.08195062),\n",
       " ('interface', 0.081943735),\n",
       " ('survey', 0.078475155),\n",
       " ('human', 0.077084005),\n",
       " ('trees', 0.07631046),\n",
       " ('graph', 0.050397925)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    (dictionary.get(i), j)\n",
    "    for i,j in model.get_topic_terms(topicid=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "\n",
    "Proszę posortować zdania najbardziej pasujące do danego tematu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(3, 1.0), (6, 1.0), (7, 1.0)]\n",
      "[(0, 1.0), (1, 1.0), (2, 1.0)]\n",
      "[(9, 1.0)]\n",
      "[(2, 1.0), (5, 1.0), (7, 1.0), (8, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# for d in corpus_lda:\n",
    "#     print(d)\n",
    "    \n",
    "# for d in corpus_lda:\n",
    "#     print(d[0])\n",
    "\n",
    "#print(corpus_lda[0][0])\n",
    "\n",
    "numpy_corpus = gensim.matutils.corpus2dense(corpus_lda, num_terms=2)\n",
    "docs = np.argsort(numpy_corpus[0,:])[::-1]\n",
    "for x in docs[:5]:\n",
    "    print(corpus[x])\n",
    "    \n",
    "#trzeba by wypisać raczej zdania niż ich reprezentacje bag-of-words, ale tu nie mam dostepu do tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad. \n",
    "Sprawdzić do jakiego tematu pasuje nowy dokument i jakie są mu najbliższe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = \"Human computer interaction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7407068), (1, 0.25929314)]\n"
     ]
    }
   ],
   "source": [
    "doc_rep = dictionary.doc2bow(doc.split(' '))\n",
    "# print(doc_rep)\n",
    "doc_assignments = model[doc_rep]\n",
    "print(doc_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.9895207), (1, 0.9744165), (2, 0.54026634), (3, 0.4591714), (4, 0.98414946), (5, 0.69093746), (6, 0.53994584), (7, 0.47826633), (8, 0.49494594)]\n",
      "[(0, 0.9895207), (4, 0.98414946), (1, 0.9744165), (5, 0.69093746), (2, 0.54026634), (6, 0.53994584), (8, 0.49494594), (7, 0.47826633), (3, 0.4591714)]\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(corpus_lda)\n",
    "\n",
    "sims = index[doc_assignments]\n",
    "print(list(enumerate(sims)))\n",
    "\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Wizualizacja modelu LDA:\n",
    "\n",
    "pyLDAvis\n",
    "\n",
    "http://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb\n",
    "\n",
    "http://www.kennyshirley.com/LDAvis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pyLDAvis.gensim.prepare??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el20167822422101047232715018\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el20167822422101047232715018_data = {\"mdsDat\": {\"x\": [0.03953085467219353, -0.03953085467219353], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [53.969139099121094, 46.030860900878906]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 1.6853241920471191, 2.1708829402923584, 1.611535906791687, 2.454820156097412, 1.817078948020935, 1.0917688608169556, 1.0727745294570923, 1.0254136323928833, 1.1622852087020874, 0.580829381942749, 0.5021064281463623, 0.4762316942214966, 1.6307883262634277, 1.6054911613464355, 1.5285242795944214, 1.6588431596755981, 1.0938626527786255, 1.0475608110427856, 1.028990387916565, 1.0186643600463867, 1.0939545631408691, 0.520824670791626, 0.6727592945098877, 0.44868481159210205], \"Term\": [\"computer\", \"response\", \"time\", \"eps\", \"graph\", \"user\", \"minors\", \"system\", \"interface\", \"trees\", \"survey\", \"human\", \"eps\", \"graph\", \"minors\", \"system\", \"trees\", \"human\", \"survey\", \"interface\", \"user\", \"time\", \"response\", \"computer\", \"computer\", \"response\", \"time\", \"user\", \"interface\", \"survey\", \"human\", \"trees\", \"system\", \"minors\", \"graph\", \"eps\"], \"Total\": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.1340088844299316, 2.843642234802246, 2.1323604583740234, 3.5487747192382812, 2.8357434272766113, 2.1207592487335205, 2.120335340499878, 2.119276285171509, 2.8211283683776855, 2.109353542327881, 2.107597589492798, 2.1070199012756348, 2.1070199012756348, 2.107597589492798, 2.109353542327881, 2.8211283683776855, 2.119276285171509, 2.120335340499878, 2.1207592487335205, 2.8357434272766113, 3.5487747192382812, 2.1323604583740234, 2.843642234802246, 2.1340088844299316], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3806999921798706, 0.3467999994754791, 0.3366999924182892, 0.24819999933242798, 0.17170000076293945, -0.047200001776218414, -0.06459999829530716, -0.10920000076293945, -0.27000001072883606, -0.6729000210762024, -0.8177000284194946, -0.8704000115394592, 0.519599974155426, 0.5037000179290771, 0.4537999927997589, 0.24480000138282776, 0.1145000010728836, 0.07069999724626541, 0.05270000174641609, -0.24799999594688416, -0.4009000062942505, -0.6337000131607056, -0.6656000018119812, -0.7835999727249146], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.228600025177002, -1.9753999710083008, -2.273400068283081, -1.8524999618530273, -2.1533000469207764, -2.6626999378204346, -2.680299997329712, -2.725399971008301, -2.600100040435791, -3.293800115585327, -3.439500093460083, -3.4923999309539795, -2.102400064468384, -2.118000030517578, -2.167099952697754, -2.0852999687194824, -2.501699924468994, -2.5450000762939453, -2.5629000663757324, -2.5729000568389893, -2.5016000270843506, -3.243799924850464, -2.987799882888794, -3.392899990081787]}, \"token.table\": {\"Topic\": [2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.9492079019546509, 0.9372032284736633, 0.7033233642578125, 0.35166168212890625, 0.4715292453765869, 0.4715292453765869, 0.4718591868877411, 0.4718591868877411, 0.9379277229309082, 0.4689638614654541, 0.47447386384010315, 0.9489477276802063, 0.4716235101222992, 0.4716235101222992, 0.5635747909545898, 0.2817873954772949, 0.474078893661499, 0.948157787322998, 0.70528244972229, 0.352641224861145, 0.35446810722351074, 0.7089362144470215], \"Term\": [\"computer\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"]}, \"R\": 12, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el20167822422101047232715018\", ldavis_el20167822422101047232715018_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el20167822422101047232715018\", ldavis_el20167822422101047232715018_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el20167822422101047232715018\", ldavis_el20167822422101047232715018_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "1      0.039531  0.0       1        1  53.969139\n",
       "0     -0.039531  0.0       2        1  46.030861, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "0     Default  2.000000   computer  2.000000  12.0000  12.0000\n",
       "3     Default  2.000000   response  2.000000  11.0000  11.0000\n",
       "6     Default  2.000000       time  2.000000  10.0000  10.0000\n",
       "8     Default  2.000000        eps  2.000000   9.0000   9.0000\n",
       "10    Default  2.000000      graph  2.000000   8.0000   8.0000\n",
       "7     Default  2.000000       user  2.000000   7.0000   7.0000\n",
       "11    Default  2.000000     minors  2.000000   6.0000   6.0000\n",
       "5     Default  3.000000     system  3.000000   5.0000   5.0000\n",
       "2     Default  2.000000  interface  2.000000   4.0000   4.0000\n",
       "9     Default  2.000000      trees  2.000000   3.0000   3.0000\n",
       "4     Default  2.000000     survey  2.000000   2.0000   2.0000\n",
       "1     Default  2.000000      human  2.000000   1.0000   1.0000\n",
       "8      Topic1  1.685324        eps  2.134009   0.3807  -2.2286\n",
       "10     Topic1  2.170883      graph  2.843642   0.3468  -1.9754\n",
       "11     Topic1  1.611536     minors  2.132360   0.3367  -2.2734\n",
       "5      Topic1  2.454820     system  3.548775   0.2482  -1.8525\n",
       "9      Topic1  1.817079      trees  2.835743   0.1717  -2.1533\n",
       "1      Topic1  1.091769      human  2.120759  -0.0472  -2.6627\n",
       "4      Topic1  1.072775     survey  2.120335  -0.0646  -2.6803\n",
       "2      Topic1  1.025414  interface  2.119276  -0.1092  -2.7254\n",
       "7      Topic1  1.162285       user  2.821128  -0.2700  -2.6001\n",
       "6      Topic1  0.580829       time  2.109354  -0.6729  -3.2938\n",
       "3      Topic1  0.502106   response  2.107598  -0.8177  -3.4395\n",
       "0      Topic1  0.476232   computer  2.107020  -0.8704  -3.4924\n",
       "0      Topic2  1.630788   computer  2.107020   0.5196  -2.1024\n",
       "3      Topic2  1.605491   response  2.107598   0.5037  -2.1180\n",
       "6      Topic2  1.528524       time  2.109354   0.4538  -2.1671\n",
       "7      Topic2  1.658843       user  2.821128   0.2448  -2.0853\n",
       "2      Topic2  1.093863  interface  2.119276   0.1145  -2.5017\n",
       "4      Topic2  1.047561     survey  2.120335   0.0707  -2.5450\n",
       "1      Topic2  1.028990      human  2.120759   0.0527  -2.5629\n",
       "9      Topic2  1.018664      trees  2.835743  -0.2480  -2.5729\n",
       "5      Topic2  1.093955     system  3.548775  -0.4009  -2.5016\n",
       "11     Topic2  0.520825     minors  2.132360  -0.6337  -3.2438\n",
       "10     Topic2  0.672759      graph  2.843642  -0.6656  -2.9878\n",
       "8      Topic2  0.448685        eps  2.134009  -0.7836  -3.3929, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "0         2  0.949208   computer\n",
       "8         1  0.937203        eps\n",
       "10        1  0.703323      graph\n",
       "10        2  0.351662      graph\n",
       "1         1  0.471529      human\n",
       "1         2  0.471529      human\n",
       "2         1  0.471859  interface\n",
       "2         2  0.471859  interface\n",
       "11        1  0.937928     minors\n",
       "11        2  0.468964     minors\n",
       "3         1  0.474474   response\n",
       "3         2  0.948948   response\n",
       "4         1  0.471624     survey\n",
       "4         2  0.471624     survey\n",
       "5         1  0.563575     system\n",
       "5         2  0.281787     system\n",
       "6         1  0.474079       time\n",
       "6         2  0.948158       time\n",
       "9         1  0.705282      trees\n",
       "9         2  0.352641      trees\n",
       "7         1  0.354468       user\n",
       "7         2  0.708936       user, R=12, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(model, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
