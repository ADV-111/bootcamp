{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.5346 - accuracy: 0.7582 - val_loss: 0.5090 - val_accuracy: 0.7913\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.4942 - accuracy: 0.7785 - val_loss: 0.4718 - val_accuracy: 0.7841\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 60us/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.4210 - val_accuracy: 0.7966\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.4021 - accuracy: 0.8134 - val_loss: 0.3842 - val_accuracy: 0.8238\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3758 - accuracy: 0.8324 - val_loss: 0.3649 - val_accuracy: 0.8386\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 1s 43us/step - loss: 0.3622 - accuracy: 0.8393 - val_loss: 0.3561 - val_accuracy: 0.8365\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 1s 43us/step - loss: 0.3551 - accuracy: 0.8421 - val_loss: 0.3515 - val_accuracy: 0.8402\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 1s 42us/step - loss: 0.3501 - accuracy: 0.8435 - val_loss: 0.3492 - val_accuracy: 0.8370\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 1s 42us/step - loss: 0.3466 - accuracy: 0.8435 - val_loss: 0.3458 - val_accuracy: 0.8414\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 1s 42us/step - loss: 0.3433 - accuracy: 0.8454 - val_loss: 0.3434 - val_accuracy: 0.8451\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 1s 43us/step - loss: 0.3417 - accuracy: 0.8459 - val_loss: 0.3417 - val_accuracy: 0.8420\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 1s 41us/step - loss: 0.3403 - accuracy: 0.8466 - val_loss: 0.3401 - val_accuracy: 0.8433\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 1s 44us/step - loss: 0.3392 - accuracy: 0.8463 - val_loss: 0.3384 - val_accuracy: 0.8435\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 1s 42us/step - loss: 0.3379 - accuracy: 0.8472 - val_loss: 0.3385 - val_accuracy: 0.8406\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.3365 - accuracy: 0.8470 - val_loss: 0.3368 - val_accuracy: 0.8457\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 1s 42us/step - loss: 0.3354 - accuracy: 0.8460 - val_loss: 0.3353 - val_accuracy: 0.8446\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 1s 41us/step - loss: 0.3345 - accuracy: 0.8475 - val_loss: 0.3347 - val_accuracy: 0.8446\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 1s 44us/step - loss: 0.3334 - accuracy: 0.8482 - val_loss: 0.3339 - val_accuracy: 0.8424\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.3321 - accuracy: 0.8483 - val_loss: 0.3327 - val_accuracy: 0.8454\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 1s 43us/step - loss: 0.3302 - accuracy: 0.8491 - val_loss: 0.3305 - val_accuracy: 0.8461\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3295 - accuracy: 0.8499 - val_loss: 0.3307 - val_accuracy: 0.8454\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 1s 44us/step - loss: 0.3291 - accuracy: 0.8495 - val_loss: 0.3302 - val_accuracy: 0.8462\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3285 - accuracy: 0.8497 - val_loss: 0.3296 - val_accuracy: 0.8477\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3282 - accuracy: 0.8497 - val_loss: 0.3324 - val_accuracy: 0.8453\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 1s 47us/step - loss: 0.3280 - accuracy: 0.8496 - val_loss: 0.3308 - val_accuracy: 0.8432\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3273 - accuracy: 0.8506 - val_loss: 0.3296 - val_accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3271 - accuracy: 0.8506 - val_loss: 0.3289 - val_accuracy: 0.8487\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 1s 44us/step - loss: 0.3265 - accuracy: 0.8513 - val_loss: 0.3281 - val_accuracy: 0.8467\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.3266 - accuracy: 0.8504 - val_loss: 0.3289 - val_accuracy: 0.8454\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3257 - accuracy: 0.8509 - val_loss: 0.3274 - val_accuracy: 0.8479\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.3255 - accuracy: 0.8510 - val_loss: 0.3273 - val_accuracy: 0.8470\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 1s 47us/step - loss: 0.3252 - accuracy: 0.8510 - val_loss: 0.3271 - val_accuracy: 0.8489\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 1s 47us/step - loss: 0.3253 - accuracy: 0.8510 - val_loss: 0.3270 - val_accuracy: 0.8480\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 1s 47us/step - loss: 0.3250 - accuracy: 0.8507 - val_loss: 0.3282 - val_accuracy: 0.8476\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 1s 47us/step - loss: 0.3249 - accuracy: 0.8512 - val_loss: 0.3269 - val_accuracy: 0.8483\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3246 - accuracy: 0.8510 - val_loss: 0.3268 - val_accuracy: 0.8487\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.3246 - accuracy: 0.8513 - val_loss: 0.3269 - val_accuracy: 0.8484\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.3244 - accuracy: 0.8514 - val_loss: 0.3272 - val_accuracy: 0.8463\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 1s 46us/step - loss: 0.3243 - accuracy: 0.8514 - val_loss: 0.3262 - val_accuracy: 0.8476\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 1s 43us/step - loss: 0.3238 - accuracy: 0.8517 - val_loss: 0.3283 - val_accuracy: 0.8486\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3238 - accuracy: 0.8515 - val_loss: 0.3261 - val_accuracy: 0.8478\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3238 - accuracy: 0.8509 - val_loss: 0.3259 - val_accuracy: 0.8491loss: 0.3267 \n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 1s 44us/step - loss: 0.3237 - accuracy: 0.8513 - val_loss: 0.3259 - val_accuracy: 0.8479\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3236 - accuracy: 0.8516 - val_loss: 0.3256 - val_accuracy: 0.8489\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3236 - accuracy: 0.8517 - val_loss: 0.3256 - val_accuracy: 0.8493\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3235 - accuracy: 0.8518 - val_loss: 0.3259 - val_accuracy: 0.8497\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 1s 45us/step - loss: 0.3234 - accuracy: 0.8518 - val_loss: 0.3257 - val_accuracy: 0.8482\n",
      "Epoch 00047: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e73ab7aeb8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "save_best_model = ModelCheckpoint(\"wagi_best.h5py\",save_best_only=True)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, save_best_model, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam 0.0001 LR\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam 0.0001 LR\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15060/15060 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3283151268127905, 0.8461487293243408]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"wagi_best.h5py\")\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do poniższych danych dobierz paametr\n",
    "```python\n",
    "patience=\n",
    "```\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_200 (Dense)            (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.6985 - accuracy: 0.5472 - val_loss: 0.8858 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.7412 - accuracy: 0.5472 - val_loss: 0.6784 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.6562 - accuracy: 0.5283 - val_loss: 0.6618 - val_accuracy: 0.5532\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.4528 - val_loss: 0.6270 - val_accuracy: 0.6596\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.6129 - accuracy: 0.7170 - val_loss: 0.6530 - val_accuracy: 0.5106\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.6002 - accuracy: 0.5660 - val_loss: 0.6733 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.5957 - accuracy: 0.5472 - val_loss: 0.5947 - val_accuracy: 0.7660\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.5117 - accuracy: 0.8302 - val_loss: 0.5333 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.4782 - accuracy: 0.8679 - val_loss: 0.5425 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.4790 - accuracy: 0.7925 - val_loss: 0.5287 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.4254 - accuracy: 0.8113 - val_loss: 0.4855 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3814 - accuracy: 0.8491 - val_loss: 0.4674 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3686 - accuracy: 0.8302 - val_loss: 0.4661 - val_accuracy: 0.7660\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3540 - accuracy: 0.8302 - val_loss: 0.4727 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3351 - accuracy: 0.8491 - val_loss: 0.4956 - val_accuracy: 0.7447\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3298 - accuracy: 0.8491 - val_loss: 0.5339 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.3135 - accuracy: 0.8679 - val_loss: 0.5541 - val_accuracy: 0.7660\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3096 - accuracy: 0.8679 - val_loss: 0.5555 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2993 - accuracy: 0.8679 - val_loss: 0.5364 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2912 - accuracy: 0.8679 - val_loss: 0.5133 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2856 - accuracy: 0.8868 - val_loss: 0.4904 - val_accuracy: 0.8085\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2762 - accuracy: 0.8868 - val_loss: 0.4820 - val_accuracy: 0.8085\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2666 - accuracy: 0.8868 - val_loss: 0.4742 - val_accuracy: 0.8085\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2589 - accuracy: 0.8868 - val_loss: 0.4693 - val_accuracy: 0.8085\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2532 - accuracy: 0.8868 - val_loss: 0.4641 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2507 - accuracy: 0.9057 - val_loss: 0.4628 - val_accuracy: 0.8085\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.2467 - accuracy: 0.9057 - val_loss: 0.4537 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2434 - accuracy: 0.9057 - val_loss: 0.4381 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9057 - val_loss: 0.4334 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2389 - accuracy: 0.9057 - val_loss: 0.4379 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.9057 - val_loss: 0.4453 - val_accuracy: 0.8085\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2325 - accuracy: 0.9057 - val_loss: 0.4629 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.8868 - val_loss: 0.4754 - val_accuracy: 0.8298\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2294 - accuracy: 0.8868 - val_loss: 0.4793 - val_accuracy: 0.8298\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2225 - accuracy: 0.8868 - val_loss: 0.4959 - val_accuracy: 0.8085\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2210 - accuracy: 0.9057 - val_loss: 0.5103 - val_accuracy: 0.8085\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2288 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.8085\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2215 - accuracy: 0.9057 - val_loss: 0.4957 - val_accuracy: 0.8085\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2193 - accuracy: 0.9057 - val_loss: 0.4797 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2150 - accuracy: 0.8868 - val_loss: 0.4826 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2136 - accuracy: 0.9057 - val_loss: 0.4817 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2089 - accuracy: 0.9057 - val_loss: 0.4942 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2061 - accuracy: 0.8868 - val_loss: 0.5084 - val_accuracy: 0.8085\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2083 - accuracy: 0.9245 - val_loss: 0.5196 - val_accuracy: 0.8085\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2079 - accuracy: 0.9245 - val_loss: 0.5036 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2039 - accuracy: 0.9057 - val_loss: 0.4872 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2003 - accuracy: 0.9057 - val_loss: 0.4772 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2004 - accuracy: 0.9245 - val_loss: 0.4696 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1964 - accuracy: 0.9245 - val_loss: 0.4565 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1975 - accuracy: 0.9057 - val_loss: 0.4458 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1965 - accuracy: 0.9057 - val_loss: 0.4518 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1930 - accuracy: 0.9245 - val_loss: 0.4589 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1896 - accuracy: 0.9245 - val_loss: 0.4718 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1915 - accuracy: 0.9245 - val_loss: 0.4864 - val_accuracy: 0.8085\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1910 - accuracy: 0.9057 - val_loss: 0.4760 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1859 - accuracy: 0.9057 - val_loss: 0.4652 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1836 - accuracy: 0.9245 - val_loss: 0.4543 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1859 - accuracy: 0.9245 - val_loss: 0.4378 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1817 - accuracy: 0.9245 - val_loss: 0.4414 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1799 - accuracy: 0.9245 - val_loss: 0.4522 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1787 - accuracy: 0.9245 - val_loss: 0.4585 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1759 - accuracy: 0.9434 - val_loss: 0.4506 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1754 - accuracy: 0.9245 - val_loss: 0.4413 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1750 - accuracy: 0.9245 - val_loss: 0.4370 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1717 - accuracy: 0.9434 - val_loss: 0.4513 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1699 - accuracy: 0.9434 - val_loss: 0.4529 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1667 - accuracy: 0.9434 - val_loss: 0.4433 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1643 - accuracy: 0.9434 - val_loss: 0.4299 - val_accuracy: 0.8298\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1631 - accuracy: 0.9245 - val_loss: 0.4259 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1658 - accuracy: 0.9245 - val_loss: 0.4254 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.9245 - val_loss: 0.4131 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1598 - accuracy: 0.9434 - val_loss: 0.4210 - val_accuracy: 0.8298\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1559 - accuracy: 0.9434 - val_loss: 0.4203 - val_accuracy: 0.8298\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9434 - val_loss: 0.4300 - val_accuracy: 0.8298\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1543 - accuracy: 0.9811 - val_loss: 0.4398 - val_accuracy: 0.8298\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1501 - accuracy: 0.9623 - val_loss: 0.4249 - val_accuracy: 0.8298\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.1474 - accuracy: 0.9623 - val_loss: 0.4095 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1448 - accuracy: 0.9623 - val_loss: 0.4033 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1443 - accuracy: 0.9434 - val_loss: 0.3996 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1408 - accuracy: 0.9623 - val_loss: 0.4051 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1383 - accuracy: 0.9623 - val_loss: 0.4230 - val_accuracy: 0.8511\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1379 - accuracy: 0.9811 - val_loss: 0.4192 - val_accuracy: 0.8511\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1365 - accuracy: 0.9811 - val_loss: 0.4075 - val_accuracy: 0.8511\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1321 - accuracy: 0.9811 - val_loss: 0.3791 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1268 - accuracy: 0.9811 - val_loss: 0.3463 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1275 - accuracy: 0.9434 - val_loss: 0.3239 - val_accuracy: 0.8511\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1325 - accuracy: 0.9245 - val_loss: 0.3126 - val_accuracy: 0.8511\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1360 - accuracy: 0.9245 - val_loss: 0.3144 - val_accuracy: 0.8511\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1188 - accuracy: 0.9434 - val_loss: 0.3484 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.1304 - accuracy: 0.9811 - val_loss: 0.4049 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.9623 - val_loss: 0.3930 - val_accuracy: 0.8936\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1240 - accuracy: 0.9623 - val_loss: 0.3592 - val_accuracy: 0.8936\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1104 - accuracy: 0.9811 - val_loss: 0.3309 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.1109 - accuracy: 0.9811 - val_loss: 0.3032 - val_accuracy: 0.8511\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1119 - accuracy: 0.9623 - val_loss: 0.2955 - val_accuracy: 0.8511\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1085 - accuracy: 0.9623 - val_loss: 0.3125 - val_accuracy: 0.8723\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1008 - accuracy: 0.9811 - val_loss: 0.3216 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0993 - accuracy: 0.9811 - val_loss: 0.3253 - val_accuracy: 0.8936\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0993 - accuracy: 0.9811 - val_loss: 0.3136 - val_accuracy: 0.8936\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0953 - accuracy: 0.9811 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0915 - accuracy: 0.9811 - val_loss: 0.2723 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.0931 - accuracy: 0.9811 - val_loss: 0.2575 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0883 - accuracy: 0.9811 - val_loss: 0.2644 - val_accuracy: 0.8723\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0885 - accuracy: 0.9811 - val_loss: 0.2804 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0824 - accuracy: 0.9811 - val_loss: 0.2721 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0808 - accuracy: 0.9811 - val_loss: 0.2523 - val_accuracy: 0.8936\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 809us/step - loss: 0.0767 - accuracy: 0.9811 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0785 - accuracy: 0.9811 - val_loss: 0.2333 - val_accuracy: 0.9149\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0729 - accuracy: 0.9811 - val_loss: 0.2176 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0763 - accuracy: 0.9811 - val_loss: 0.2107 - val_accuracy: 0.8936\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0741 - accuracy: 0.9811 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0667 - accuracy: 0.9811 - val_loss: 0.2318 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0657 - accuracy: 0.9811 - val_loss: 0.2249 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0622 - accuracy: 0.9811 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 0.2132 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.8936\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.8936\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0501 - accuracy: 0.9811 - val_loss: 0.2264 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0516 - accuracy: 0.9811 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0488 - accuracy: 0.9811 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9362\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.8936\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.8936\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9149\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9362\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9362\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9362\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9362\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9362\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9362\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9362\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9362\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9362\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9362\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9362\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.8936\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9362\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9149\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9149\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.8936\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.8936\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9149\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9362\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9149\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9362\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9362\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.8936\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9149\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9362\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9362\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.8936\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9362\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.8936\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9149\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9149\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1801 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9362\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.9149\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9149\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1830 - val_accuracy: 0.9149\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9149\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9362\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9362\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9362\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9362\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9362\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9362\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9362\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9362\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9362\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9362\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9362\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9362\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9362\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9362\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 790us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9362\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9149\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9149\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9149\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9149\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9362\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9149\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9149\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9149\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9149\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9149\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9149\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9362\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9149\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9149\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9149\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9149\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9149\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9149\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 978us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 0.9149\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9149\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9149\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2007 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2006 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9149\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9149\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9149\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9149\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9149\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2066 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2270 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 772us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2492 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.9855e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 9.9867e-04 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 9.9002e-04 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 9.5224e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 9.3830e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 9.6917e-04 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 9.7703e-04 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 9.4144e-04 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 9.2330e-04 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 9.8469e-04 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 9.3438e-04 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 9.2808e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 9.0961e-04 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.3921e-04 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.1677e-04 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 9.3456e-04 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 8.8433e-04 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.8122e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.7585e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.8645e-04 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.6635e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.7366e-04 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.6265e-04 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.6727e-04 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.8609e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 8.5393e-04 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.7711e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 8.6243e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 8.3513e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.2796e-04 - accuracy: 1.0000 - val_loss: 0.2662 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.5942e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.5605e-04 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.1544e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.1286e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.0774e-04 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.1766e-04 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.0440e-04 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.9801e-04 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.4405e-04 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.1353e-04 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.7472e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.8243e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.0188e-04 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.3707e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.1059e-04 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.8828e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.1374e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.0084e-04 - accuracy: 1.0000 - val_loss: 0.2729 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.6327e-04 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.8847e-04 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.5510e-04 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.4445e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.4382e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 7.4078e-04 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 7.3330e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 7.2875e-04 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.2239e-04 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 7.3076e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 7.5302e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 7.1976e-04 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 7.0945e-04 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 7.3016e-04 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.2189e-04 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.9883e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.9641e-04 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.1279e-04 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.9232e-04 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.8962e-04 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 7.2109e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 7.0407e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 6.8456e-04 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 6.7315e-04 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.7320e-04 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.7771e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 6.7522e-04 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 6.8673e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 6.7337e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.5473e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 6.5378e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 6.5099e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 6.6410e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 6.5139e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 6.4261e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.4002e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.5132e-04 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.5196e-04 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.4553e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.3170e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.1585e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 6.7511e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.5912e-04 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.2955e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.1736e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.0978e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 6.0421e-04 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.0520e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 6.1802e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.2970e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.1621e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 5.9874e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.8827e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.8792e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.9161e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.0198e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.8641e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.8247e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.9655e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 5.8374e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.7020e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.9733e-04 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.8661e-04 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.8744e-04 - accuracy: 1.0000 - val_loss: 0.2842 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.7705e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.5532e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.5295e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.5050e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.4788e-04 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.5582e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.4337e-04 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.4161e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.4110e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.4969e-04 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.5404e-04 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.3650e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.2875e-04 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.4497e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.3855e-04 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.3710e-04 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.2120e-04 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 5.3449e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.2363e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.1385e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.1255e-04 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.1643e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.2144e-04 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.3103e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.3573e-04 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.2006e-04 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9898e-04 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.0796e-04 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.9480e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 4.9556e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9090e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9212e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.2027e-04 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 5.1550e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9161e-04 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 4.7754e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 5.0726e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.8434e-04 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9689e-04 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.8261e-04 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.7204e-04 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 4.8891e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 4.8224e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.6904e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.8116e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 4.7362e-04 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.6102e-04 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.5758e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 4.5653e-04 - accuracy: 1.0000 - val_loss: 0.2910 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.6905e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.5624e-04 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.5163e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4907e-04 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4846e-04 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.5418e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.5004e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4543e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4696e-04 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4618e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 4.5311e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 4.4751e-04 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 4.3653e-04 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 4.3322e-04 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4787e-04 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.3347e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.3408e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.4428e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.3784e-04 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.2460e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.2462e-04 - accuracy: 1.0000 - val_loss: 0.2982 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 4.2065e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.3893e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.2313e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 4.1966e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 4.1515e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.1261e-04 - accuracy: 1.0000 - val_loss: 0.3007 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 4.1385e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 4.1526e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 4.1851e-04 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 4.2395e-04 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 4.2702e-04 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 4.3171e-04 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 4.0227e-04 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 4.1643e-04 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.0138e-04 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9896e-04 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9628e-04 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9391e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9191e-04 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 4.0066e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 4.0137e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8817e-04 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8671e-04 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9244e-04 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8408e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9423e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.9217e-04 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8009e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8507e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.7964e-04 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.7653e-04 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 3.7720e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 3.8644e-04 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.7686e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.6984e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.6726e-04 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 940us/step - loss: 3.7099e-04 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 3.9247e-04 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.8002e-04 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.7054e-04 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 3.6414e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 3.7549e-04 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 3.6885e-04 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 3.5946e-04 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 3.5701e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.5799e-04 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 3.5705e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.5776e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.5680e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.6265e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 3.5050e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.4897e-04 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.5442e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.4551e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.4940e-04 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.5320e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.4837e-04 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.4201e-04 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.3956e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 3.3763e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 3.4037e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.5636e-04 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.4611e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.3750e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.4867e-04 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 3.3234e-04 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.4543e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.4027e-04 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.3593e-04 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.3718e-04 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.2978e-04 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.3938e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 3.2533e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.2241e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.3381e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.2325e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.2098e-04 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.1764e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.1735e-04 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.2850e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.2325e-04 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.2620e-04 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.1450e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.1065e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.1017e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.1076e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.1735e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.0983e-04 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.0256e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.0442e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.0750e-04 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.2482e-04 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.1250e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.0371e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.1720e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.9821e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.9910e-04 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.0554e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.1233e-04 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.0439e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.9622e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.9000e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.9144e-04 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.0633e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.0113e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.9408e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8456e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8621e-04 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.8698e-04 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.0509e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 3.0107e-04 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8960e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8618e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8261e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.7757e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8186e-04 - accuracy: 1.0000 - val_loss: 0.3174 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.8276e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.8946e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8254e-04 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.7507e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.7019e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7370e-04 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7822e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.8377e-04 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.8314e-04 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8084e-04 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7345e-04 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.6783e-04 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6680e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6807e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7043e-04 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7120e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6956e-04 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.7231e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6319e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6398e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6063e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5993e-04 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6912e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.6079e-04 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5959e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 2.5664e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 2.5649e-04 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5455e-04 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5475e-04 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5458e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5812e-04 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5802e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.5595e-04 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.5288e-04 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.5017e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.4864e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.5666e-04 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5110e-04 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4737e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5223e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4749e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.4365e-04 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4176e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4150e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4487e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4894e-04 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4820e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5161e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4308e-04 - accuracy: 1.0000 - val_loss: 0.3251 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5060e-04 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3716e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4553e-04 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4309e-04 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3692e-04 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.3537e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3578e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4064e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3702e-04 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.3151e-04 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3046e-04 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2956e-04 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 2.2890e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 2.2815e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.2777e-04 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3041e-04 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2650e-04 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.2553e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.3039e-04 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 2.2464e-04 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 2.2392e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.2411e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.2222e-04 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2202e-04 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.2319e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.2580e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2498e-04 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.2267e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.2615e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.2168e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.1688e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.1662e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.2526e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.2106e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2155e-04 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.1591e-04 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.2040e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1418e-04 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1207e-04 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1222e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 2.1241e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.1267e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1511e-04 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1697e-04 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1281e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.1064e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0813e-04 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0591e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.1393e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0766e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0862e-04 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0542e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0240e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0289e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0385e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0606e-04 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0474e-04 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0480e-04 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.0361e-04 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0085e-04 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9149\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9982e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9149\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.0349e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9149\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0104e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9149\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9819e-04 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9653e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9627e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9643e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9666e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9622e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9652e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9935e-04 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9263e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.9220e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9192e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9135e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9075e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9232e-04 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9429e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9184e-04 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8831e-04 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8792e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8750e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8705e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8675e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 1.8614e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8864e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8466e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8636e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8390e-04 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.8504e-04 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8338e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.8483e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8309e-04 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8309e-04 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.8263e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.8162e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9149\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.8051e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 1.7965e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.8004e-04 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 1.7857e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.7892e-04 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8217e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.7906e-04 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7676e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8174e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.7634e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.7597e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.7769e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.7460e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.7632e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.7376e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.7556e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.7295e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.7597e-04 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.7301e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 1.7027e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6856e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.7082e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.7250e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.8034e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 1.7623e-04 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.7310e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.7416e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 1.6778e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9149\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 1.6758e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9149\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 1.6654e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9149\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.7081e-04 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9149\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.6677e-04 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9149\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6574e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9149\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 1.6860e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6665e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 1.6369e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6344e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6458e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6331e-04 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6270e-04 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6377e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 1.6296e-04 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 1.6253e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 1.6276e-04 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9149\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.6470e-04 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9149\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.6096e-04 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 1.6419e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.5845e-04 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.5805e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.5767e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.5747e-04 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 1.5889e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9149\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 1.5679e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.5601e-04 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 1.5544e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.6062e-04 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e7657be7f0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
