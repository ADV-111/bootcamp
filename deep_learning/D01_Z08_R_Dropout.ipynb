{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15060, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.6746 - accuracy: 0.5950 - val_loss: 0.5647 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.5823 - accuracy: 0.7357 - val_loss: 0.5447 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.5513 - accuracy: 0.7490 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.4870 - accuracy: 0.7819 - val_loss: 0.4240 - val_accuracy: 0.8254\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.4442 - accuracy: 0.8060 - val_loss: 0.3936 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.4260 - accuracy: 0.8121 - val_loss: 0.3789 - val_accuracy: 0.8374\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4108 - accuracy: 0.8183 - val_loss: 0.3698 - val_accuracy: 0.8384\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.4020 - accuracy: 0.8189 - val_loss: 0.3636 - val_accuracy: 0.8364\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3947 - accuracy: 0.8215 - val_loss: 0.3590 - val_accuracy: 0.8373\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 1s 50us/step - loss: 0.3911 - accuracy: 0.8213 - val_loss: 0.3571 - val_accuracy: 0.8374\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3901 - accuracy: 0.8230 - val_loss: 0.3555 - val_accuracy: 0.8376\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3871 - accuracy: 0.8215 - val_loss: 0.3539 - val_accuracy: 0.8381\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3897 - accuracy: 0.8212 - val_loss: 0.3528 - val_accuracy: 0.8390\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.3836 - accuracy: 0.8229 - val_loss: 0.3515 - val_accuracy: 0.8386\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 50us/step - loss: 0.3808 - accuracy: 0.8273 - val_loss: 0.3502 - val_accuracy: 0.8383\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3794 - accuracy: 0.8274 - val_loss: 0.3490 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3793 - accuracy: 0.8258 - val_loss: 0.3481 - val_accuracy: 0.8396\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.3770 - accuracy: 0.8292 - val_loss: 0.3471 - val_accuracy: 0.8404\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3789 - accuracy: 0.8276 - val_loss: 0.3463 - val_accuracy: 0.8415\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 59us/step - loss: 0.3772 - accuracy: 0.8280 - val_loss: 0.3459 - val_accuracy: 0.8420\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3770 - accuracy: 0.8286 - val_loss: 0.3455 - val_accuracy: 0.8422\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.3451 - val_accuracy: 0.8426\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3737 - accuracy: 0.8295 - val_loss: 0.3446 - val_accuracy: 0.8430\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3734 - accuracy: 0.8295 - val_loss: 0.3442 - val_accuracy: 0.8428\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3737 - accuracy: 0.8291 - val_loss: 0.3438 - val_accuracy: 0.8428\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 50us/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3434 - val_accuracy: 0.8433\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3704 - accuracy: 0.8307 - val_loss: 0.3431 - val_accuracy: 0.8439\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3716 - accuracy: 0.8294 - val_loss: 0.3427 - val_accuracy: 0.8436\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3714 - accuracy: 0.8292 - val_loss: 0.3423 - val_accuracy: 0.8442\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3717 - accuracy: 0.8306 - val_loss: 0.3422 - val_accuracy: 0.8444\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3420 - val_accuracy: 0.8445\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 63us/step - loss: 0.3710 - accuracy: 0.8321 - val_loss: 0.3418 - val_accuracy: 0.8444\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3699 - accuracy: 0.8316 - val_loss: 0.3417 - val_accuracy: 0.8444\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.3717 - accuracy: 0.8314 - val_loss: 0.3415 - val_accuracy: 0.8443\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3720 - accuracy: 0.8295 - val_loss: 0.3414 - val_accuracy: 0.8444\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.3704 - accuracy: 0.8314 - val_loss: 0.3413 - val_accuracy: 0.8444\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.3694 - accuracy: 0.8309 - val_loss: 0.3411 - val_accuracy: 0.8446\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3692 - accuracy: 0.8311 - val_loss: 0.3409 - val_accuracy: 0.8446\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3694 - accuracy: 0.8308 - val_loss: 0.3407 - val_accuracy: 0.8446\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3718 - accuracy: 0.8302 - val_loss: 0.3407 - val_accuracy: 0.8448\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30162/30162 [==============================] - 2s 59us/step - loss: 0.3686 - accuracy: 0.8329 - val_loss: 0.3406 - val_accuracy: 0.8447\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.3685 - accuracy: 0.8316 - val_loss: 0.3405 - val_accuracy: 0.8447\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3708 - accuracy: 0.8329 - val_loss: 0.3405 - val_accuracy: 0.8446\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3726 - accuracy: 0.8296 - val_loss: 0.3404 - val_accuracy: 0.8446\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3708 - accuracy: 0.8315 - val_loss: 0.3403 - val_accuracy: 0.8446\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3694 - accuracy: 0.8306 - val_loss: 0.3403 - val_accuracy: 0.8446\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3675 - accuracy: 0.8309 - val_loss: 0.3402 - val_accuracy: 0.8449\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.3688 - accuracy: 0.8328 - val_loss: 0.3401 - val_accuracy: 0.8448\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3665 - accuracy: 0.8313 - val_loss: 0.3400 - val_accuracy: 0.8451\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3685 - accuracy: 0.8334 - val_loss: 0.3400 - val_accuracy: 0.8450\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3690 - accuracy: 0.8322 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3671 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3673 - accuracy: 0.8321 - val_loss: 0.3399 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3697 - accuracy: 0.8318 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3689 - accuracy: 0.8315 - val_loss: 0.3398 - val_accuracy: 0.8450\n",
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3669 - accuracy: 0.8320 - val_loss: 0.3398 - val_accuracy: 0.8448\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3680 - accuracy: 0.8323 - val_loss: 0.3397 - val_accuracy: 0.8449\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.3668 - accuracy: 0.8328 - val_loss: 0.3397 - val_accuracy: 0.8448\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3674 - accuracy: 0.8323 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3679 - accuracy: 0.8328 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 1s 49us/step - loss: 0.3686 - accuracy: 0.8321 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.3698 - accuracy: 0.8330 - val_loss: 0.3396 - val_accuracy: 0.8449\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 2s 61us/step - loss: 0.3651 - accuracy: 0.8321 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.3677 - accuracy: 0.8315 - val_loss: 0.3396 - val_accuracy: 0.8450\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.3674 - accuracy: 0.8328 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.3687 - accuracy: 0.8299 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 2s 51us/step - loss: 0.3672 - accuracy: 0.8316 - val_loss: 0.3395 - val_accuracy: 0.8451\n",
      "Epoch 68/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3669 - accuracy: 0.8330 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 69/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3693 - accuracy: 0.8314 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 70/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3672 - accuracy: 0.8322 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 71/100\n",
      "30162/30162 [==============================] - 1s 50us/step - loss: 0.3692 - accuracy: 0.8296 - val_loss: 0.3395 - val_accuracy: 0.8450\n",
      "Epoch 72/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3677 - accuracy: 0.8322 - val_loss: 0.3394 - val_accuracy: 0.8451\n",
      "Epoch 73/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3661 - accuracy: 0.8300 - val_loss: 0.3394 - val_accuracy: 0.8451\n",
      "Epoch 74/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3675 - accuracy: 0.8327 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 75/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3690 - accuracy: 0.8291 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 76/100\n",
      "30162/30162 [==============================] - 2s 50us/step - loss: 0.3671 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 77/100\n",
      "30162/30162 [==============================] - 1s 50us/step - loss: 0.3677 - accuracy: 0.8309 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 78/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3680 - accuracy: 0.8316 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 79/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3686 - accuracy: 0.8309 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 80/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3698 - accuracy: 0.8319 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 81/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3676 - accuracy: 0.8317 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 82/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3680 - accuracy: 0.8341 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 83/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3682 - accuracy: 0.8303 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 84/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3684 - accuracy: 0.8321 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 85/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3687 - accuracy: 0.8322 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 86/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3676 - accuracy: 0.8317 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 87/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3648 - accuracy: 0.8328 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3677 - accuracy: 0.8313 - val_loss: 0.3394 - val_accuracy: 0.8452\n",
      "Epoch 89/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3677 - accuracy: 0.8313 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 90/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3654 - accuracy: 0.8309 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 91/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3682 - accuracy: 0.8319 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 92/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3681 - accuracy: 0.8311 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 93/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3694 - accuracy: 0.8333 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 94/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3686 - accuracy: 0.8318 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 95/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3682 - accuracy: 0.8306 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3680 - accuracy: 0.8328 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 97/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3678 - accuracy: 0.8320 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 98/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3713 - accuracy: 0.8297 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 99/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3665 - accuracy: 0.8330 - val_loss: 0.3393 - val_accuracy: 0.8452\n",
      "Epoch 100/100\n",
      "30162/30162 [==============================] - 1s 48us/step - loss: 0.3660 - accuracy: 0.8332 - val_loss: 0.3393 - val_accuracy: 0.8452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x233e205b6d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do do modelu \n",
    "```python\n",
    "model.add(Dropout(0.8))\n",
    "```\n",
    "po każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5660 - val_loss: 0.6948 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.7447 - accuracy: 0.5283 - val_loss: 0.6873 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.6486 - accuracy: 0.5472 - val_loss: 0.6949 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6477 - accuracy: 0.5849 - val_loss: 0.6326 - val_accuracy: 0.7234\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.6021 - accuracy: 0.8113 - val_loss: 0.6014 - val_accuracy: 0.7447\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5629 - accuracy: 0.8302 - val_loss: 0.5790 - val_accuracy: 0.7872\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 716us/step - loss: 0.5254 - accuracy: 0.8302 - val_loss: 0.5509 - val_accuracy: 0.7447\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.5021 - accuracy: 0.8302 - val_loss: 0.5204 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.4549 - accuracy: 0.8302 - val_loss: 0.5043 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.4138 - accuracy: 0.8302 - val_loss: 0.4981 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.3889 - accuracy: 0.8491 - val_loss: 0.4917 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3592 - accuracy: 0.8491 - val_loss: 0.4899 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3373 - accuracy: 0.8679 - val_loss: 0.4974 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.3270 - accuracy: 0.8679 - val_loss: 0.5014 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.3216 - accuracy: 0.8491 - val_loss: 0.5059 - val_accuracy: 0.7447\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3107 - accuracy: 0.8679 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2996 - accuracy: 0.8679 - val_loss: 0.5292 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2936 - accuracy: 0.8679 - val_loss: 0.5376 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2909 - accuracy: 0.8679 - val_loss: 0.5362 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2726 - accuracy: 0.8679 - val_loss: 0.5040 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2650 - accuracy: 0.8868 - val_loss: 0.4679 - val_accuracy: 0.8298\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2625 - accuracy: 0.8868 - val_loss: 0.4486 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2623 - accuracy: 0.8868 - val_loss: 0.4551 - val_accuracy: 0.8298\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2457 - accuracy: 0.8868 - val_loss: 0.4536 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2410 - accuracy: 0.9057 - val_loss: 0.4671 - val_accuracy: 0.7872\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2392 - accuracy: 0.9057 - val_loss: 0.4851 - val_accuracy: 0.8298\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2399 - accuracy: 0.9057 - val_loss: 0.4847 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2357 - accuracy: 0.9057 - val_loss: 0.4666 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2300 - accuracy: 0.8868 - val_loss: 0.4483 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2352 - accuracy: 0.9057 - val_loss: 0.4448 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2255 - accuracy: 0.9057 - val_loss: 0.4702 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2251 - accuracy: 0.8868 - val_loss: 0.4944 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2216 - accuracy: 0.9057 - val_loss: 0.4908 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2168 - accuracy: 0.9057 - val_loss: 0.4908 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2147 - accuracy: 0.9057 - val_loss: 0.4878 - val_accuracy: 0.8085\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2141 - accuracy: 0.8868 - val_loss: 0.4777 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2106 - accuracy: 0.8868 - val_loss: 0.4798 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2086 - accuracy: 0.8868 - val_loss: 0.4755 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2068 - accuracy: 0.8868 - val_loss: 0.4794 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2052 - accuracy: 0.8868 - val_loss: 0.4785 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2052 - accuracy: 0.9057 - val_loss: 0.4699 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2020 - accuracy: 0.8868 - val_loss: 0.4748 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1988 - accuracy: 0.9057 - val_loss: 0.4857 - val_accuracy: 0.8085\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1987 - accuracy: 0.9057 - val_loss: 0.4902 - val_accuracy: 0.8085\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1997 - accuracy: 0.9057 - val_loss: 0.4903 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1968 - accuracy: 0.9057 - val_loss: 0.4661 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1925 - accuracy: 0.9245 - val_loss: 0.4549 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1940 - accuracy: 0.9057 - val_loss: 0.4408 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1934 - accuracy: 0.9057 - val_loss: 0.4496 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1879 - accuracy: 0.9245 - val_loss: 0.4561 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 527us/step - loss: 0.1870 - accuracy: 0.9245 - val_loss: 0.4663 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1836 - accuracy: 0.9057 - val_loss: 0.4857 - val_accuracy: 0.8085\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1863 - accuracy: 0.9434 - val_loss: 0.4960 - val_accuracy: 0.8085\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1868 - accuracy: 0.9434 - val_loss: 0.4807 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.1812 - accuracy: 0.9245 - val_loss: 0.4728 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1803 - accuracy: 0.9245 - val_loss: 0.4586 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1806 - accuracy: 0.9245 - val_loss: 0.4363 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1840 - accuracy: 0.9057 - val_loss: 0.4362 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1832 - accuracy: 0.9245 - val_loss: 0.4647 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1769 - accuracy: 0.9245 - val_loss: 0.4742 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1716 - accuracy: 0.9434 - val_loss: 0.4572 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1684 - accuracy: 0.9434 - val_loss: 0.4324 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1689 - accuracy: 0.9245 - val_loss: 0.4164 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1679 - accuracy: 0.9245 - val_loss: 0.4213 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.1663 - accuracy: 0.9245 - val_loss: 0.4229 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1622 - accuracy: 0.9434 - val_loss: 0.4109 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1631 - accuracy: 0.9434 - val_loss: 0.4054 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1632 - accuracy: 0.9434 - val_loss: 0.3897 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1624 - accuracy: 0.9245 - val_loss: 0.3952 - val_accuracy: 0.8511\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1563 - accuracy: 0.9434 - val_loss: 0.4279 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1574 - accuracy: 0.9811 - val_loss: 0.4407 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1547 - accuracy: 0.9811 - val_loss: 0.4229 - val_accuracy: 0.8298\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1519 - accuracy: 0.9623 - val_loss: 0.3973 - val_accuracy: 0.8511\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1476 - accuracy: 0.9434 - val_loss: 0.3902 - val_accuracy: 0.8511\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1475 - accuracy: 0.9245 - val_loss: 0.3938 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1495 - accuracy: 0.9434 - val_loss: 0.4143 - val_accuracy: 0.8298\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1405 - accuracy: 0.9623 - val_loss: 0.4121 - val_accuracy: 0.8298\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1403 - accuracy: 0.9623 - val_loss: 0.4028 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1414 - accuracy: 0.9623 - val_loss: 0.3836 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1352 - accuracy: 0.9623 - val_loss: 0.3869 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1321 - accuracy: 0.9623 - val_loss: 0.4032 - val_accuracy: 0.8723\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1327 - accuracy: 0.9811 - val_loss: 0.4067 - val_accuracy: 0.8723\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1289 - accuracy: 0.9811 - val_loss: 0.3847 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1247 - accuracy: 0.9811 - val_loss: 0.3668 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1276 - accuracy: 0.9623 - val_loss: 0.3508 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1251 - accuracy: 0.9623 - val_loss: 0.3627 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.1199 - accuracy: 0.9623 - val_loss: 0.3595 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.1156 - accuracy: 0.9811 - val_loss: 0.3667 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1158 - accuracy: 0.9811 - val_loss: 0.3761 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1161 - accuracy: 0.9811 - val_loss: 0.3534 - val_accuracy: 0.8936\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1100 - accuracy: 0.9811 - val_loss: 0.3344 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1066 - accuracy: 0.9811 - val_loss: 0.3154 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1039 - accuracy: 0.9811 - val_loss: 0.3069 - val_accuracy: 0.8723\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1028 - accuracy: 0.9811 - val_loss: 0.2985 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0999 - accuracy: 0.9811 - val_loss: 0.2914 - val_accuracy: 0.8723\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0966 - accuracy: 0.9811 - val_loss: 0.2951 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0949 - accuracy: 0.9811 - val_loss: 0.2897 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0915 - accuracy: 0.9811 - val_loss: 0.2917 - val_accuracy: 0.8936\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0899 - accuracy: 0.9811 - val_loss: 0.2873 - val_accuracy: 0.8936\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0861 - accuracy: 0.9811 - val_loss: 0.2688 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0851 - accuracy: 0.9811 - val_loss: 0.2480 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0828 - accuracy: 0.9811 - val_loss: 0.2420 - val_accuracy: 0.8936\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0795 - accuracy: 0.9811 - val_loss: 0.2452 - val_accuracy: 0.8936\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0757 - accuracy: 0.9811 - val_loss: 0.2588 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0773 - accuracy: 0.9623 - val_loss: 0.2681 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0746 - accuracy: 0.9811 - val_loss: 0.2441 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 0.0687 - accuracy: 0.9811 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0675 - accuracy: 0.9811 - val_loss: 0.2144 - val_accuracy: 0.8936\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0666 - accuracy: 0.9811 - val_loss: 0.2113 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0608 - accuracy: 0.9811 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.2323 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 0.2330 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.2148 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0454 - accuracy: 0.9811 - val_loss: 0.1934 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9149\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.8936\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0414 - accuracy: 0.9811 - val_loss: 0.2064 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.8936\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9362\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9149\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9149\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9149\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.1826 - val_accuracy: 0.9362\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9362\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9149\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1812 - val_accuracy: 0.9149\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9362\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9149\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9149\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 565us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9149\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9149\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9149\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9149\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9149\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9149\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9149\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9149\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9149\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9149\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9149\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 545us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9149\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9149\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9362\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.8936\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1818 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1837 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9149\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9149\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9149\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9149\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1955 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9149\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2025 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9149\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9149\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.8936\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 643us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1958 - val_accuracy: 0.8936\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.8936\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.8936\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.8936\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.8936\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.8936\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.8936\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.8936\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8936\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.8936\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.8936\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.8936\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.8936\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.8936\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.8936\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.8936\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.8936\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 527us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.8936\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.8936\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2134 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 764us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 726us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2276 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2341 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2368 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 761us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2402 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2556 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 809us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 9.9225e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.9669e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.9375e-04 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.7589e-04 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 9.6190e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 9.7463e-04 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 9.7850e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 9.3220e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 9.4150e-04 - accuracy: 1.0000 - val_loss: 0.2819 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 9.8599e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 9.4141e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 9.1908e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 9.2023e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.2969e-04 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 9.4884e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.1515e-04 - accuracy: 1.0000 - val_loss: 0.2805 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.4636e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.9190e-04 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 9.1552e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 8.8380e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.7964e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 8.7587e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 8.9596e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.6625e-04 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.6359e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.7999e-04 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.5402e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.6740e-04 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.5811e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 8.4571e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.8666e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 8.5039e-04 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 8.9576e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 8.3006e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.6973e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 8.3312e-04 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 716us/step - loss: 8.5779e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 8.3685e-04 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.0753e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.0015e-04 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 8.0762e-04 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 8.0165e-04 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.0019e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 8.0729e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 8.5221e-04 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.0588e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 8.3117e-04 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 7.7111e-04 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.7069e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.7180e-04 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 7.8037e-04 - accuracy: 1.0000 - val_loss: 0.2898 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 7.5410e-04 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 7.5072e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 7.6201e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 7.7629e-04 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 706us/step - loss: 7.6856e-04 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 7.5178e-04 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 7.4824e-04 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 7.3772e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.2462e-04 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 7.2780e-04 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 7.1686e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 7.1724e-04 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.2953e-04 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.4228e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 7.3745e-04 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.2183e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.8898e-04 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 6.7900e-04 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 7.3182e-04 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 7.7656e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 7.2039e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.4419e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.8272e-04 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.1462e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.8729e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.7236e-04 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 7.1073e-04 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.7927e-04 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 6.6657e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.6671e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.6208e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 6.7589e-04 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 6.6050e-04 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 6.4452e-04 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 6.4249e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.5169e-04 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.3852e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 6.3920e-04 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.4999e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.3112e-04 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.2789e-04 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 6.3438e-04 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 6.2036e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 6.1756e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 6.1979e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.3307e-04 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.3034e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.2612e-04 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.3551e-04 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 6.0218e-04 - accuracy: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.0810e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.9631e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 5.9534e-04 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 6.3217e-04 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.2819e-04 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.9953e-04 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 5.8151e-04 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.7027e-04 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 5.9616e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 6.2676e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.9902e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 5.6192e-04 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 5.6757e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.3396e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 6.1203e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.9488e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.6399e-04 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.5505e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.6184e-04 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.9316e-04 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.7157e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.4703e-04 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.4489e-04 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.7688e-04 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.6484e-04 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 5.4114e-04 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.6484e-04 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.3916e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.3289e-04 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.4074e-04 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.5142e-04 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 5.3477e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.1452e-04 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.5753e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.2885e-04 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.3009e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.2168e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.1219e-04 - accuracy: 1.0000 - val_loss: 0.3155 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.0703e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.0570e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.0632e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.0485e-04 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.0795e-04 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9502e-04 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.9411e-04 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.9168e-04 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.9468e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.3019e-04 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.0976e-04 - accuracy: 1.0000 - val_loss: 0.3178 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.9401e-04 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.0451e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 752us/step - loss: 4.9377e-04 - accuracy: 1.0000 - val_loss: 0.3219 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 4.9339e-04 - accuracy: 1.0000 - val_loss: 0.3214 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.7518e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.8272e-04 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 4.7122e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 4.7044e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.6983e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.6830e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.6599e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.7513e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.6076e-04 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.6664e-04 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 4.5771e-04 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 4.5769e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 4.6393e-04 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 4.7079e-04 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.5875e-04 - accuracy: 1.0000 - val_loss: 0.3261 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.4884e-04 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.4821e-04 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.5230e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 4.5174e-04 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.4828e-04 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 4.4176e-04 - accuracy: 1.0000 - val_loss: 0.3254 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.3857e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.3731e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.3638e-04 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.3566e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.3448e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.3786e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.2969e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.2783e-04 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.3273e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.2684e-04 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.3334e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.2987e-04 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.3919e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 4.2902e-04 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.2016e-04 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.1573e-04 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.3346e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.1961e-04 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 4.2458e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.0870e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 4.0672e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 4.0501e-04 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.0304e-04 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 4.0225e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 4.0859e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.1296e-04 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.9806e-04 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.9652e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.9489e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 4.0262e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.0401e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 3.9091e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.9484e-04 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.8782e-04 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.8693e-04 - accuracy: 1.0000 - val_loss: 0.3350 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 3.9780e-04 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.8711e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.8331e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.8377e-04 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.9669e-04 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 3.8958e-04 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 3.7986e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.7666e-04 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.7593e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.8247e-04 - accuracy: 1.0000 - val_loss: 0.3359 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.8171e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 3.7719e-04 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.7215e-04 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 3.6831e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.7960e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 3.6710e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 3.6956e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.7745e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 3.6745e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.7339e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.7089e-04 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.6371e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.6842e-04 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 3.6077e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 3.5476e-04 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.6690e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.5408e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.5730e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.5042e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 3.6091e-04 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.5442e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.5020e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.4540e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.4590e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 3.5302e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 3.5493e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.4837e-04 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.4286e-04 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 3.3820e-04 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.5065e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 3.4628e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.3508e-04 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.4569e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.3948e-04 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.3339e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.2902e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 3.2810e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.3009e-04 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.3170e-04 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.3683e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.3177e-04 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.3159e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.2284e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 3.2065e-04 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 3.3132e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.2647e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 3.1675e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.1427e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 3.1307e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 3.2537e-04 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 3.1598e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 3.1225e-04 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 3.0914e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 886us/step - loss: 3.0774e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 3.0713e-04 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.0693e-04 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 3.1279e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 3.0562e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 838us/step - loss: 3.0344e-04 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.1493e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 3.0346e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 819us/step - loss: 3.0770e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.0055e-04 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.9979e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 3.0407e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.9669e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 2.9614e-04 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 3.0051e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.9364e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 2.9675e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 3.0087e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 2.9240e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.9370e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 2.9992e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.9174e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 2.8871e-04 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.8709e-04 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.8824e-04 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.8900e-04 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8665e-04 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.8460e-04 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.8172e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.8956e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.8513e-04 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.7988e-04 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.7821e-04 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7623e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.7781e-04 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.8168e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.9185e-04 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.8437e-04 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.9027e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.7195e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.7131e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.7336e-04 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.7237e-04 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.8162e-04 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.8936\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 2.7935e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6902e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.6770e-04 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.6490e-04 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.6418e-04 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.7049e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.6892e-04 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 2.6177e-04 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.6544e-04 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.6736e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.6344e-04 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5822e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.6476e-04 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.5700e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5614e-04 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5467e-04 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.5435e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.5376e-04 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5763e-04 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.5334e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.5107e-04 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.8936\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.6000e-04 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.8936\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.5211e-04 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.8936\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.5355e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.8936\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4932e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.4707e-04 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.5511e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4771e-04 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.4854e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4505e-04 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.5212e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.8936\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4734e-04 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.8936\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.4846e-04 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.8936\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.4838e-04 - accuracy: 1.0000 - val_loss: 0.3683 - val_accuracy: 0.8936\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.4434e-04 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.8936\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.4006e-04 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.8936\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.3955e-04 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.8936\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.3891e-04 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.8936\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.3830e-04 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.8936\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.3686e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8936\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.3632e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8936\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.3528e-04 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.8936\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 2.3487e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.8936\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.3419e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.8936\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.3677e-04 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.8936\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 2.3895e-04 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.8936\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 639us/step - loss: 2.3197e-04 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.8936\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.3454e-04 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.8936\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.3679e-04 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.8936\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.2971e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.8936\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 2.2898e-04 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.8936\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2852e-04 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.8936\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.2771e-04 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.8936\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.3030e-04 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.8936\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 1.8909e-04 - accuracy: 1.00 - 0s 696us/step - loss: 2.2727e-04 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.8936\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.2528e-04 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.8936\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.2728e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.8936\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.2924e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8936\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 2.2851e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8936\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.2840e-04 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.8936\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.3307e-04 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.8936\n",
      "Epoch 880/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 2.2588e-04 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.8936\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.2224e-04 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.8936\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.2071e-04 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.8936\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.2092e-04 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.8936\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.2841e-04 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.8936\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.2286e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.8936\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.2020e-04 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.8936\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.2354e-04 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.8936\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1620e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8936\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1550e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8936\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.1486e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8936\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.1696e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.8936\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.1910e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.8936\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.1322e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.8936\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.1270e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.8936\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 2.1645e-04 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.8936\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1568e-04 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.8936\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 2.1062e-04 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.8936\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.1000e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.8936\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.0948e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8936\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.1260e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8936\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 2.0859e-04 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.8936\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0745e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.8936\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0719e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.8936\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.0685e-04 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.8936\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.0939e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.8936\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.0745e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8936\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.0520e-04 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.8936\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.1041e-04 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.8936\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.1003e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8936\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0373e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.8936\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.0294e-04 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.8936\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 2.0603e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.8936\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.0526e-04 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.8936\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.0093e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.8936\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 2.0023e-04 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.8936\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 2.0145e-04 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.8936\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9919e-04 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.8936\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9910e-04 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.8936\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.9908e-04 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8936\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 1.9871e-04 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8936\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9807e-04 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8936\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 2.0076e-04 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.8936\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.9864e-04 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8936\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.0073e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8936\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9572e-04 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.8936\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.9668e-04 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8936\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.9384e-04 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.8936\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9361e-04 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.8936\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9492e-04 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.8936\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 1.9665e-04 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8936\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.9579e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.8936\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9512e-04 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.8936\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9417e-04 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.8936\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.9389e-04 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9228e-04 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.8936\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.9054e-04 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.8936\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 1.8906e-04 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.8936\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8828e-04 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.8936\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8781e-04 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.8936\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.9131e-04 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.8936\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8705e-04 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.8936\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8654e-04 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.8936\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8573e-04 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8936\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8531e-04 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.8936\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8501e-04 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8936\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8756e-04 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.8936\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8875e-04 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.8936\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.8555e-04 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.8936\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8755e-04 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.8936\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8502e-04 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.8936\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.8163e-04 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.8936\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.8208e-04 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.8936\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.8695e-04 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.8936\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8122e-04 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.8936\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 1.8275e-04 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.8936\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.7935e-04 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.8936\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.8342e-04 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.8936\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.7818e-04 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.8936\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.8041e-04 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.8936\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7721e-04 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.8936\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7687e-04 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.8936\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7650e-04 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.8936\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.7603e-04 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.8936\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.7754e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8936\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7967e-04 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8936\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 1.7407e-04 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.8936\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7639e-04 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8936\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7335e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8936\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7397e-04 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8936\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7245e-04 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8936\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.7278e-04 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.8936\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.7274e-04 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.8936\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.7227e-04 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.8936\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 1.7322e-04 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.8936\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.7557e-04 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.8936\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.6949e-04 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.8936\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6921e-04 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.8936\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.6870e-04 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.8936\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.6842e-04 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8936\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.7006e-04 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.8936\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 1.6744e-04 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.8936\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.7087e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.8936\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.6676e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.8936\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.6796e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.8936\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 1.7000e-04 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.8936\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 1.6523e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8936\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 1.6691e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8936\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 1.6524e-04 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.8936\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 1.6406e-04 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8936\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.6371e-04 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.8936\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 1.7046e-04 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.8936\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.6861e-04 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.8936\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 1.6533e-04 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.8936\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 1.6245e-04 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.8936\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 1.6070e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8936\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 1.6729e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8936\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 1.6240e-04 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.8936\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 1.6207e-04 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.8936\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 1.6196e-04 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8936\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 1.6003e-04 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.8936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x233e3bccf28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd4XMW5+PHvu0Wr7iL3KrkAbtjYciEmgAMG00wChJ5ACJgQSLgkcINzCQRSLgEuLT+aqZdqCOSCAQOmmBIC2DIYcMUFF1nYluUi2aq7O78/ZtdayStrJe1qdVbv53n07Cmz57xHa787mjNnRowxKKWUSi2uZAeglFIq/jS5K6VUCtLkrpRSKUiTu1JKpSBN7koplYI0uSulVArS5K6UUilIk7tSSqUgTe5KKZWCPMk6cY8ePUx+fn6yTq+UUo60ZMmSHcaYns2VS1pyz8/Pp6ioKFmnV0opRxKRjbGU02YZpZRKQZrclVIqBWlyV0qpFJS0NnellGpKXV0dxcXFVFdXJzuUpElPT2fAgAF4vd5WvV+Tu1KqwykuLiYnJ4f8/HxEJNnhtDtjDGVlZRQXF1NQUNCqY2izjFKqw6muriYvL69TJnYAESEvL69Nf7locldKdUidNbGHtfX6HZfcjTG8tKSYqtpAskNRSqkOy3HJ/ZP1Zfz2H1/y59dXJDsUpVQK2717N/fff3+L33fyySeze/fuBETUMo5L7uVVfgBKK2qSHIlSKpW1NLkbYwgGg8yfP5+uXbsmMLLYOC65G2MAcHXy9jilVGJdf/31rFu3jnHjxnHNNddw3HHHMX78eMaMGcMrr7wCwIYNGxgxYgS//OUvGT9+PJs3byY/P58dO3bs33fZZZcxatQoTjjhBKqqqgB4+OGHmThxImPHjuXMM8+ksrIy7vE7ritk0OZ2XI77WlJKtcbNry5nRUl5XI85sl8uN5026qBlbr31VpYtW8bSpUvx+/1UVlaSm5vLjh07mDJlCjNnzgRg9erVPP7441Fr+WvWrOG5557j4Ycf5uyzz+all17iwgsv5IwzzuCyyy4D4IYbbuDRRx/lV7/6VVyv0YHJ3Wb3zn4nXSnVfowx/P73v+fDDz/E5XKxZcsWtm3bBsDgwYOZMmVK1PcVFBQwbtw4ACZMmMCGDRsAWLZsGTfccAO7d+9m7969nHjiiXGP2bHJXZtllOocmqtht4dnnnmG0tJSlixZgtfrJT8/f38f9KysrCbf5/P59i+73e79zTIXX3wxL7/8MmPHjuWJJ57g/fffj3vMjmvcMOFmGc3tSqkEysnJoaKiAoA9e/bQq1cvvF4vCxcuZOPGmEbdbVJFRQV9+/alrq6OZ555Jh7hHkBr7kopFUVeXh5Tp05l9OjRTJw4kVWrVlFYWMi4ceM47LDD2nTsP/3pT0yePJnBgwczZsyY/V8i8RRTcheRGcA9gBt4xBhza6P9dwHTQquZQC9jTEL6AoVvqGpuV0ol2rPPPttsmWXLljVYD7er9+jRo8G+a6+9dv/yFVdcwRVXXBGfIJvQbHIXETdwHzAdKAYWi8g8Y8z+p4iMMddElP8VcEQCYgW05q6UUrGIpc19ErDWGLPeGFMLzAVOP0j584Dn4hFcNPX93BN1BqWUcr5Yknt/YHPEenFo2wFEZDBQALzX9tCi298sg2Z3pZRqSizJPVoWNU2UPRd40RgTdVQvEZklIkUiUlRaWhprjA2kV37Hhe63yQzE96EGpZRKJbHcUC0GBkasDwBKmih7LnBlUwcyxswB5gAUFhY29QVxUIO3vM6PvI9TtfofwJbWHEIppVJeLDX3xcBwESkQkTRsAp/XuJCIHAp0Az6Jb4gNlaf3AyAjuDeRp1FKKUdrNrkbY/zAVcBbwErgBWPMchG5RURmRhQ9D5hrwnc8E2RHxpBEHl4ppVo93G/Y3XffnZDBwFoipidUjTHzjTGHGGOGGmP+Etp2ozFmXkSZPxpjrk9UoGH+HodRarrwTW70sRyUUqqtOk1y70jOnTSILfTCTTDZoSilUlTkcL/XXXcdALfffjsTJ07k8MMP56abbgJg3759nHLKKYwdO5bRo0fz/PPPc++991JSUsK0adOYNm3awU6TUI4bfgAgIB5cQX+yw1BKtYc3roetX8f3mH3GwEm3Nrk7crhfgAULFrBmzRoWLVqEMYaZM2fy4YcfUlpaSr9+/Xj99dcBOwZNly5duPPOO1m4cCE9evSIb9wt4LiaO4AfNy6jyV0p1T4WLFjAggULOOKIIxg/fjyrVq1izZo1jBkzhnfeeYff/e53fPTRR3Tp0iXZoe7nyJp7EDdi6pIdhlKqPRykht1ejDHMnj2byy+//IB9S5YsYf78+cyePZsTTjiBG2+8MQkRHsiZNXfx4Naau1IqQSKH+wU48cQTeeyxx9i713bB3rJlC9u3b6ekpITMzEwuvPBCrr32Wj7//POo708GR9bcA7i1zV0plTCRw/2edNJJ3H777axcuZIjjzwSgOzsbJ5++mnWrl3Lddddh8vlwuv18sADDwAwa9YsTjrpJPr27cvChQuTcg2S4G7pTSosLDRFRUWteu97t8xgpKeEPr//Ks5RKaU6gpUrVzJixIhkh5F00X4PIrLEGFPY3Hsd2SwT0GYZpZQ6KEcmdyMeggG9oaqUUk1xZHLvmpOJCWjNXalUlqwm446irdfvyOTuS/Phxt/pP3ylUlV6ejplZWWd9v+4MYaysjLS09NbfQxH9pYRtxcvAWoDQXwed7LDUUrF2YABAyguLqa18z6kgvT0dAYMGNDq9zs0uXvwEKDWr8ldqVTk9XopKChIdhiO5shmGTw+fNRR49fBw5RSKhpHJnfjzcQrAWprqpMdilJKdUiOTO54MwHwV+lsTEopFY0zk3taFgD+Gk3uSikVjTOTe7jmXr0vyYEopVTHFFNyF5EZIrJaRNaKSNSp9ETkbBFZISLLReTZ+IbZkMsXqrlXa81dKaWiabYrpIi4gfuA6UAxsFhE5hljVkSUGQ7MBqYaY3aJSK9EBQzgCjXLBGq05q6UUtHEUnOfBKw1xqw3xtQCc4HTG5W5DLjPGLMLwBizPb5hNuTyZQNgNLkrpVRUsST3/sDmiPXi0LZIhwCHiMjHIvKpiMyIV4DReNJtzT1Yq8ldKaWiieUJVYmyrfGADx5gOHAsMAD4SERGG2N2NziQyCxgFsCgQYNaHGyYO5TcjSZ3pZSKKpaaezEwMGJ9AFASpcwrxpg6Y8y3wGpssm/AGDPHGFNojCns2bNna2PGE2qWobay1cdQSqlUFktyXwwMF5ECEUkDzgXmNSrzMjANQER6YJtp1scz0EjejFByr9PkrpRS0TSb3I0xfuAq4C1gJfCCMWa5iNwiIjNDxd4CykRkBbAQuM4YU5aooL3pNrmLJnellIoqplEhjTHzgfmNtt0YsWyA34R+Ei4tzUuN8SJ1Ve1xOqWUchxHPqGa5nFRiQ+XX2+oKqVUNM5M7m4X+0jHpc0ySikVlSOTu4hQRTpuvyZ3pZSKxpHJHaCKdDwBTe5KKRWNY5N7jaTjCegNVaWUisaxyb3alY5Xk7tSSkXl2OReIxl4tVlGKaWicmxyr3Vl4AtqzV0ppaJxbnJ3Z5AW1AmylVIqGscm9zpXBj5TBabxAJVKKaWcm9zdmbgwUFdlR4f85D7QIYCVUgpwcHL3e+wk2dTug2/ehLd+D2/flNyglFKqg0iB5L4Xdm+0yzqQmFJKAQ5O7oFwcq+rhF2h5O5yJy8gpZTqQByb3I03olmmYqtd1pq7UkoBDk7ukhaeam8v7A0nd32oSSmlwMHJ3Z2eYxdq90HFNrusNXellAIcnNw9oan2/FUVsG+73ajJXSmlgBiTu4jMEJHVIrJWRK6Psv9iESkVkaWhn0vjH2pD4Umy68o2QNBvN2qzjFJKATHMoSoibuA+YDpQDCwWkXnGmBWNij5vjLkqATFGlZZpm2XM9pWhQF1ac1dKqZBYau6TgLXGmPXGmFpgLnB6YsNqni8zh70mncw18+yGgqM1uSulVEgsyb0/sDlivTi0rbEzReQrEXlRRAZGO5CIzBKRIhEpKi0tbUW49XxeL6tN6DQ9R0D3oQ2bZZoac6ZsHXz7YZvOrZRSHV0syV2ibGucOV8F8o0xhwPvAP8b7UDGmDnGmEJjTGHPnj1bFmkjXrewMjjIrvSfAN6M+pp7MAg3d4UFfzjwjX8fD/97WpvOrZRSHV0syb0YiKyJDwBKIgsYY8qMMTWh1YeBCfEJr2lpHherTCi5Z+WBN9PW3I2xfd8B/n0vlJfAxk/gtiHwzYLIoBMdolJKJU0syX0xMFxECkQkDTgXmBdZQET6RqzOBFbGL8TofB4XzwemsXH0VTDxMltzx8DXL8KSx+sLfvMmLP8nVJZB8eL67TUViQ5RKaWSptneMsYYv4hcBbwFuIHHjDHLReQWoMgYMw/4tYjMBPzATuDiBMYMgNftog4Pa0b+msFde9uaO8A/G/XCLPkC9myxy4Ha+u1VOyE9N9FhKqVUUjSb3AGMMfOB+Y223RixPBuYHd/QDi7NY//oqA0E7QZvRvSCnz9Zv1y9p365Yht0y09McEoplWSOfUI1zR1K7v5wcs9s/k3hAcYAVr0KC/+qbe9KqZTk2OTudcdQc79kAeQNq1+viLgP/O+/wwd/q7/5qpRSKcSxyd3naVxzj5LcfTlw/guQ0xcyukH5dweWqdqdwCiVUio5HJvc0w5I7lGaZdIyIW8o/HYV9B1XP8BYpGpN7kqp1OPY5B5ulqk7WLNMeMx3gOxe9cvdCuqXteaulEpBjk3usdXcs+qXw8ndkwG9RtRv15q7UioFOTa5e1yCSMQN1bQoyd2TXr+cFUru3fJtW3xYdXnCYlRKqWRxbHIXEbxuV31y90RplpGIYXGyI5J7ZHONPqmqlEpBjk3uAD63q75ZJisPTvxvuGZ59MLh5N69AHyRyV1r7kqp1OPo5O71uOpvqAIc+UvoMgB+/jac8UjDwvubZQrAnVa/vabcjib5/E9gx5rEB62UUu3A0ck9LbLmHmngJDj8xw239RoBR/0GRp4OrohRF2oqYMO/YOU8mH9dYgNWSql24uzk7mkiuUfjcsPxN0FObxh6HPQ41G6vLq8fUCyyRq+UUg7m6OTudQt1gVaMDTNwIly1CPqNtzX38E1VjyZ3pVRqcHRyT/O4qYm15h6NLweqdtmx3qFhc41SSjmYo7NZmieiK2RrBP2wpQh2bbDrgbq4xKWUUsnm7Jq7W6hrS81948f2tXKHffXXNF1WKaUcxNnJva019/EXNVxf+zbM/08d410p5XgxJXcRmSEiq0VkrYhcf5ByZ4mIEZHC+IXYtHSPm+q6QOsPcOrdMPQHDbctegi2r2hbYEoplWTNJncRcQP3AScBI4HzRGRklHI5wK+Bz+IdZFMy0txU1bYhubtc0Hv0gdtfvxa+eLr1x1VKqSSLpeY+CVhrjFlvjKkF5gKnRyn3J+A2oDqO8R1UVpqHfbX+th2kz+EHbtv0b3jlyrYdVymlkiiW5N4f2ByxXhzatp+IHAEMNMa8FsfYmpWR5qayLTV3sGPSKKVUiokluUuUbfvvOIqIC7gL+G2zBxKZJSJFIlJUWloae5RNyPLZ5G7acgM0o3ub41BKqWatWwj3jIWHfwAlSxN+ulj6uRcDAyPWBwARM02TA4wG3hc7xG4fYJ6IzDTGFEUeyBgzB5gDUFhY2OYuKZlpHgJBQ20giM/jbuVBNLkrpVopGICydbBjNYgLvn4Rdm+CnodCxXeweZGdwzktE7atgK4DobzEPlvTb1xCQ4sluS8GhotIAbAFOBc4P7zTGLMH6BFeF5H3gWsbJ/ZEyEyzCb2yJtCG5B4KfcBEKF7ccJ8xDceEV0p1TjUVUFwEecOg5Av49kM7dHjR4w1nc8voDl0Hweo37BPwI2bakWd3bYTBR8JZT9gpQaNNLhRnzSZ3Y4xfRK4C3gLcwGPGmOUicgtQZIyZl+ggmxJO7vtq/XTLauW4MGmZ8JtVdrz3oB/+HDHXal1Vu3wISqkOYvNi2PoVlG+B3P62dl1cBB/cVv+wI9ihSoJ+6F8IhZdAt8H2CfdBU6LP55wEMQ0/YIyZD8xvtO3GJsoe2/awYpOZZsNvU3dIgNy+9tXlhpNuh3dugrpK+42ryV2p1LOvzCbrtGyo3QdfzYX1H9jhSKIZ9D2YcidUbIXMPFsj91dBWo7tUt0BOXpsmfqaexuTe6TJsyCjG/zzUlj1mp14e9z5zb9PKdUxff4kfPGMHQ3W5YFvP7JNKyYybwj0GQPTb4HRZ9rmle0rYde3dva2fuMPbKLt4KPIOjy52/Ar29rXvbH0XPv6eqgDkCZ3pTq26j22B0p5CWz92taqs3qBCcJHd4DbB5s/tTc984bD1Ktt+3mgxo4pNfwEyBva8JgDJtgfh3J4cq+/oRpXvtz4Hk8p1XZ11bade9cG+NedtnnEXw07v4XNn9VPuuPy2gpa1S6b3PO/D+c/D5502/TaSTg6uWf5Qsm9LePLROPLabiuvWaUSjxj7E3JcHNH5U7bzbDiO9uMUvSoraGLyybwQK39v9otHybNgmHH2eaUXiPA44OavbYnS27/Tvn/19HJPSPcLFMT52aZjG4N12v32W5PSqnE2PktvPBTWyuffrNtXvnkPtuxAQCBw06xSdrlhRP/YmvivlxwN5HGfNmd+v+to5N7VrhZJp43VOHAB5tqyjv1PxKl4s4YWP5/UPSYnbt4S5Hd5suF166xZUacBqN+BN2H2OdRug48+DFVA45O7hn7k3uca+6N+6mG51hVSrVc2Tr7mtMX1i+0T21u+sS2k3cfatvFexwKZzwEXfNh65c20fcfn9Swnc7RyT3N7cLjkvjX3BurLk/s8ZVKJSVLYfHDMPQ4WPU6LHvRbhe37X7o8kJ2bzjtHjjiJwfe5Ox3RPvHnIIcndxFJD4jQ0Zz7rOwezO8+TvbLKOUOlDZOvsk9yf3QW4/Wwv/7EHbVv7F0zahH32dfViopgLyj7I/bm+yI095jk7uEBrTPd43VMHevNm23C5rcledmb/W9gf3ZMDKebadvOsg2z88XCuPNPgo+OH9sOEjOxlOggfIUtE5Prlnprnj3xUyLNzfXdvcVWfir4EFN9gnNCdcbJcrvqvfn5ZtE7c3y9707DkCRs6E9C62Z1mvEbZct8FJCV9Zjk/u2ekeyqvqEnPwcH93bXNXqahql71xWVMOK1+zNzk3fgzBINTssWU2fGT7kU++Amor7I3Pwp/ZHi4eX1LDVwfn+OTeOzedjWX7EnPwcHLXmrtKNVuXwaPTI/qRYx8Ayj8KKnfBpMugx3Cb8MecXT8kh3IMxyf3fl3S+XR9WWIO7nKHbgRpzV050M5vYcO/7JObJV/AO3+Eqt1Q8H1Y95692fm9X9l+5P3GR28b7z2q3cNW8eH45D4oL4uKaj/byqvpnZse/xP4cjW5K2cID5r1+ZOwr9SOQ24C9WOP9xplZwha87atlU+/xdbUVUpyfHIfO6ALAMu27ElQcs/RNnfVMdVWwrKXIKcPdCuAR4+37egZ3e3NzQkXQcExsOJl6DsWplzZ4YepVfHj+OQ+sLudTKNkT3ViTpCeq23uqv0F6mz/8fRcKP0G9m6DwVNt18Mv58LEn8OSJ2DNgvr3uNPgxL/CuAsgo2v99lE/bPfwVfI5Prn3yPbhdgnbEpXcM/Psw0xKtZdgAB470Q6idfZT8MTJdnv/wvqZgta9a19P+IudSWz9B3DEhTBwUlJCVh1PTMldRGYA92DnUH3EGHNro/2/AK4EAsBeYJYxZkWcY43K7RJ6ZvvYVp6g5N6twE6Gq8P+qkTx18K7N9sp3KZcAd8thS1L7L4nTgYEsnraxD7iNJhxK3x4OxQcbWcNgvpXpUKaTe4i4gbuA6YDxcBiEZnXKHk/a4x5MFR+JnAnMCMB8UbVO9fH1kQl97yhtrtYxdb6uVaVipeaCljwB1jyuF0PP/E5+Cjonm8f4T/qGpj8C/jiSZhwCWTl2XFZlDqIWGruk4C1xpj1ACIyFzgd2J/cjTGRdxyzABPPIJvTOzedDYnq6959iH3duU6Tu2qdYAA++h/bQ6XnYTDv11C6ys7NWbYOavfam51Tr7Y3SEtXwvQ/2XFaBkyCsefaB4aOvi7ZV6IcJJbk3h+IbHQuBiY3LiQiVwK/AdKAH0Q7kIjMAmYBDBo0qKWxNqlf1ww+XruDYNDgcsW56SQ8r+LWZdptTMWuapd9PN+TBitegYV/sdvdafanz+GhgbS+D5MvhyHH2ma/I3/Z8DgTLmrvyFWKiCW5R8uWB9TMjTH3AfeJyPnADcAB/yqNMXOAOQCFhYVxq90f1ieHfbUBNu6spKBHVrwOa3UJTRDw5u9sDSqyF4JSYavfsPN5DjkWnjoDSj63w9pO+JntipiWY/uc11XZEUeHT092xCrFxZLci4HIKVAGACUHKT8XeKAtQbXUkUPzAFiwfCuXHzO0mdItFDnW9BOnwBUfx/f4yrkCoTGNPnsIFvyXXe6Wb3tXTbnS3hj9INT34Jxn7IBagdr6gbWUSqBYkvtiYLiIFABbgHOB8yMLiMhwY8ya0OopwBra0eC8LLpkeCnZXZWYE1y2EB6eBtuWJeb4qmMKhkYbbTyZBNi28id/CHs22fWhx9la+a5v4fT/B+POtz2s1r0Lvi4wcGL7xa0UMSR3Y4xfRK4C3sJ2hXzMGLNcRG4Biowx84CrROR4oA7YRZQmmUTLzfBQXp2Acd3BTvc15Zf2sW7VefzjIjum/8y/Q/Fi2LnePlC0exNUhP549WbZ5rqT7wCXq+H7RWDY8e0ft1LE2M/dGDMfmN9o240Ry1fHOa4Wy033Jm7oX7BjzNTutbW5aDU55XzGwKrX7GBbecNg5at2cK0nTrH7M/Ns76m+Y8GbDhMvhSOvTG7MSjXB8U+ohnXJ8FJencDkHh7ytKYcMrol7jyqfVXutFPEjTjVPtb/2YP1+7rl27by1W/Y/dpWrhwkpZL7N9sSOAZMeFamak3ujmKMrYF36W9HR1z9BgyYaMdp+fR++/DQ7k3w0R22/MRLbQ+Xr+bCiNOhz2j7o5TDpExyH9g9k3dXbScQNLjj3dcd6mvu/3ua7e/+w/vjfw4VH5U77es/Z8GO1TZ5N9ZlIOzZbIeXOP1+WPMWDPoeTPmF3d/nz+0Xr1IJkDLJfVjPbGr9Qd5duY0TRvWJ/wnCNffdG2HpRk3uHdXSZ+HlK8DlhWCdHcN84qWw+k2o3g3nPA0b/w0f3gaFl8Cpd9n3HXFBcuNWKs5SJrlPH9kbXoLHPv42McldpxnrWNa8Y9vEe4RufH7wNzv3Z+kqm9DTsmDSLDj8x7b8sbPtjfCMbvZBo0NmQN/Dk3gBSiVWyiT3bllpHD+iN5t2Jmo+1S6JOa6KTaAOXrrUjoToy4F/Xgbisgl80cO2TT27N/QZA+c9B7n9Gr4/q0f9sggMmNC+8SvVzlImuQPkZaXx9ZbdiTm41tyTY+27tjdLz8PsY/wrXrbbc/rZoSA+e9C2lV/wQv2E5kqp1EruXTO97K5MUHdInyb3duevhf+73M4HGp6cQty25n3+89B7NFTttP3Pdax9pRpIqeTeJdNLjT/I3ho/2b44X5q30fysweCBTySqllv1ur3BedyNdljbYMD2bnntGtubZV8pHHeTnWZu7Hm2l0tlGfQ8xL4/srlFKbVfSiX3EX1t7fqOt1bzx5mjEnuymnIdIbKtdm2EuaFhirZ+ZcdmKS4CjP1Lqc8YGDYdpv5Hwy/SrLykhKuUk6RUcp9c0B2AJ/69gYu+lx//4X+vXAyLH4ZFc2xzgCb3pgUDsOAGKFtr28vTsuwwt92HwCtX2akL/TV2KNw+Y+x6Rndb1uODU+7Um55KtYEY066TJu1XWFhoioqK4n7c17/6jiuf/RyADbeeEvfj880CePbHcNFrth143IW2O56qt3e7nRP0i6chtz+UbzmwzKAj7Q3QY6+H/hNgXxlkdte2c6WaISJLjDGFzZVLqZo7wDGH9ty/7A8E8bjj3C6eGWoSKHoUlv8f1FXDSbce/D2prLq8vifRjjXw9Yv2ASETtHN/Tvuv+oG4lr0I5SUwYiYUfL/hcbSpRam4Srnknu3zMLp/Lsu2lPNl8R4mDI7zODCZoeOVfGFfAzXxPb5T7N0ORY/Zh4cGToag3w6LC/YhoeNvhn7j7PrQafb1qGuSEalSnVLKJXeAu885guPv/IBnPtuYgOQeqmHu2mBf/Z0suW/6DJ4+ww5/HLan2D40NPFSGHWGbXLRnkRKJVVKJvdhvbI5a8IA3lq+lRp/AJ8njuOv+3Lt6ILB0MQgVQl6aKoj2LXBNjutnm97srjc8OkDUFdpH+fvO87eJNXx7ZXqcFIyuQOcMqYvLy4p5oWiYn4yZXD8Dixi25PDqh2c3Cu2gjvN9lTZ9Clk97TD3VaWwYd32GFvGxsyzc46pDeRlerQYkruIjIDuAc7zd4jxphbG+3/DXAp4AdKgUuMMRvjHGuLHDW8B4f2zuGhD9Zx/qRB8R0GuOcI2L7cDkJVsTV+x20v696DNW/bLp3hv0DCoyi+9xcwATtuy8TL7JgtAyZBlwF2fBdN6ko5QrPJXUTcwH3AdKAYWCwi84wxKyKKfQEUGmMqReQK4DbgnEQEHCuv28U104fzi6c/58+vr+DGU0ci8epmd8ZDsP59m9gXPdzwadUV82z784Bmeyq1j9LVsPhRmDbbNiltXwlP/cjuKzjaTmYxfDoceZV9kOizh2xf88NO1USulIPFUnOfBKw1xqwHEJG5wOnA/uRujFkYUf5T4MJ4BtlaJ47qw1HDevD4xxs49tBeHHNIz+bfFIs+Y+zPZw/Z3jKVZbZJA+CFn9jXP+6Jz7nAdh/M6Ru9D/iOtXbez4mXgi/bJuvIcm/Otv3xFz1kHxIKP65/8XzIn9rwWP2OgB89iFLK+WLp0tAf2ByxXhza1pSfA2+0Jah4EREe/qmtQV/02CKWbNwZ3xOEe87sK4VXrrR9vBur3AnbV7X+HNtXwp0jYPEj0fe/fSO8cxO8ejUDcmPxAAAQ6klEQVR8+xHcMRzmHAtPng7PnmMTuyfDDrKV3QtqKuBHcw5M7EqplBJLzT1aW0bUx1pF5EKgEDimif2zgFkAgwYNijHEtslIc3P1ccO55901/OzxxXz2++PJSItT745wcl/2kn0a84un6/fdNRqm3wz/ugu2fg1/KAN3K+5fr3/fvq55G0acZrte1lTYXiuTL4dv3gzF8KL9AZvMw/3ws3vDz96AvKGtukSllDPFkm2KgYER6wOAksaFROR44L+AY4wxUTt/G2PmAHPADj/Q4mhb6Zrph7CxbB8vLy3hhpeX8T9nj43PgcPJ/dMHDty3ZzP8626b2MHegO0b5bxfPANZPWHY8VC6EnqNtMnbl2ObVzYvsuUqy2yNvOI7e5zvvoSlT4M3E678DD6+15b/wR/se8tL6ies0Ef6lep0Yknui4HhIlIAbAHOBc6PLCAiRwAPATOMMdvjHmUcXDP9EF5eWsLLS7dwwqjenDCyd9tvsGb3tq91Tcz+VFlWv1y2ziblQB0Eau1AWhXb4JVf2v3hhN1rlP0iABh8lJ02DuyXRPhp2O++rD/u0ddC10Fwyh0Nz93lYC1nSqlU12ybuzHGD1wFvAWsBF4wxiwXkVtEZGao2O1ANvAPEVkqIvMSFnErDc7L4r7zxxMIGi5/agkXPb6YZVvaeNMzuxdk9Wp6f21E0t/0ib3Z+dLP4a/9bA+bte/U7w8n7HBiB9j4L6jcYZ/4bDzMwdjzbA+XI69q2zUopVJSyo0KeTDGGE68+0O+2WYfne+R7aPohuPbdtC/F0LZGkjLbvhIfnPOfBTe+1P9MAYAU66ET++Dc56GgmPsnKHffQkXvggPHmXLXPCiPc/IH2pzi1KdUKyjQnaq5B526xurePCDdXhcwjd/PglXWx5wum2IbX4ZMg3WL4xe5uwn4YWfHrjd5YWLX7cPD/Uda78gIHrSLvnCjsA4JOq9aqVUJxFrcu+Uoztdf9Jh3H7W4fiDhvU7mmgvj9XwE+3rkGObLpPTDy57Dy5baHvNhB19LQyaDPlH1d9Abao23u8ITexKqZh1yuQOMG6gnUXpV899gT8QbKb0QZx6F/zHMvt4fqSBU+qXs3vZCSn6j2/YHXLg5NafVymlDqLTJvdhvbKZMLgbK78r5+/vraXVzVPedOg60Naswd78POcZO0RBWHajm66n3mWT/cBJrTunUko1o1O2uUeaeut7bNldxU+PHMwtp49u28G+ftG2vYdnFVr8iO36OOWKtgeqlFJom3vMbjvrcDK8bp78ZCNle9s48caYsxpOFzfxUk3sSqmk6PTJfeqwHsw++TAA/uftb5IcjVJKxUenT+4A508axOSC7jz72SbeW7Ut2eEopVSbaXIHPG4XlxxVAMAlTyT/PoBSSrWVJveQaYf2omumF4DVWyuSHI1SSrWNJveQNI+LW88YA8CP7v84ydEopVTbaHKPMO2wXvTvmkFlbYCq2kCyw1FKqVbT5B7B53Fz65m29n7pk4uTHI1SSrWeJvdGvjfUzjH68doyFizfmuRolFKqdTS5N+J2CQ9cMB6AWU8taf2wBEoplUSa3KM4bkRveuX4ANhYVpnkaJRSquU0uUeR5nHx7GV2xMZLnljctlEjlVIqCTS5N2Foz2zS3C7W79jH55t2JzscpZRqkZiSu4jMEJHVIrJWRK6Psv9oEflcRPwiclb8w2x/IsJHv5sGwJebNbkrpZyl2eQuIm7gPuAkYCRwnoiMbFRsE3Ax8Gy8A0ym3rnpjOybyytfbtEbq0opR4ml5j4JWGuMWW+MqQXmAqdHFjDGbDDGfAWkXOP0eZMGsmxLOa9+9V2yQ1FKqZjFktz7A5sj1otD21pMRGaJSJGIFJWWlrbmEO3ugsmDGdIziyc+/jbZoSilVMxiSe7RZmxuVRuFMWaOMabQGFPYs2fP1hyi3blcwgWTB/P5pt2sKClPdjhKKRWTWJJ7MTAwYn0AUJKYcDqmM8f3x+dx8eAH65IdilJKxSSW5L4YGC4iBSKSBpwLzEtsWB1L18w0fjJlMK99VcKW3VXJDkcppZrVbHI3xviBq4C3gJXAC8aY5SJyi4jMBBCRiSJSDPwYeEhElicy6GQ4b/IgvG4X/z1/ZbJDUUqpZnliKWSMmQ/Mb7TtxojlxdjmmpQ1tGc2508exOMfb+C6E/cxOC8r2SEppVST9AnVFjhlTF8Ajrn9fe33rpTq0DS5t8D4Qd3okW0HFCvZU53kaJRSqmma3FvA5RLm/HQCAP8o2txMaaWUSh5N7i00bkBXZozqw73vrtGeM0qpDkuTewu5XMIfTrND61z/0ldJjkYppaLT5N4K/btmcN6kQXy0Zgf/+eKXyQ5HKaUOoMm9lX593HAAXigqZtG3O5McjVJKNaTJvZV656bzzKV2tqaLHlvEvhp/kiNSSql6mtzbYOqwHtx59liq6gKMuukt/qpPryqlOghN7m10xvgBnDnePpw758P1fP+293hl6ZYkR6WU6uw0ucfBbWcdzi+OGQrA5p1VXD13qXaTVEollSb3OHC7hOtPOowrpw3dv+2Uez+ieFdlEqNSSnVmkqwxUgoLC01RUVFSzp1I/163g1e/LOG5RfYJ1i4ZXhZeeyzds9KSHJlSKhWIyBJjTGFz5bTmHmffG9qD/z7jcG4763AA9lTVMf5Pb/OLp5awrnRvkqNTSnUWWnNPoLK9Ndz86grmfWknrvK6hfMmDaIwvztTh+aRFxqETCmlYhVrzV2TezuoCwR5ZWkJcxdtomjjLgBEYHJBdwoHd2dkv1wmFXTfP+KkUko1RZN7B1VVG+Df63bwxabdvLHsO9aV7tu/75De2fTOTWdQ90ymDutBfl4WI/rmIBJtjnKlVGcU1+QuIjOAewA38Igx5tZG+33Ak8AEoAw4xxiz4WDH7KzJPZIxhnWle/l4bRkbyyrZvKuSTWWVrC3dSyBoP5c0t4t+XdPp2yWDT9aXMXVYHn1yMyivruOCyYMY0TeXrple0twu/RJQqhOINbk3O82eiLiB+4DpQDGwWETmGWNWRBT7ObDLGDNMRM4F/gac07rQOw8RYVivHIb1ymmw3R8I8sn6Mr4q3kNpRQ3Fuyr5Zpu9Gfvx2rL95d5esa3B+3rn+hjYLZMe2T58XhfpHjertlWQ7XNzxMBuHNY3h9x0L1V1AXrl+PC4XGSkueidm06ax6VfEEqlkFjmUJ0ErDXGrAcQkbnA6UBkcj8d+GNo+UXg/4mIGJ2LrlU8bhffH96T7w/v2WC7MYbyKj87K2vZVl7N1j3VVFTXsbW8mr3VfrZX1FC2t5b1O/ayryZAeXUdFdV+fB5Xgy+FJs/rEjLS3HjdLlxiv3xcAlk+DznpXnweFxleN163kOZx7f/rItvnJd3rIsvnwe0SPC7B7RLcoS8Kj9uF2wXpXjdpbheu0D63SyKWwXXANqE2EEQAn8eNweBxuTDGkOXz4BLB5QJBQvECoWWXCC4RROwwzS6x5UQgVKzBuoiEXu12hCb3iTRablxGvyBVBxBLcu8PRE47VAxMbqqMMcYvInuAPGBHPIJUlojQJdNLl0wvBT2an6A7/N0qIlRU17FpZyVVtQHcLmF7RQ0uEXZX1rK7so7aQJDKWj/7agIEgoagMQSNPcb2ihr8QUNVrZ/dlbXUBgw1dQE8bgltD1BdF6C6Log/GAy9P9G/jY4v/AXZ4EsjUviLhvAXU30ZabBPwsX3b5TI7RGHbfy10viLRhrsaxxxo7IHPW7jd8pB9jUdzwERSPTlxudoPr5mznPQvbEUaL7IwWK4+rjhnDa2X/MnaYNYknu0CBv/142lDCIyC5gFMGjQoBhOrdoi8h9XTrqXUf26tNu5g0FDwBiMAX8wSNBAdV2AWn9w/5dH/SsNtgWMse8PGrwe+yhGdV0AQfb/tbCv1o/Z/wUEhvovo/3rQQiG1gMR2+0rYAyG0Psjl6n/Ymz8ngbrpontEccORpSJFC5vVxq87D9uw2315SP/Ho784zjaORqsR5Q4cN/B3msOsq9RPAcp25L4Ghc+8L2xX3djzdU7YmlwaLZEMwW6ZHibPUdbxZLci4GBEesDgJImyhSLiAfoAhwwyLkxZg4wB+wN1dYErJzB5RJcoe/8tNCzctm+WP65KaXiIZYnVBcDw0WkQETSgHOBeY3KzAMuCi2fBbyn7e1KKZU8zValQm3oVwFvYbtCPmaMWS4itwBFxph5wKPAUyKyFltjPzeRQSullDq4mP5ONsbMB+Y32nZjxHI18OP4hqaUUqq1dOAwpZRKQZrclVIqBWlyV0qpFKTJXSmlUpAmd6WUSkFJG/JXREqBja18ew8639AGes2dg15z59CWax5sjOnZXKGkJfe2EJGiWIa8TCV6zZ2DXnPn0B7XrM0ySimVgjS5K6VUCnJqcp+T7ACSQK+5c9Br7hwSfs2ObHNXSil1cE6tuSullDoIxyV3EZkhIqtFZK2IXJ/seOJFRAaKyEIRWSkiy0Xk6tD27iLytoisCb12C20XEbk39Hv4SkTGJ/cKWkdE3CLyhYi8FlovEJHPQtf7fGiYaUTEF1pfG9qfn8y4W0tEuorIiyKyKvRZH9kJPuNrQv+ml4nIcyKSnoqfs4g8JiLbRWRZxLYWf7YiclGo/BoRuSjauWLhqOQu9ZN1nwSMBM4TkZHJjSpu/MBvjTEjgCnAlaFrux541xgzHHg3tA72dzA89DMLeKD9Q46Lq4GVEet/A+4KXe8u7OTrEDEJO3BXqJwT3QO8aYw5DBiLvfaU/YxFpD/wa6DQGDMaO2z4uaTm5/wEMKPRthZ9tiLSHbgJO5XpJOCm8BdCi9kpvZzxAxwJvBWxPhuYney4EnStrwDTgdVA39C2vsDq0PJDwHkR5feXc8oPdlavd4EfAK9hp2vcAXgaf97Y+QSODC17QuUk2dfQwuvNBb5tHHeKf8bh+ZW7hz6314ATU/VzBvKBZa39bIHzgIcitjco15IfR9XciT5Zd/8kxZIwoT9FjwA+A3obY74DCL32ChVLhd/F3cB/AsHQeh6w2xjjD61HXlODSdiB8CTsTjIEKAUeDzVFPSIiWaTwZ2yM2QLcAWwCvsN+bktI7c85Uks/27h95k5L7jFNxO1kIpINvAT8hzGm/GBFo2xzzO9CRE4FthtjlkRujlLUxLDPKTzAeOABY8wRwD7q/0yPxvHXHGpSOB0oAPoBWdgmicZS6XOORVPXGbfrd1pyj2WybscSES82sT9jjPlnaPM2Eekb2t8X2B7a7vTfxVRgpohsAOZim2buBrqGJlmHhte0/3oPNgl7B1cMFBtjPgutv4hN9qn6GQMcD3xrjCk1xtQB/wS+R2p/zpFa+tnG7TN3WnKPZbJuRxIRwc5Fu9IYc2fErsjJxy/CtsWHt/80dNd9CrAn/OefExhjZhtjBhhj8rGf43vGmAuAhdhJ1uHA63X0JOzGmK3AZhE5NLTpOGAFKfoZh2wCpohIZujfePiaU/ZzbqSln+1bwAki0i30V88JoW0tl+wbEK24YXEy8A2wDvivZMcTx+s6Cvvn11fA0tDPydj2xneBNaHX7qHygu05tA74GtsbIenX0cprPxZ4LbQ8BFgErAX+AfhC29ND62tD+4ckO+5WXus4oCj0Ob8MdEv1zxi4GVgFLAOeAnyp+DkDz2HvK9Rha+A/b81nC1wSuv61wM9aG48+oaqUUinIac0ySimlYqDJXSmlUpAmd6WUSkGa3JVSKgVpcldKqRSkyV0ppVKQJnellEpBmtyVUioF/X/JNVe5it+iEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_train, y_train, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.9897 - accuracy: 0.4528 - val_loss: 0.7418 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 620us/step - loss: 0.9950 - accuracy: 0.4717 - val_loss: 0.7347 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.8332 - accuracy: 0.5472 - val_loss: 0.7301 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.8709 - accuracy: 0.5472 - val_loss: 0.7127 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.9477 - accuracy: 0.4717 - val_loss: 0.6976 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.6766 - accuracy: 0.6415 - val_loss: 0.6836 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.7315 - accuracy: 0.5094 - val_loss: 0.6782 - val_accuracy: 0.5106\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.8481 - accuracy: 0.5472 - val_loss: 0.6762 - val_accuracy: 0.5106\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.8545 - accuracy: 0.5094 - val_loss: 0.6761 - val_accuracy: 0.4681\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.7238 - accuracy: 0.6604 - val_loss: 0.6766 - val_accuracy: 0.4468\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.7778 - accuracy: 0.5660 - val_loss: 0.6777 - val_accuracy: 0.4468\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 1.0900 - accuracy: 0.4340 - val_loss: 0.6788 - val_accuracy: 0.4468\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.9844 - accuracy: 0.5660 - val_loss: 0.6820 - val_accuracy: 0.4468\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.7549 - accuracy: 0.5849 - val_loss: 0.6828 - val_accuracy: 0.4468\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.9162 - accuracy: 0.5472 - val_loss: 0.6797 - val_accuracy: 0.4468\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.8701 - accuracy: 0.5472 - val_loss: 0.6806 - val_accuracy: 0.4468\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.8573 - accuracy: 0.5283 - val_loss: 0.6696 - val_accuracy: 0.4468\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.8857 - accuracy: 0.4528 - val_loss: 0.6579 - val_accuracy: 0.4681\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.6849 - accuracy: 0.6038 - val_loss: 0.6429 - val_accuracy: 0.5745\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.8416 - accuracy: 0.5094 - val_loss: 0.6284 - val_accuracy: 0.7447\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.8626 - accuracy: 0.4906 - val_loss: 0.6166 - val_accuracy: 0.7447\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.8759 - accuracy: 0.5283 - val_loss: 0.6043 - val_accuracy: 0.7872\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.7794 - accuracy: 0.5660 - val_loss: 0.5952 - val_accuracy: 0.7447\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6293 - accuracy: 0.6981 - val_loss: 0.5875 - val_accuracy: 0.7660\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.7485 - accuracy: 0.6226 - val_loss: 0.5809 - val_accuracy: 0.7447\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.8101 - accuracy: 0.4906 - val_loss: 0.5737 - val_accuracy: 0.7660\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.6079 - accuracy: 0.6981 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.6634 - accuracy: 0.6226 - val_loss: 0.5617 - val_accuracy: 0.7660\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.7192 - accuracy: 0.6038 - val_loss: 0.5572 - val_accuracy: 0.7872\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.6647 - accuracy: 0.6792 - val_loss: 0.5523 - val_accuracy: 0.7872\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5835 - accuracy: 0.6792 - val_loss: 0.5435 - val_accuracy: 0.7872\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.7519 - accuracy: 0.4906 - val_loss: 0.5350 - val_accuracy: 0.7660\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.6633 - accuracy: 0.6226 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.4808 - accuracy: 0.6604 - val_loss: 0.5161 - val_accuracy: 0.7447\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.7398 - accuracy: 0.6038 - val_loss: 0.5079 - val_accuracy: 0.7660\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.7273 - accuracy: 0.6415 - val_loss: 0.5002 - val_accuracy: 0.7447\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5552 - accuracy: 0.7736 - val_loss: 0.4937 - val_accuracy: 0.7447\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.4855 - accuracy: 0.7547 - val_loss: 0.4886 - val_accuracy: 0.7447\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6528 - accuracy: 0.6604 - val_loss: 0.4840 - val_accuracy: 0.7447\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6343 - accuracy: 0.6226 - val_loss: 0.4816 - val_accuracy: 0.7447\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5697 - accuracy: 0.6792 - val_loss: 0.4795 - val_accuracy: 0.7660\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 643us/step - loss: 0.3995 - accuracy: 0.8302 - val_loss: 0.4772 - val_accuracy: 0.7660\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5173 - accuracy: 0.6792 - val_loss: 0.4737 - val_accuracy: 0.7660\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5327 - accuracy: 0.7925 - val_loss: 0.4720 - val_accuracy: 0.7660\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 0.4738 - accuracy: 0.7170 - val_loss: 0.4704 - val_accuracy: 0.7660\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.4184 - accuracy: 0.8679 - val_loss: 0.4706 - val_accuracy: 0.7660\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5552 - accuracy: 0.7170 - val_loss: 0.4706 - val_accuracy: 0.7660\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.4275 - accuracy: 0.7358 - val_loss: 0.4723 - val_accuracy: 0.7660\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5171 - accuracy: 0.7547 - val_loss: 0.4704 - val_accuracy: 0.7660\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.4649 - accuracy: 0.7358 - val_loss: 0.4695 - val_accuracy: 0.7447\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5591 - accuracy: 0.7547 - val_loss: 0.4702 - val_accuracy: 0.7447\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.4847 - accuracy: 0.7547 - val_loss: 0.4727 - val_accuracy: 0.7660\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3910 - accuracy: 0.8302 - val_loss: 0.4758 - val_accuracy: 0.7660\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.4141 - accuracy: 0.8113 - val_loss: 0.4784 - val_accuracy: 0.7660\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3882 - accuracy: 0.8491 - val_loss: 0.4819 - val_accuracy: 0.7660\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3953 - accuracy: 0.8113 - val_loss: 0.4855 - val_accuracy: 0.7660\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.4460 - accuracy: 0.7925 - val_loss: 0.4889 - val_accuracy: 0.7660\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.4391 - accuracy: 0.7736 - val_loss: 0.4901 - val_accuracy: 0.7660\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3653 - accuracy: 0.8491 - val_loss: 0.4929 - val_accuracy: 0.7660\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.4190 - accuracy: 0.8491 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.4289 - accuracy: 0.8113 - val_loss: 0.4970 - val_accuracy: 0.7660\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.4462 - accuracy: 0.7736 - val_loss: 0.5006 - val_accuracy: 0.7872\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3746 - accuracy: 0.8679 - val_loss: 0.5034 - val_accuracy: 0.7872\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.4255 - accuracy: 0.8679 - val_loss: 0.5073 - val_accuracy: 0.7872\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5151 - accuracy: 0.8113 - val_loss: 0.5116 - val_accuracy: 0.7872\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 725us/step - loss: 0.4174 - accuracy: 0.8113 - val_loss: 0.5147 - val_accuracy: 0.7872\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 660us/step - loss: 0.3044 - accuracy: 0.8491 - val_loss: 0.5180 - val_accuracy: 0.7872\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.4111 - accuracy: 0.8302 - val_loss: 0.5198 - val_accuracy: 0.7872\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3487 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7872\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3722 - accuracy: 0.8302 - val_loss: 0.5226 - val_accuracy: 0.7872\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3272 - accuracy: 0.8679 - val_loss: 0.5219 - val_accuracy: 0.7872\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3695 - accuracy: 0.8302 - val_loss: 0.5201 - val_accuracy: 0.7872\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2850 - accuracy: 0.8679 - val_loss: 0.5181 - val_accuracy: 0.7872\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3987 - accuracy: 0.8302 - val_loss: 0.5151 - val_accuracy: 0.7872\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3362 - accuracy: 0.8868 - val_loss: 0.5113 - val_accuracy: 0.7872\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2963 - accuracy: 0.9057 - val_loss: 0.5104 - val_accuracy: 0.7872\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3407 - accuracy: 0.8679 - val_loss: 0.5094 - val_accuracy: 0.7872\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.3969 - accuracy: 0.9057 - val_loss: 0.5087 - val_accuracy: 0.7872\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.4746 - accuracy: 0.8302 - val_loss: 0.5060 - val_accuracy: 0.7872\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3143 - accuracy: 0.9057 - val_loss: 0.5034 - val_accuracy: 0.8085\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3753 - accuracy: 0.8113 - val_loss: 0.5006 - val_accuracy: 0.8085\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2643 - accuracy: 0.8679 - val_loss: 0.4994 - val_accuracy: 0.8085\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2997 - accuracy: 0.8868 - val_loss: 0.4991 - val_accuracy: 0.8085\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3815 - accuracy: 0.8679 - val_loss: 0.4992 - val_accuracy: 0.8085\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3342 - accuracy: 0.9057 - val_loss: 0.4995 - val_accuracy: 0.8085\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3477 - accuracy: 0.8491 - val_loss: 0.5001 - val_accuracy: 0.8085\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3835 - accuracy: 0.8679 - val_loss: 0.5015 - val_accuracy: 0.8085\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3284 - accuracy: 0.8679 - val_loss: 0.5048 - val_accuracy: 0.7872\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.3030 - accuracy: 0.9057 - val_loss: 0.5098 - val_accuracy: 0.7872\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3223 - accuracy: 0.8679 - val_loss: 0.5145 - val_accuracy: 0.7872\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3232 - accuracy: 0.8679 - val_loss: 0.5216 - val_accuracy: 0.7872\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2587 - accuracy: 0.8868 - val_loss: 0.5278 - val_accuracy: 0.7872\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3410 - accuracy: 0.8679 - val_loss: 0.5299 - val_accuracy: 0.7872\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3142 - accuracy: 0.8868 - val_loss: 0.5289 - val_accuracy: 0.7872\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.3000 - accuracy: 0.8491 - val_loss: 0.5287 - val_accuracy: 0.7872\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3163 - accuracy: 0.8679 - val_loss: 0.5287 - val_accuracy: 0.7872\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2937 - accuracy: 0.8679 - val_loss: 0.5293 - val_accuracy: 0.7872\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3369 - accuracy: 0.8679 - val_loss: 0.5296 - val_accuracy: 0.7872\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3578 - accuracy: 0.8302 - val_loss: 0.5287 - val_accuracy: 0.7872\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2698 - accuracy: 0.9057 - val_loss: 0.5255 - val_accuracy: 0.7872\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 602us/step - loss: 0.3068 - accuracy: 0.8679 - val_loss: 0.5224 - val_accuracy: 0.7872\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3077 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7872\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3517 - accuracy: 0.8491 - val_loss: 0.5133 - val_accuracy: 0.7872\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3029 - accuracy: 0.8868 - val_loss: 0.5108 - val_accuracy: 0.7872\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3077 - accuracy: 0.9057 - val_loss: 0.5107 - val_accuracy: 0.7872\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.2960 - accuracy: 0.9057 - val_loss: 0.5107 - val_accuracy: 0.7872\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2670 - accuracy: 0.8491 - val_loss: 0.5139 - val_accuracy: 0.7872\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2985 - accuracy: 0.9057 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2749 - accuracy: 0.8868 - val_loss: 0.5177 - val_accuracy: 0.7872\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3182 - accuracy: 0.8679 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2654 - accuracy: 0.9245 - val_loss: 0.5158 - val_accuracy: 0.7872\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.4127 - accuracy: 0.8491 - val_loss: 0.5151 - val_accuracy: 0.7872\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2479 - accuracy: 0.8868 - val_loss: 0.5164 - val_accuracy: 0.7872\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2875 - accuracy: 0.8491 - val_loss: 0.5177 - val_accuracy: 0.7872\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2757 - accuracy: 0.8868 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3033 - accuracy: 0.8868 - val_loss: 0.5137 - val_accuracy: 0.7872\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2821 - accuracy: 0.8679 - val_loss: 0.5126 - val_accuracy: 0.7872\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.2828 - accuracy: 0.9057 - val_loss: 0.5104 - val_accuracy: 0.8085\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2791 - accuracy: 0.8491 - val_loss: 0.5105 - val_accuracy: 0.8085\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2929 - accuracy: 0.9057 - val_loss: 0.5124 - val_accuracy: 0.8085\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2488 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.8085\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2432 - accuracy: 0.8679 - val_loss: 0.5187 - val_accuracy: 0.7872\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3135 - accuracy: 0.8679 - val_loss: 0.5210 - val_accuracy: 0.7872\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3887 - accuracy: 0.8491 - val_loss: 0.5199 - val_accuracy: 0.7872\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.4848 - accuracy: 0.8679 - val_loss: 0.5209 - val_accuracy: 0.7872\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.3702 - accuracy: 0.8679 - val_loss: 0.5235 - val_accuracy: 0.7872\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3224 - accuracy: 0.8679 - val_loss: 0.5285 - val_accuracy: 0.7872\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3717 - accuracy: 0.8302 - val_loss: 0.5318 - val_accuracy: 0.7872\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2823 - accuracy: 0.9057 - val_loss: 0.5367 - val_accuracy: 0.7872\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3186 - accuracy: 0.8868 - val_loss: 0.5422 - val_accuracy: 0.7872\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2766 - accuracy: 0.9057 - val_loss: 0.5444 - val_accuracy: 0.7872\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2974 - accuracy: 0.9057 - val_loss: 0.5434 - val_accuracy: 0.7872\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3345 - accuracy: 0.8868 - val_loss: 0.5431 - val_accuracy: 0.7872\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3724 - accuracy: 0.8679 - val_loss: 0.5379 - val_accuracy: 0.7872\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2695 - accuracy: 0.9057 - val_loss: 0.5308 - val_accuracy: 0.7872\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2573 - accuracy: 0.9057 - val_loss: 0.5223 - val_accuracy: 0.7872\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2699 - accuracy: 0.8868 - val_loss: 0.5161 - val_accuracy: 0.7872\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2874 - accuracy: 0.9057 - val_loss: 0.5099 - val_accuracy: 0.7872\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.5044 - val_accuracy: 0.7872\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2908 - accuracy: 0.8679 - val_loss: 0.5007 - val_accuracy: 0.8085\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.3179 - accuracy: 0.8679 - val_loss: 0.5004 - val_accuracy: 0.8085\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2269 - accuracy: 0.9057 - val_loss: 0.5005 - val_accuracy: 0.8085\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2704 - accuracy: 0.8868 - val_loss: 0.4984 - val_accuracy: 0.8085\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3317 - accuracy: 0.8491 - val_loss: 0.4968 - val_accuracy: 0.8085\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2278 - accuracy: 0.9245 - val_loss: 0.4948 - val_accuracy: 0.7872\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2827 - accuracy: 0.8491 - val_loss: 0.4946 - val_accuracy: 0.7872\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2729 - accuracy: 0.9057 - val_loss: 0.4953 - val_accuracy: 0.7872\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2897 - accuracy: 0.8868 - val_loss: 0.4976 - val_accuracy: 0.7872\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2943 - accuracy: 0.9057 - val_loss: 0.5002 - val_accuracy: 0.7872\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2958 - accuracy: 0.9245 - val_loss: 0.5037 - val_accuracy: 0.7872\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2576 - accuracy: 0.8868 - val_loss: 0.5077 - val_accuracy: 0.7872\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2632 - accuracy: 0.8679 - val_loss: 0.5110 - val_accuracy: 0.7872\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3288 - accuracy: 0.8679 - val_loss: 0.5158 - val_accuracy: 0.7872\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2536 - accuracy: 0.8679 - val_loss: 0.5193 - val_accuracy: 0.7872\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2707 - accuracy: 0.9057 - val_loss: 0.5243 - val_accuracy: 0.8085\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2823 - accuracy: 0.8868 - val_loss: 0.5281 - val_accuracy: 0.8085\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 0.2139 - accuracy: 0.9245 - val_loss: 0.5333 - val_accuracy: 0.8085\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3193 - accuracy: 0.8868 - val_loss: 0.5370 - val_accuracy: 0.8298\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3026 - accuracy: 0.9245 - val_loss: 0.5378 - val_accuracy: 0.8298\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2359 - accuracy: 0.8868 - val_loss: 0.5341 - val_accuracy: 0.8298\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2726 - accuracy: 0.8868 - val_loss: 0.5282 - val_accuracy: 0.8298\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2773 - accuracy: 0.8679 - val_loss: 0.5237 - val_accuracy: 0.8085\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5204 - val_accuracy: 0.8085\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2494 - accuracy: 0.9245 - val_loss: 0.5140 - val_accuracy: 0.8085\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2832 - accuracy: 0.8868 - val_loss: 0.5084 - val_accuracy: 0.8085\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2866 - accuracy: 0.9057 - val_loss: 0.5024 - val_accuracy: 0.7872\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2636 - accuracy: 0.9245 - val_loss: 0.4979 - val_accuracy: 0.7872\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3237 - accuracy: 0.8302 - val_loss: 0.4940 - val_accuracy: 0.8085\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3139 - accuracy: 0.8868 - val_loss: 0.4921 - val_accuracy: 0.8085\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3157 - accuracy: 0.8491 - val_loss: 0.4950 - val_accuracy: 0.7872\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2136 - accuracy: 0.9057 - val_loss: 0.4985 - val_accuracy: 0.7872\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.3235 - accuracy: 0.8868 - val_loss: 0.5038 - val_accuracy: 0.8298\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2384 - accuracy: 0.8868 - val_loss: 0.5082 - val_accuracy: 0.8298\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2478 - accuracy: 0.8868 - val_loss: 0.5123 - val_accuracy: 0.8298\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1986 - accuracy: 0.9057 - val_loss: 0.5167 - val_accuracy: 0.8298\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2770 - accuracy: 0.9057 - val_loss: 0.5189 - val_accuracy: 0.8298\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2159 - accuracy: 0.9434 - val_loss: 0.5190 - val_accuracy: 0.8298\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2835 - accuracy: 0.8868 - val_loss: 0.5192 - val_accuracy: 0.8298\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2996 - accuracy: 0.9057 - val_loss: 0.5204 - val_accuracy: 0.8298\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2322 - accuracy: 0.8679 - val_loss: 0.5235 - val_accuracy: 0.8298\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3050 - accuracy: 0.8302 - val_loss: 0.5239 - val_accuracy: 0.8298\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3272 - accuracy: 0.9057 - val_loss: 0.5256 - val_accuracy: 0.8298\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2441 - accuracy: 0.9245 - val_loss: 0.5209 - val_accuracy: 0.8298\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2548 - accuracy: 0.9434 - val_loss: 0.5156 - val_accuracy: 0.8298\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2263 - accuracy: 0.8868 - val_loss: 0.5090 - val_accuracy: 0.8298\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2894 - accuracy: 0.9057 - val_loss: 0.5022 - val_accuracy: 0.8298\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2769 - accuracy: 0.8868 - val_loss: 0.4953 - val_accuracy: 0.8085\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2467 - accuracy: 0.8679 - val_loss: 0.4923 - val_accuracy: 0.8085\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2337 - accuracy: 0.8868 - val_loss: 0.4900 - val_accuracy: 0.8085\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2585 - accuracy: 0.9057 - val_loss: 0.4877 - val_accuracy: 0.8085\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2425 - accuracy: 0.8679 - val_loss: 0.4871 - val_accuracy: 0.8085\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2609 - accuracy: 0.9057 - val_loss: 0.4872 - val_accuracy: 0.8085\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2174 - accuracy: 0.9057 - val_loss: 0.4871 - val_accuracy: 0.8085\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2830 - accuracy: 0.9057 - val_loss: 0.4881 - val_accuracy: 0.8085\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2815 - accuracy: 0.8491 - val_loss: 0.4906 - val_accuracy: 0.8085\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2435 - accuracy: 0.9434 - val_loss: 0.4939 - val_accuracy: 0.8298\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2957 - accuracy: 0.8679 - val_loss: 0.4987 - val_accuracy: 0.8298\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2241 - accuracy: 0.8868 - val_loss: 0.5012 - val_accuracy: 0.8298\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2855 - accuracy: 0.8868 - val_loss: 0.5041 - val_accuracy: 0.8298\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3719 - accuracy: 0.8491 - val_loss: 0.5080 - val_accuracy: 0.8298\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2376 - accuracy: 0.8868 - val_loss: 0.5095 - val_accuracy: 0.8298\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2416 - accuracy: 0.8679 - val_loss: 0.5074 - val_accuracy: 0.8298\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2379 - accuracy: 0.8679 - val_loss: 0.5042 - val_accuracy: 0.8298\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2760 - accuracy: 0.9057 - val_loss: 0.4972 - val_accuracy: 0.8298\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2346 - accuracy: 0.9057 - val_loss: 0.4901 - val_accuracy: 0.8298\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2528 - accuracy: 0.9245 - val_loss: 0.4832 - val_accuracy: 0.8085\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2145 - accuracy: 0.9245 - val_loss: 0.4779 - val_accuracy: 0.8085\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2483 - accuracy: 0.8868 - val_loss: 0.4751 - val_accuracy: 0.8085\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1848 - accuracy: 0.9245 - val_loss: 0.4733 - val_accuracy: 0.8085\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2555 - accuracy: 0.9434 - val_loss: 0.4713 - val_accuracy: 0.8085\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2164 - accuracy: 0.9057 - val_loss: 0.4690 - val_accuracy: 0.8085\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2435 - accuracy: 0.9057 - val_loss: 0.4661 - val_accuracy: 0.8085\n",
      "Epoch 213/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 734us/step - loss: 0.2389 - accuracy: 0.9057 - val_loss: 0.4646 - val_accuracy: 0.8085\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2522 - accuracy: 0.8868 - val_loss: 0.4638 - val_accuracy: 0.8085\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2523 - accuracy: 0.8679 - val_loss: 0.4642 - val_accuracy: 0.8085\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1871 - accuracy: 0.9057 - val_loss: 0.4634 - val_accuracy: 0.8085\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2613 - accuracy: 0.8679 - val_loss: 0.4641 - val_accuracy: 0.8085\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1947 - accuracy: 0.9245 - val_loss: 0.4657 - val_accuracy: 0.8085\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2068 - accuracy: 0.9245 - val_loss: 0.4680 - val_accuracy: 0.8085\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2380 - accuracy: 0.9057 - val_loss: 0.4704 - val_accuracy: 0.8085\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3159 - accuracy: 0.8679 - val_loss: 0.4735 - val_accuracy: 0.8085\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2380 - accuracy: 0.8868 - val_loss: 0.4748 - val_accuracy: 0.8085\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2383 - accuracy: 0.9245 - val_loss: 0.4760 - val_accuracy: 0.8085\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2364 - accuracy: 0.8868 - val_loss: 0.4772 - val_accuracy: 0.8085\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1814 - accuracy: 0.9434 - val_loss: 0.4779 - val_accuracy: 0.8085\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2563 - accuracy: 0.8868 - val_loss: 0.4813 - val_accuracy: 0.8085\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1971 - accuracy: 0.9623 - val_loss: 0.4819 - val_accuracy: 0.8085\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1855 - accuracy: 0.9623 - val_loss: 0.4830 - val_accuracy: 0.8085\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3258 - accuracy: 0.8868 - val_loss: 0.4855 - val_accuracy: 0.8085\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3279 - accuracy: 0.8491 - val_loss: 0.4860 - val_accuracy: 0.8085\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1710 - accuracy: 0.9434 - val_loss: 0.4873 - val_accuracy: 0.8085\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3408 - accuracy: 0.8679 - val_loss: 0.4877 - val_accuracy: 0.8085\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3031 - accuracy: 0.8868 - val_loss: 0.4851 - val_accuracy: 0.8085\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2376 - accuracy: 0.9057 - val_loss: 0.4824 - val_accuracy: 0.8085\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2219 - accuracy: 0.9245 - val_loss: 0.4816 - val_accuracy: 0.8085\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2340 - accuracy: 0.9057 - val_loss: 0.4816 - val_accuracy: 0.8085\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1952 - accuracy: 0.9057 - val_loss: 0.4815 - val_accuracy: 0.8085\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2355 - accuracy: 0.8868 - val_loss: 0.4815 - val_accuracy: 0.8085\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2910 - accuracy: 0.8868 - val_loss: 0.4815 - val_accuracy: 0.8085\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.4809 - val_accuracy: 0.8085\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2119 - accuracy: 0.9245 - val_loss: 0.4795 - val_accuracy: 0.8085\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2056 - accuracy: 0.9057 - val_loss: 0.4790 - val_accuracy: 0.8085\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2209 - accuracy: 0.9057 - val_loss: 0.4786 - val_accuracy: 0.8085\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2260 - accuracy: 0.8868 - val_loss: 0.4782 - val_accuracy: 0.8085\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2014 - accuracy: 0.9057 - val_loss: 0.4777 - val_accuracy: 0.8085\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2218 - accuracy: 0.8868 - val_loss: 0.4787 - val_accuracy: 0.8085\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2779 - accuracy: 0.9057 - val_loss: 0.4763 - val_accuracy: 0.8085\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2324 - accuracy: 0.9057 - val_loss: 0.4755 - val_accuracy: 0.8085\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.1887 - accuracy: 0.9245 - val_loss: 0.4756 - val_accuracy: 0.8085\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1696 - accuracy: 0.9245 - val_loss: 0.4748 - val_accuracy: 0.8085\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1883 - accuracy: 0.9245 - val_loss: 0.4734 - val_accuracy: 0.8085\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2088 - accuracy: 0.9434 - val_loss: 0.4722 - val_accuracy: 0.8085\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2392 - accuracy: 0.8868 - val_loss: 0.4713 - val_accuracy: 0.8085\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2022 - accuracy: 0.9057 - val_loss: 0.4708 - val_accuracy: 0.8085\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2297 - accuracy: 0.9057 - val_loss: 0.4680 - val_accuracy: 0.8085\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3350 - accuracy: 0.8679 - val_loss: 0.4663 - val_accuracy: 0.8085\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1885 - accuracy: 0.9434 - val_loss: 0.4637 - val_accuracy: 0.8085\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3607 - accuracy: 0.8679 - val_loss: 0.4619 - val_accuracy: 0.8085\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2600 - accuracy: 0.8491 - val_loss: 0.4590 - val_accuracy: 0.8085\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2143 - accuracy: 0.8868 - val_loss: 0.4576 - val_accuracy: 0.8085\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1754 - accuracy: 0.8868 - val_loss: 0.4572 - val_accuracy: 0.8085\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2475 - accuracy: 0.9057 - val_loss: 0.4563 - val_accuracy: 0.8085\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2413 - accuracy: 0.9434 - val_loss: 0.4563 - val_accuracy: 0.8085\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1784 - accuracy: 0.9434 - val_loss: 0.4556 - val_accuracy: 0.8085\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2539 - accuracy: 0.8868 - val_loss: 0.4551 - val_accuracy: 0.8085\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1743 - accuracy: 0.9245 - val_loss: 0.4549 - val_accuracy: 0.8085\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1997 - accuracy: 0.9245 - val_loss: 0.4542 - val_accuracy: 0.8085\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2148 - accuracy: 0.9057 - val_loss: 0.4545 - val_accuracy: 0.8085\n",
      "Epoch 269/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.1930 - accuracy: 0.9057 - val_loss: 0.4559 - val_accuracy: 0.8085\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.3012 - accuracy: 0.8679 - val_loss: 0.4563 - val_accuracy: 0.8085\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2457 - accuracy: 0.9057 - val_loss: 0.4583 - val_accuracy: 0.8085\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2323 - accuracy: 0.8679 - val_loss: 0.4621 - val_accuracy: 0.8085\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2373 - accuracy: 0.9057 - val_loss: 0.4662 - val_accuracy: 0.8085\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2842 - accuracy: 0.8868 - val_loss: 0.4690 - val_accuracy: 0.8298\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2561 - accuracy: 0.9057 - val_loss: 0.4692 - val_accuracy: 0.8298\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2149 - accuracy: 0.9057 - val_loss: 0.4696 - val_accuracy: 0.8298\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2100 - accuracy: 0.9057 - val_loss: 0.4703 - val_accuracy: 0.8298\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1910 - accuracy: 0.9057 - val_loss: 0.4704 - val_accuracy: 0.8298\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2076 - accuracy: 0.9057 - val_loss: 0.4683 - val_accuracy: 0.8298\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1889 - accuracy: 0.9434 - val_loss: 0.4653 - val_accuracy: 0.8298\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2612 - accuracy: 0.9434 - val_loss: 0.4635 - val_accuracy: 0.8298\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1805 - accuracy: 0.9245 - val_loss: 0.4618 - val_accuracy: 0.8085\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2265 - accuracy: 0.9245 - val_loss: 0.4604 - val_accuracy: 0.8085\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2553 - accuracy: 0.9057 - val_loss: 0.4568 - val_accuracy: 0.8085\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 928us/step - loss: 0.2393 - accuracy: 0.9434 - val_loss: 0.4539 - val_accuracy: 0.8085\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2571 - accuracy: 0.8679 - val_loss: 0.4520 - val_accuracy: 0.8085\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.4513 - val_accuracy: 0.8085\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1989 - accuracy: 0.9245 - val_loss: 0.4506 - val_accuracy: 0.8085\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2738 - accuracy: 0.8868 - val_loss: 0.4483 - val_accuracy: 0.8085\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2586 - accuracy: 0.8491 - val_loss: 0.4472 - val_accuracy: 0.8085\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2310 - accuracy: 0.9245 - val_loss: 0.4451 - val_accuracy: 0.8085\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1987 - accuracy: 0.9057 - val_loss: 0.4443 - val_accuracy: 0.8085\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2103 - accuracy: 0.9057 - val_loss: 0.4430 - val_accuracy: 0.8085\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2478 - accuracy: 0.9057 - val_loss: 0.4419 - val_accuracy: 0.8085\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1714 - accuracy: 0.9057 - val_loss: 0.4406 - val_accuracy: 0.8085\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2138 - accuracy: 0.9245 - val_loss: 0.4378 - val_accuracy: 0.8085\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1844 - accuracy: 0.9245 - val_loss: 0.4371 - val_accuracy: 0.8085\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1631 - accuracy: 0.9623 - val_loss: 0.4369 - val_accuracy: 0.8085\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2016 - accuracy: 0.9245 - val_loss: 0.4368 - val_accuracy: 0.8085\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2812 - accuracy: 0.8868 - val_loss: 0.4367 - val_accuracy: 0.8085\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2797 - accuracy: 0.8868 - val_loss: 0.4349 - val_accuracy: 0.8085\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2183 - accuracy: 0.9057 - val_loss: 0.4353 - val_accuracy: 0.8085\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1856 - accuracy: 0.9434 - val_loss: 0.4370 - val_accuracy: 0.8085\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1951 - accuracy: 0.9245 - val_loss: 0.4377 - val_accuracy: 0.8085\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2303 - accuracy: 0.9057 - val_loss: 0.4367 - val_accuracy: 0.8085\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1417 - accuracy: 0.9434 - val_loss: 0.4346 - val_accuracy: 0.8085\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1791 - accuracy: 0.9434 - val_loss: 0.4341 - val_accuracy: 0.8085\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2355 - accuracy: 0.9057 - val_loss: 0.4342 - val_accuracy: 0.8085\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1912 - accuracy: 0.8868 - val_loss: 0.4347 - val_accuracy: 0.8085\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1989 - accuracy: 0.9434 - val_loss: 0.4369 - val_accuracy: 0.8085\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2467 - accuracy: 0.9057 - val_loss: 0.4385 - val_accuracy: 0.8085\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2186 - accuracy: 0.9057 - val_loss: 0.4410 - val_accuracy: 0.8085\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2125 - accuracy: 0.9245 - val_loss: 0.4421 - val_accuracy: 0.8085\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2224 - accuracy: 0.8868 - val_loss: 0.4422 - val_accuracy: 0.8085\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2226 - accuracy: 0.8868 - val_loss: 0.4429 - val_accuracy: 0.8085\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1794 - accuracy: 0.9434 - val_loss: 0.4435 - val_accuracy: 0.8085\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 655us/step - loss: 0.1549 - accuracy: 0.9434 - val_loss: 0.4448 - val_accuracy: 0.8085\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2255 - accuracy: 0.8868 - val_loss: 0.4452 - val_accuracy: 0.8085\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2459 - accuracy: 0.8868 - val_loss: 0.4440 - val_accuracy: 0.8085\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2311 - accuracy: 0.9057 - val_loss: 0.4448 - val_accuracy: 0.8085\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2330 - accuracy: 0.9245 - val_loss: 0.4449 - val_accuracy: 0.8085\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1527 - accuracy: 0.9623 - val_loss: 0.4442 - val_accuracy: 0.8085\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2055 - accuracy: 0.9057 - val_loss: 0.4434 - val_accuracy: 0.8085\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1786 - accuracy: 0.9434 - val_loss: 0.4410 - val_accuracy: 0.8085\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 884us/step - loss: 0.2232 - accuracy: 0.9434 - val_loss: 0.4375 - val_accuracy: 0.8085\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2334 - accuracy: 0.8868 - val_loss: 0.4365 - val_accuracy: 0.8085\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2126 - accuracy: 0.9623 - val_loss: 0.4360 - val_accuracy: 0.8085\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2616 - accuracy: 0.8679 - val_loss: 0.4363 - val_accuracy: 0.8085\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2439 - accuracy: 0.8868 - val_loss: 0.4355 - val_accuracy: 0.8085\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2102 - accuracy: 0.9434 - val_loss: 0.4383 - val_accuracy: 0.8085\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.1842 - accuracy: 0.9434 - val_loss: 0.4390 - val_accuracy: 0.8085\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2165 - accuracy: 0.8868 - val_loss: 0.4400 - val_accuracy: 0.8085\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2512 - accuracy: 0.9245 - val_loss: 0.4408 - val_accuracy: 0.8085\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 706us/step - loss: 0.2196 - accuracy: 0.9057 - val_loss: 0.4412 - val_accuracy: 0.8085\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2465 - accuracy: 0.8868 - val_loss: 0.4418 - val_accuracy: 0.8298\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2455 - accuracy: 0.9245 - val_loss: 0.4405 - val_accuracy: 0.8085\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1922 - accuracy: 0.8868 - val_loss: 0.4372 - val_accuracy: 0.8085\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1569 - accuracy: 0.9434 - val_loss: 0.4351 - val_accuracy: 0.8085\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2267 - accuracy: 0.8868 - val_loss: 0.4345 - val_accuracy: 0.8085\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2183 - accuracy: 0.9434 - val_loss: 0.4327 - val_accuracy: 0.8085\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1997 - accuracy: 0.9245 - val_loss: 0.4309 - val_accuracy: 0.8085\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2230 - accuracy: 0.9057 - val_loss: 0.4284 - val_accuracy: 0.8085\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1691 - accuracy: 0.9245 - val_loss: 0.4254 - val_accuracy: 0.8085\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1518 - accuracy: 0.9434 - val_loss: 0.4247 - val_accuracy: 0.8085\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2129 - accuracy: 0.9245 - val_loss: 0.4261 - val_accuracy: 0.8085\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2050 - accuracy: 0.9245 - val_loss: 0.4261 - val_accuracy: 0.8085\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1867 - accuracy: 0.9245 - val_loss: 0.4274 - val_accuracy: 0.8085\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1789 - accuracy: 0.9245 - val_loss: 0.4303 - val_accuracy: 0.8085\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2193 - accuracy: 0.9245 - val_loss: 0.4341 - val_accuracy: 0.8085\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2212 - accuracy: 0.9057 - val_loss: 0.4387 - val_accuracy: 0.8085\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1900 - accuracy: 0.9245 - val_loss: 0.4422 - val_accuracy: 0.8298\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2122 - accuracy: 0.9434 - val_loss: 0.4471 - val_accuracy: 0.8298\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2017 - accuracy: 0.9057 - val_loss: 0.4517 - val_accuracy: 0.8298\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1586 - accuracy: 0.9245 - val_loss: 0.4539 - val_accuracy: 0.8298\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2178 - accuracy: 0.9057 - val_loss: 0.4555 - val_accuracy: 0.8298\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1646 - accuracy: 0.9434 - val_loss: 0.4561 - val_accuracy: 0.8298\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1773 - accuracy: 0.9245 - val_loss: 0.4558 - val_accuracy: 0.8298\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2073 - accuracy: 0.9057 - val_loss: 0.4551 - val_accuracy: 0.8298\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1740 - accuracy: 0.9057 - val_loss: 0.4538 - val_accuracy: 0.8298\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1705 - accuracy: 0.9245 - val_loss: 0.4518 - val_accuracy: 0.8298\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1606 - accuracy: 0.9245 - val_loss: 0.4504 - val_accuracy: 0.8298\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1069 - accuracy: 0.9623 - val_loss: 0.4503 - val_accuracy: 0.8298\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2156 - accuracy: 0.9245 - val_loss: 0.4475 - val_accuracy: 0.8085\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2187 - accuracy: 0.9057 - val_loss: 0.4455 - val_accuracy: 0.8085\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1596 - accuracy: 0.9245 - val_loss: 0.4423 - val_accuracy: 0.8085\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1851 - accuracy: 0.9245 - val_loss: 0.4400 - val_accuracy: 0.8085\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2167 - accuracy: 0.8868 - val_loss: 0.4389 - val_accuracy: 0.8085\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1316 - accuracy: 0.9623 - val_loss: 0.4394 - val_accuracy: 0.8085\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1787 - accuracy: 0.9245 - val_loss: 0.4386 - val_accuracy: 0.8085\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1502 - accuracy: 0.9623 - val_loss: 0.4382 - val_accuracy: 0.8085\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2262 - accuracy: 0.9245 - val_loss: 0.4381 - val_accuracy: 0.8085\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2171 - accuracy: 0.8868 - val_loss: 0.4382 - val_accuracy: 0.8298\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1436 - accuracy: 0.9057 - val_loss: 0.4373 - val_accuracy: 0.8298\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2384 - accuracy: 0.9245 - val_loss: 0.4372 - val_accuracy: 0.8298\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2093 - accuracy: 0.9057 - val_loss: 0.4369 - val_accuracy: 0.8298\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.3002 - accuracy: 0.9057 - val_loss: 0.4359 - val_accuracy: 0.8298\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2584 - accuracy: 0.9057 - val_loss: 0.4364 - val_accuracy: 0.8085\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1681 - accuracy: 0.9434 - val_loss: 0.4362 - val_accuracy: 0.8085\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1822 - accuracy: 0.9245 - val_loss: 0.4355 - val_accuracy: 0.8085\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1483 - accuracy: 0.9434 - val_loss: 0.4341 - val_accuracy: 0.8085\n",
      "Epoch 381/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.1753 - accuracy: 0.9434 - val_loss: 0.4336 - val_accuracy: 0.8085\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 704us/step - loss: 0.1635 - accuracy: 0.9623 - val_loss: 0.4313 - val_accuracy: 0.8085\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2265 - accuracy: 0.9057 - val_loss: 0.4309 - val_accuracy: 0.8085\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1830 - accuracy: 0.9245 - val_loss: 0.4308 - val_accuracy: 0.8085\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 608us/step - loss: 0.1684 - accuracy: 0.9245 - val_loss: 0.4306 - val_accuracy: 0.8085\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1969 - accuracy: 0.9434 - val_loss: 0.4315 - val_accuracy: 0.8085\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1919 - accuracy: 0.9245 - val_loss: 0.4326 - val_accuracy: 0.8085\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1827 - accuracy: 0.9057 - val_loss: 0.4324 - val_accuracy: 0.8298\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2069 - accuracy: 0.9057 - val_loss: 0.4327 - val_accuracy: 0.8298\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1344 - accuracy: 0.9434 - val_loss: 0.4353 - val_accuracy: 0.8298\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1511 - accuracy: 0.9434 - val_loss: 0.4366 - val_accuracy: 0.8298\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1885 - accuracy: 0.9245 - val_loss: 0.4371 - val_accuracy: 0.8298\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2316 - accuracy: 0.9623 - val_loss: 0.4381 - val_accuracy: 0.8298\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2707 - accuracy: 0.9057 - val_loss: 0.4368 - val_accuracy: 0.8298\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1973 - accuracy: 0.9623 - val_loss: 0.4341 - val_accuracy: 0.8298\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2262 - accuracy: 0.8868 - val_loss: 0.4308 - val_accuracy: 0.8298\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1580 - accuracy: 0.9623 - val_loss: 0.4294 - val_accuracy: 0.8298\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2136 - accuracy: 0.8868 - val_loss: 0.4271 - val_accuracy: 0.8298\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1601 - accuracy: 0.9434 - val_loss: 0.4250 - val_accuracy: 0.8298\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1786 - accuracy: 0.8868 - val_loss: 0.4237 - val_accuracy: 0.8298\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2190 - accuracy: 0.8868 - val_loss: 0.4212 - val_accuracy: 0.8511\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1957 - accuracy: 0.9245 - val_loss: 0.4174 - val_accuracy: 0.8511\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2019 - accuracy: 0.9057 - val_loss: 0.4152 - val_accuracy: 0.8511\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2177 - accuracy: 0.9434 - val_loss: 0.4149 - val_accuracy: 0.8511\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1311 - accuracy: 0.9623 - val_loss: 0.4138 - val_accuracy: 0.8511\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2077 - accuracy: 0.8679 - val_loss: 0.4151 - val_accuracy: 0.8511\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2041 - accuracy: 0.9057 - val_loss: 0.4171 - val_accuracy: 0.8511\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1731 - accuracy: 0.9245 - val_loss: 0.4193 - val_accuracy: 0.8298\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2867 - accuracy: 0.8679 - val_loss: 0.4204 - val_accuracy: 0.8298\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1980 - accuracy: 0.9245 - val_loss: 0.4228 - val_accuracy: 0.8298\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1695 - accuracy: 0.9623 - val_loss: 0.4242 - val_accuracy: 0.8298\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2501 - accuracy: 0.9245 - val_loss: 0.4237 - val_accuracy: 0.8298\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1718 - accuracy: 0.9434 - val_loss: 0.4232 - val_accuracy: 0.8298\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1498 - accuracy: 0.9623 - val_loss: 0.4224 - val_accuracy: 0.8298\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1652 - accuracy: 0.9623 - val_loss: 0.4207 - val_accuracy: 0.8298\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1880 - accuracy: 0.9245 - val_loss: 0.4179 - val_accuracy: 0.8298\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2150 - accuracy: 0.9245 - val_loss: 0.4164 - val_accuracy: 0.8298\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2113 - accuracy: 0.9057 - val_loss: 0.4160 - val_accuracy: 0.8298\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1570 - accuracy: 0.9434 - val_loss: 0.4154 - val_accuracy: 0.8298\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1866 - accuracy: 0.9434 - val_loss: 0.4151 - val_accuracy: 0.8298\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2262 - accuracy: 0.8868 - val_loss: 0.4136 - val_accuracy: 0.8298\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2653 - accuracy: 0.8868 - val_loss: 0.4105 - val_accuracy: 0.8298\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2599 - accuracy: 0.9245 - val_loss: 0.4070 - val_accuracy: 0.8511\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1877 - accuracy: 0.8868 - val_loss: 0.4034 - val_accuracy: 0.8511\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2145 - accuracy: 0.9057 - val_loss: 0.3989 - val_accuracy: 0.8298\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1614 - accuracy: 0.9434 - val_loss: 0.3978 - val_accuracy: 0.8298\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2094 - accuracy: 0.9057 - val_loss: 0.3978 - val_accuracy: 0.8298\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1741 - accuracy: 0.9245 - val_loss: 0.3975 - val_accuracy: 0.8298\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1800 - accuracy: 0.9623 - val_loss: 0.3966 - val_accuracy: 0.8298\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1858 - accuracy: 0.9434 - val_loss: 0.3980 - val_accuracy: 0.8298\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1519 - accuracy: 0.9245 - val_loss: 0.3999 - val_accuracy: 0.8298\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2266 - accuracy: 0.9057 - val_loss: 0.4017 - val_accuracy: 0.8511\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2425 - accuracy: 0.9057 - val_loss: 0.4015 - val_accuracy: 0.8511\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1388 - accuracy: 0.9623 - val_loss: 0.4022 - val_accuracy: 0.8511\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1814 - accuracy: 0.9245 - val_loss: 0.4033 - val_accuracy: 0.8511\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1749 - accuracy: 0.9245 - val_loss: 0.4043 - val_accuracy: 0.8511\n",
      "Epoch 437/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 583us/step - loss: 0.1607 - accuracy: 0.9434 - val_loss: 0.4041 - val_accuracy: 0.8511\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1647 - accuracy: 0.9245 - val_loss: 0.4036 - val_accuracy: 0.8511\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2062 - accuracy: 0.9434 - val_loss: 0.4035 - val_accuracy: 0.8511\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1552 - accuracy: 0.9811 - val_loss: 0.4028 - val_accuracy: 0.8511\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2144 - accuracy: 0.9057 - val_loss: 0.4020 - val_accuracy: 0.8511\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2646 - accuracy: 0.9057 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1579 - accuracy: 0.9434 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1946 - accuracy: 0.9057 - val_loss: 0.4026 - val_accuracy: 0.8511\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1476 - accuracy: 0.9434 - val_loss: 0.4025 - val_accuracy: 0.8511\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1301 - accuracy: 0.9623 - val_loss: 0.4022 - val_accuracy: 0.8511\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1841 - accuracy: 0.9245 - val_loss: 0.4019 - val_accuracy: 0.8511\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1560 - accuracy: 0.9623 - val_loss: 0.4020 - val_accuracy: 0.8511\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1911 - accuracy: 0.9245 - val_loss: 0.4021 - val_accuracy: 0.8511\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1205 - accuracy: 0.9811 - val_loss: 0.4024 - val_accuracy: 0.8511\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2093 - accuracy: 0.9434 - val_loss: 0.4027 - val_accuracy: 0.8511\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1840 - accuracy: 0.9245 - val_loss: 0.4055 - val_accuracy: 0.8511\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2098 - accuracy: 0.9245 - val_loss: 0.4075 - val_accuracy: 0.8511\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2263 - accuracy: 0.9057 - val_loss: 0.4087 - val_accuracy: 0.8511\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1641 - accuracy: 0.9434 - val_loss: 0.4094 - val_accuracy: 0.8511\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2046 - accuracy: 0.9245 - val_loss: 0.4099 - val_accuracy: 0.8511\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1725 - accuracy: 0.9245 - val_loss: 0.4108 - val_accuracy: 0.8511\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1775 - accuracy: 0.9434 - val_loss: 0.4092 - val_accuracy: 0.8511\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1200 - accuracy: 0.9811 - val_loss: 0.4068 - val_accuracy: 0.8511\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1809 - accuracy: 0.9245 - val_loss: 0.4045 - val_accuracy: 0.8511\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1987 - accuracy: 0.9057 - val_loss: 0.4034 - val_accuracy: 0.8511\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1754 - accuracy: 0.9434 - val_loss: 0.4023 - val_accuracy: 0.8511\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1438 - accuracy: 0.9623 - val_loss: 0.4005 - val_accuracy: 0.8511\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2340 - accuracy: 0.8868 - val_loss: 0.3980 - val_accuracy: 0.8511\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1372 - accuracy: 0.9623 - val_loss: 0.3976 - val_accuracy: 0.8511\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1179 - accuracy: 0.9245 - val_loss: 0.3979 - val_accuracy: 0.8511\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1332 - accuracy: 0.9623 - val_loss: 0.3986 - val_accuracy: 0.8511\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1845 - accuracy: 0.9245 - val_loss: 0.4020 - val_accuracy: 0.8511\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1814 - accuracy: 0.9245 - val_loss: 0.4044 - val_accuracy: 0.8511\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1007 - accuracy: 0.9811 - val_loss: 0.4066 - val_accuracy: 0.8511\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1695 - accuracy: 0.9434 - val_loss: 0.4084 - val_accuracy: 0.8511\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 644us/step - loss: 0.2053 - accuracy: 0.9057 - val_loss: 0.4080 - val_accuracy: 0.8511\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1464 - accuracy: 0.9623 - val_loss: 0.4068 - val_accuracy: 0.8511\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1258 - accuracy: 0.9623 - val_loss: 0.4055 - val_accuracy: 0.8511\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1593 - accuracy: 0.9434 - val_loss: 0.4062 - val_accuracy: 0.8511\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1156 - accuracy: 0.9623 - val_loss: 0.4071 - val_accuracy: 0.8511\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1480 - accuracy: 0.9434 - val_loss: 0.4054 - val_accuracy: 0.8511\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1785 - accuracy: 0.9245 - val_loss: 0.4033 - val_accuracy: 0.8511\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1555 - accuracy: 0.9245 - val_loss: 0.4027 - val_accuracy: 0.8511\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2170 - accuracy: 0.8868 - val_loss: 0.4020 - val_accuracy: 0.8511\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1876 - accuracy: 0.8868 - val_loss: 0.4039 - val_accuracy: 0.8511\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1534 - accuracy: 0.9434 - val_loss: 0.4057 - val_accuracy: 0.8511\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1917 - accuracy: 0.9434 - val_loss: 0.4053 - val_accuracy: 0.8511\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1966 - accuracy: 0.9245 - val_loss: 0.4031 - val_accuracy: 0.8511\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1096 - accuracy: 0.9623 - val_loss: 0.4018 - val_accuracy: 0.8511\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1659 - accuracy: 0.9434 - val_loss: 0.4001 - val_accuracy: 0.8511\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1700 - accuracy: 0.9434 - val_loss: 0.4011 - val_accuracy: 0.8511\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1587 - accuracy: 0.9245 - val_loss: 0.4038 - val_accuracy: 0.8511\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1344 - accuracy: 0.9623 - val_loss: 0.4069 - val_accuracy: 0.8511\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2154 - accuracy: 0.9434 - val_loss: 0.4100 - val_accuracy: 0.8511\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1863 - accuracy: 0.9245 - val_loss: 0.4129 - val_accuracy: 0.8511\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1154 - accuracy: 0.9623 - val_loss: 0.4153 - val_accuracy: 0.8511\n",
      "Epoch 493/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 583us/step - loss: 0.1344 - accuracy: 0.9623 - val_loss: 0.4155 - val_accuracy: 0.8511\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1589 - accuracy: 0.9434 - val_loss: 0.4155 - val_accuracy: 0.8511\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2068 - accuracy: 0.9057 - val_loss: 0.4136 - val_accuracy: 0.8511\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1644 - accuracy: 0.9057 - val_loss: 0.4129 - val_accuracy: 0.8511\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1446 - accuracy: 0.9245 - val_loss: 0.4101 - val_accuracy: 0.8511\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1510 - accuracy: 0.9434 - val_loss: 0.4081 - val_accuracy: 0.8511\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1314 - accuracy: 0.9623 - val_loss: 0.4065 - val_accuracy: 0.8511\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1537 - accuracy: 0.9245 - val_loss: 0.4062 - val_accuracy: 0.8511\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1862 - accuracy: 0.9434 - val_loss: 0.4053 - val_accuracy: 0.8511\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1567 - accuracy: 0.9434 - val_loss: 0.4035 - val_accuracy: 0.8511\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1368 - accuracy: 0.9434 - val_loss: 0.3986 - val_accuracy: 0.8511\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1560 - accuracy: 0.9434 - val_loss: 0.3948 - val_accuracy: 0.8511\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1338 - accuracy: 0.9434 - val_loss: 0.3914 - val_accuracy: 0.8511\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1540 - accuracy: 0.9057 - val_loss: 0.3894 - val_accuracy: 0.8511\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1061 - accuracy: 0.9811 - val_loss: 0.3872 - val_accuracy: 0.8511\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2179 - accuracy: 0.9434 - val_loss: 0.3841 - val_accuracy: 0.8511\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1556 - accuracy: 0.9245 - val_loss: 0.3807 - val_accuracy: 0.8723\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1574 - accuracy: 0.9057 - val_loss: 0.3786 - val_accuracy: 0.8723\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1936 - accuracy: 0.9434 - val_loss: 0.3763 - val_accuracy: 0.8723\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1376 - accuracy: 0.9434 - val_loss: 0.3748 - val_accuracy: 0.8723\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1310 - accuracy: 0.9623 - val_loss: 0.3747 - val_accuracy: 0.8723\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2072 - accuracy: 0.9057 - val_loss: 0.3760 - val_accuracy: 0.8723\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1240 - accuracy: 0.9623 - val_loss: 0.3776 - val_accuracy: 0.8723\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1992 - accuracy: 0.9245 - val_loss: 0.3776 - val_accuracy: 0.8723\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1184 - accuracy: 0.9623 - val_loss: 0.3774 - val_accuracy: 0.8723\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2333 - accuracy: 0.8868 - val_loss: 0.3777 - val_accuracy: 0.8723\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1472 - accuracy: 0.9245 - val_loss: 0.3788 - val_accuracy: 0.8723\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1388 - accuracy: 0.9623 - val_loss: 0.3794 - val_accuracy: 0.8723\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1324 - accuracy: 0.9245 - val_loss: 0.3794 - val_accuracy: 0.8723\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1422 - accuracy: 0.9434 - val_loss: 0.3793 - val_accuracy: 0.8723\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1015 - accuracy: 0.9623 - val_loss: 0.3799 - val_accuracy: 0.8511\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1618 - accuracy: 0.9245 - val_loss: 0.3815 - val_accuracy: 0.8511\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1768 - accuracy: 0.9434 - val_loss: 0.3834 - val_accuracy: 0.8511\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9434 - val_loss: 0.3863 - val_accuracy: 0.8511\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1431 - accuracy: 0.9434 - val_loss: 0.3900 - val_accuracy: 0.8511\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1621 - accuracy: 0.9434 - val_loss: 0.3930 - val_accuracy: 0.8511\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1030 - accuracy: 0.9623 - val_loss: 0.3945 - val_accuracy: 0.8511\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1435 - accuracy: 0.9623 - val_loss: 0.3953 - val_accuracy: 0.8511\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1689 - accuracy: 0.9434 - val_loss: 0.3989 - val_accuracy: 0.8723\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1503 - accuracy: 0.9434 - val_loss: 0.4043 - val_accuracy: 0.8723\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2012 - accuracy: 0.9245 - val_loss: 0.4069 - val_accuracy: 0.8723\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1483 - accuracy: 0.9434 - val_loss: 0.4049 - val_accuracy: 0.8723\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0932 - accuracy: 0.9623 - val_loss: 0.4021 - val_accuracy: 0.8511\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1324 - accuracy: 0.9623 - val_loss: 0.3975 - val_accuracy: 0.8511\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1549 - accuracy: 0.9434 - val_loss: 0.3951 - val_accuracy: 0.8511\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1294 - accuracy: 0.9623 - val_loss: 0.3931 - val_accuracy: 0.8511\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1141 - accuracy: 0.9623 - val_loss: 0.3913 - val_accuracy: 0.8511\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1879 - accuracy: 0.9245 - val_loss: 0.3873 - val_accuracy: 0.8511\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1428 - accuracy: 0.9434 - val_loss: 0.3853 - val_accuracy: 0.8511\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1343 - accuracy: 0.9434 - val_loss: 0.3852 - val_accuracy: 0.8511\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2006 - accuracy: 0.8868 - val_loss: 0.3857 - val_accuracy: 0.8511\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1006 - accuracy: 0.9623 - val_loss: 0.3843 - val_accuracy: 0.8511\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1946 - accuracy: 0.9434 - val_loss: 0.3855 - val_accuracy: 0.8511\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1311 - accuracy: 0.9434 - val_loss: 0.3866 - val_accuracy: 0.8511\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1197 - accuracy: 0.9245 - val_loss: 0.3855 - val_accuracy: 0.8511\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2020 - accuracy: 0.9245 - val_loss: 0.3823 - val_accuracy: 0.8511\n",
      "Epoch 549/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 0.1360 - accuracy: 0.9623 - val_loss: 0.3801 - val_accuracy: 0.8511\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1682 - accuracy: 0.9434 - val_loss: 0.3785 - val_accuracy: 0.8511\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1562 - accuracy: 0.9623 - val_loss: 0.3773 - val_accuracy: 0.8511\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 656us/step - loss: 0.1027 - accuracy: 0.9434 - val_loss: 0.3745 - val_accuracy: 0.8511\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1347 - accuracy: 0.9434 - val_loss: 0.3700 - val_accuracy: 0.8723\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1601 - accuracy: 0.9623 - val_loss: 0.3658 - val_accuracy: 0.8723\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1203 - accuracy: 0.9623 - val_loss: 0.3620 - val_accuracy: 0.8723\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 634us/step - loss: 0.1324 - accuracy: 0.9623 - val_loss: 0.3594 - val_accuracy: 0.8723\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1361 - accuracy: 0.9811 - val_loss: 0.3581 - val_accuracy: 0.8723\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1868 - accuracy: 0.9245 - val_loss: 0.3590 - val_accuracy: 0.8723\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1662 - accuracy: 0.9434 - val_loss: 0.3586 - val_accuracy: 0.8723\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1265 - accuracy: 0.9245 - val_loss: 0.3609 - val_accuracy: 0.8723\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1324 - accuracy: 0.9623 - val_loss: 0.3645 - val_accuracy: 0.8723\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1043 - accuracy: 0.9623 - val_loss: 0.3694 - val_accuracy: 0.8723\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0773 - accuracy: 0.9811 - val_loss: 0.3736 - val_accuracy: 0.8723\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1051 - accuracy: 0.9623 - val_loss: 0.3759 - val_accuracy: 0.8723\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 607us/step - loss: 0.1068 - accuracy: 0.9623 - val_loss: 0.3768 - val_accuracy: 0.8723\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1158 - accuracy: 0.9623 - val_loss: 0.3777 - val_accuracy: 0.8723\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0921 - accuracy: 0.9623 - val_loss: 0.3767 - val_accuracy: 0.8723\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1058 - accuracy: 0.9623 - val_loss: 0.3762 - val_accuracy: 0.8723\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1314 - accuracy: 0.9057 - val_loss: 0.3756 - val_accuracy: 0.8723\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1107 - accuracy: 0.9623 - val_loss: 0.3774 - val_accuracy: 0.8723\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1301 - accuracy: 0.9623 - val_loss: 0.3795 - val_accuracy: 0.8723\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1130 - accuracy: 0.9623 - val_loss: 0.3827 - val_accuracy: 0.8723\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1511 - accuracy: 0.9623 - val_loss: 0.3878 - val_accuracy: 0.8723\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1332 - accuracy: 0.9623 - val_loss: 0.3904 - val_accuracy: 0.8723\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1372 - accuracy: 0.9434 - val_loss: 0.3935 - val_accuracy: 0.8723\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1727 - accuracy: 0.9245 - val_loss: 0.3992 - val_accuracy: 0.8511\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1587 - accuracy: 0.9623 - val_loss: 0.4043 - val_accuracy: 0.8723\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1327 - accuracy: 0.9434 - val_loss: 0.4053 - val_accuracy: 0.8723\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1268 - accuracy: 0.9811 - val_loss: 0.4047 - val_accuracy: 0.8723\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0971 - accuracy: 0.9811 - val_loss: 0.4022 - val_accuracy: 0.8723\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1095 - accuracy: 0.9623 - val_loss: 0.3966 - val_accuracy: 0.8723\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1406 - accuracy: 0.9623 - val_loss: 0.3890 - val_accuracy: 0.8723\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0816 - accuracy: 0.9811 - val_loss: 0.3805 - val_accuracy: 0.8936\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1300 - accuracy: 0.9434 - val_loss: 0.3693 - val_accuracy: 0.8723\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 752us/step - loss: 0.1445 - accuracy: 0.9434 - val_loss: 0.3568 - val_accuracy: 0.8723\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1333 - accuracy: 0.9623 - val_loss: 0.3465 - val_accuracy: 0.8723\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1806 - accuracy: 0.9434 - val_loss: 0.3365 - val_accuracy: 0.8723\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 0.3285 - val_accuracy: 0.8723\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 846us/step - loss: 0.1158 - accuracy: 0.9434 - val_loss: 0.3229 - val_accuracy: 0.8723\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1605 - accuracy: 0.9434 - val_loss: 0.3202 - val_accuracy: 0.8723\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1328 - accuracy: 0.9811 - val_loss: 0.3211 - val_accuracy: 0.8723\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1370 - accuracy: 0.9434 - val_loss: 0.3222 - val_accuracy: 0.8723\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1026 - accuracy: 0.9811 - val_loss: 0.3223 - val_accuracy: 0.8723\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1454 - accuracy: 0.9434 - val_loss: 0.3221 - val_accuracy: 0.8723\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2184 - accuracy: 0.9057 - val_loss: 0.3213 - val_accuracy: 0.8936\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1203 - accuracy: 0.9434 - val_loss: 0.3218 - val_accuracy: 0.8936\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 978us/step - loss: 0.1397 - accuracy: 0.9245 - val_loss: 0.3218 - val_accuracy: 0.8936\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0767 - accuracy: 0.9811 - val_loss: 0.3205 - val_accuracy: 0.8936\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1627 - accuracy: 0.9245 - val_loss: 0.3221 - val_accuracy: 0.8936\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1276 - accuracy: 0.9623 - val_loss: 0.3223 - val_accuracy: 0.8723\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1316 - accuracy: 0.9811 - val_loss: 0.3215 - val_accuracy: 0.8723\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1342 - accuracy: 0.9057 - val_loss: 0.3208 - val_accuracy: 0.8723\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0917 - accuracy: 0.9623 - val_loss: 0.3205 - val_accuracy: 0.8723\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0940 - accuracy: 0.9811 - val_loss: 0.3208 - val_accuracy: 0.8723\n",
      "Epoch 605/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 678us/step - loss: 0.1331 - accuracy: 0.9434 - val_loss: 0.3210 - val_accuracy: 0.8723\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1396 - accuracy: 0.9434 - val_loss: 0.3239 - val_accuracy: 0.8723\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1282 - accuracy: 0.9811 - val_loss: 0.3253 - val_accuracy: 0.8723\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1285 - accuracy: 0.9623 - val_loss: 0.3260 - val_accuracy: 0.8723\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0934 - accuracy: 0.9623 - val_loss: 0.3268 - val_accuracy: 0.8723\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1264 - accuracy: 0.9434 - val_loss: 0.3274 - val_accuracy: 0.8723\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0829 - accuracy: 0.9811 - val_loss: 0.3278 - val_accuracy: 0.8723\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0911 - accuracy: 0.9623 - val_loss: 0.3283 - val_accuracy: 0.8723\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1758 - accuracy: 0.8868 - val_loss: 0.3291 - val_accuracy: 0.8723\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1384 - accuracy: 0.9623 - val_loss: 0.3282 - val_accuracy: 0.8723\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0937 - accuracy: 0.9623 - val_loss: 0.3282 - val_accuracy: 0.8723\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1799 - accuracy: 0.9245 - val_loss: 0.3295 - val_accuracy: 0.8723\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1159 - accuracy: 0.9623 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0983 - accuracy: 0.9623 - val_loss: 0.3275 - val_accuracy: 0.8723\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0988 - accuracy: 0.9245 - val_loss: 0.3262 - val_accuracy: 0.8723\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1224 - accuracy: 0.9434 - val_loss: 0.3260 - val_accuracy: 0.8723\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1226 - accuracy: 0.9434 - val_loss: 0.3289 - val_accuracy: 0.8723\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1353 - accuracy: 0.9434 - val_loss: 0.3318 - val_accuracy: 0.8723\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 742us/step - loss: 0.1583 - accuracy: 0.9245 - val_loss: 0.3353 - val_accuracy: 0.8723\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1204 - accuracy: 0.9434 - val_loss: 0.3383 - val_accuracy: 0.8723\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1039 - accuracy: 0.9811 - val_loss: 0.3389 - val_accuracy: 0.8723\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1323 - accuracy: 0.9623 - val_loss: 0.3394 - val_accuracy: 0.8723\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1165 - accuracy: 0.9623 - val_loss: 0.3393 - val_accuracy: 0.8723\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1906 - accuracy: 0.9434 - val_loss: 0.3384 - val_accuracy: 0.8723\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1510 - accuracy: 0.9434 - val_loss: 0.3367 - val_accuracy: 0.8723\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.1495 - accuracy: 0.9245 - val_loss: 0.3359 - val_accuracy: 0.8723\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1299 - accuracy: 0.9623 - val_loss: 0.3323 - val_accuracy: 0.8723\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1100 - accuracy: 0.9057 - val_loss: 0.3309 - val_accuracy: 0.8723\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0987 - accuracy: 0.9811 - val_loss: 0.3280 - val_accuracy: 0.8723\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1437 - accuracy: 0.9245 - val_loss: 0.3280 - val_accuracy: 0.8723\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0819 - accuracy: 0.9811 - val_loss: 0.3289 - val_accuracy: 0.8723\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1539 - accuracy: 0.9245 - val_loss: 0.3278 - val_accuracy: 0.8723\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1324 - accuracy: 0.9811 - val_loss: 0.3272 - val_accuracy: 0.8723\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0826 - accuracy: 0.9811 - val_loss: 0.3250 - val_accuracy: 0.8723\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1579 - accuracy: 0.9434 - val_loss: 0.3209 - val_accuracy: 0.8723\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0992 - accuracy: 0.9623 - val_loss: 0.3189 - val_accuracy: 0.8723\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0996 - accuracy: 0.9623 - val_loss: 0.3174 - val_accuracy: 0.8723\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1072 - accuracy: 0.9434 - val_loss: 0.3173 - val_accuracy: 0.8723\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1604 - accuracy: 0.9245 - val_loss: 0.3150 - val_accuracy: 0.8723\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1401 - accuracy: 0.9057 - val_loss: 0.3154 - val_accuracy: 0.8723\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1690 - accuracy: 0.9245 - val_loss: 0.3158 - val_accuracy: 0.8723\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1978 - accuracy: 0.9434 - val_loss: 0.3156 - val_accuracy: 0.8723\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1292 - accuracy: 0.9434 - val_loss: 0.3154 - val_accuracy: 0.8723\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1013 - accuracy: 0.9434 - val_loss: 0.3170 - val_accuracy: 0.8723\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0805 - accuracy: 0.9811 - val_loss: 0.3192 - val_accuracy: 0.8723\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0797 - accuracy: 0.9811 - val_loss: 0.3192 - val_accuracy: 0.8723\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 978us/step - loss: 0.1211 - accuracy: 0.9811 - val_loss: 0.3187 - val_accuracy: 0.8723\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 660us/step - loss: 0.1539 - accuracy: 0.9434 - val_loss: 0.3174 - val_accuracy: 0.8723\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1443 - accuracy: 0.9811 - val_loss: 0.3138 - val_accuracy: 0.8723\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1085 - accuracy: 0.9434 - val_loss: 0.3103 - val_accuracy: 0.8723\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1303 - accuracy: 0.9434 - val_loss: 0.3076 - val_accuracy: 0.8723\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0787 - accuracy: 0.9623 - val_loss: 0.3059 - val_accuracy: 0.8723\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1265 - accuracy: 0.9623 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1112 - accuracy: 0.9623 - val_loss: 0.3017 - val_accuracy: 0.8723\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1566 - accuracy: 0.9434 - val_loss: 0.2999 - val_accuracy: 0.8723\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1027 - accuracy: 0.9434 - val_loss: 0.2977 - val_accuracy: 0.8723\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 763us/step - loss: 0.1425 - accuracy: 0.9623 - val_loss: 0.2944 - val_accuracy: 0.8723\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1178 - accuracy: 0.9434 - val_loss: 0.2889 - val_accuracy: 0.8723\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1057 - accuracy: 0.9623 - val_loss: 0.2870 - val_accuracy: 0.8723\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1185 - accuracy: 0.9434 - val_loss: 0.2881 - val_accuracy: 0.8723\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1289 - accuracy: 0.9434 - val_loss: 0.2904 - val_accuracy: 0.8723\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1116 - accuracy: 0.9434 - val_loss: 0.2908 - val_accuracy: 0.8723\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0997 - accuracy: 0.9434 - val_loss: 0.2909 - val_accuracy: 0.8723\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0967 - accuracy: 0.9811 - val_loss: 0.2905 - val_accuracy: 0.8723\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1392 - accuracy: 0.9434 - val_loss: 0.2932 - val_accuracy: 0.8723\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0990 - accuracy: 0.9623 - val_loss: 0.2974 - val_accuracy: 0.8723\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0774 - accuracy: 0.9811 - val_loss: 0.3005 - val_accuracy: 0.8723\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1365 - accuracy: 0.9434 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1105 - accuracy: 0.9623 - val_loss: 0.3045 - val_accuracy: 0.8723\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0726 - accuracy: 0.9623 - val_loss: 0.3046 - val_accuracy: 0.8723\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1352 - accuracy: 0.9434 - val_loss: 0.3085 - val_accuracy: 0.8723\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0959 - accuracy: 0.9623 - val_loss: 0.3144 - val_accuracy: 0.8723\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 704us/step - loss: 0.0682 - accuracy: 0.9623 - val_loss: 0.3178 - val_accuracy: 0.8723\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1141 - accuracy: 0.9434 - val_loss: 0.3198 - val_accuracy: 0.8723\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1110 - accuracy: 0.9623 - val_loss: 0.3204 - val_accuracy: 0.8723\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0813 - accuracy: 0.9434 - val_loss: 0.3194 - val_accuracy: 0.8723\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0700 - accuracy: 0.9623 - val_loss: 0.3174 - val_accuracy: 0.8723\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0987 - accuracy: 0.9811 - val_loss: 0.3120 - val_accuracy: 0.8723\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1009 - accuracy: 0.9434 - val_loss: 0.3072 - val_accuracy: 0.8723\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1173 - accuracy: 0.9623 - val_loss: 0.3054 - val_accuracy: 0.8723\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1068 - accuracy: 0.9623 - val_loss: 0.3051 - val_accuracy: 0.8723\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0683 - accuracy: 0.9811 - val_loss: 0.3042 - val_accuracy: 0.8723\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1376 - accuracy: 0.9434 - val_loss: 0.3011 - val_accuracy: 0.8723\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1147 - accuracy: 0.9434 - val_loss: 0.2964 - val_accuracy: 0.8723\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1168 - accuracy: 0.9623 - val_loss: 0.2919 - val_accuracy: 0.8723\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1017 - accuracy: 0.9623 - val_loss: 0.2893 - val_accuracy: 0.8723\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1534 - accuracy: 0.9245 - val_loss: 0.2885 - val_accuracy: 0.8936\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0769 - accuracy: 0.9623 - val_loss: 0.2850 - val_accuracy: 0.8936\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0980 - accuracy: 0.9811 - val_loss: 0.2806 - val_accuracy: 0.8936\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1294 - accuracy: 0.9245 - val_loss: 0.2807 - val_accuracy: 0.8936\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1781 - accuracy: 0.9434 - val_loss: 0.2800 - val_accuracy: 0.8936\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1547 - accuracy: 0.9434 - val_loss: 0.2785 - val_accuracy: 0.8936\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0817 - accuracy: 0.9811 - val_loss: 0.2816 - val_accuracy: 0.8936\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0960 - accuracy: 0.9623 - val_loss: 0.2837 - val_accuracy: 0.8936\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0932 - accuracy: 0.9623 - val_loss: 0.2861 - val_accuracy: 0.8936\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0709 - accuracy: 0.9623 - val_loss: 0.2872 - val_accuracy: 0.8936\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0640 - accuracy: 0.9811 - val_loss: 0.2928 - val_accuracy: 0.8936\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1227 - accuracy: 0.9623 - val_loss: 0.2965 - val_accuracy: 0.8936\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0739 - accuracy: 0.9623 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1478 - accuracy: 0.9434 - val_loss: 0.2959 - val_accuracy: 0.8936\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0748 - accuracy: 0.9623 - val_loss: 0.2935 - val_accuracy: 0.8936\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0694 - accuracy: 0.9811 - val_loss: 0.2912 - val_accuracy: 0.8723\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1290 - accuracy: 0.9623 - val_loss: 0.2885 - val_accuracy: 0.8723\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1163 - accuracy: 0.9623 - val_loss: 0.2851 - val_accuracy: 0.8723\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1431 - accuracy: 0.9623 - val_loss: 0.2828 - val_accuracy: 0.8723\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1452 - accuracy: 0.9434 - val_loss: 0.2817 - val_accuracy: 0.8723\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0625 - accuracy: 0.9623 - val_loss: 0.2822 - val_accuracy: 0.8723\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0923 - accuracy: 0.9245 - val_loss: 0.2824 - val_accuracy: 0.8723\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1045 - accuracy: 0.9623 - val_loss: 0.2819 - val_accuracy: 0.8723\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.8723\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0775 - accuracy: 0.9623 - val_loss: 0.2784 - val_accuracy: 0.8723\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0798 - accuracy: 0.9623 - val_loss: 0.2794 - val_accuracy: 0.8723\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 678us/step - loss: 0.1478 - accuracy: 0.9245 - val_loss: 0.2791 - val_accuracy: 0.8723\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.8723\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1338 - accuracy: 0.9434 - val_loss: 0.2845 - val_accuracy: 0.8723\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0597 - accuracy: 0.9623 - val_loss: 0.2879 - val_accuracy: 0.8723\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1298 - accuracy: 0.9057 - val_loss: 0.2909 - val_accuracy: 0.8723\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1776 - accuracy: 0.9434 - val_loss: 0.2933 - val_accuracy: 0.8936\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1295 - accuracy: 0.9623 - val_loss: 0.2946 - val_accuracy: 0.8936\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1300 - accuracy: 0.9623 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1136 - accuracy: 0.9434 - val_loss: 0.2913 - val_accuracy: 0.8936\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.1535 - accuracy: 0.9434 - val_loss: 0.2844 - val_accuracy: 0.8936\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1272 - accuracy: 0.9434 - val_loss: 0.2742 - val_accuracy: 0.8936\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1123 - accuracy: 0.9623 - val_loss: 0.2659 - val_accuracy: 0.8936\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0790 - accuracy: 0.9811 - val_loss: 0.2609 - val_accuracy: 0.8936\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1122 - accuracy: 0.9811 - val_loss: 0.2617 - val_accuracy: 0.8936\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1161 - accuracy: 0.9434 - val_loss: 0.2658 - val_accuracy: 0.8936\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0826 - accuracy: 0.9434 - val_loss: 0.2700 - val_accuracy: 0.8936\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1283 - accuracy: 0.9245 - val_loss: 0.2722 - val_accuracy: 0.8936\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0697 - accuracy: 0.9623 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0766 - accuracy: 0.9623 - val_loss: 0.2725 - val_accuracy: 0.8936\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1768 - accuracy: 0.9057 - val_loss: 0.2720 - val_accuracy: 0.8936\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0966 - accuracy: 0.9434 - val_loss: 0.2680 - val_accuracy: 0.8936\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0653 - accuracy: 0.9434 - val_loss: 0.2598 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0735 - accuracy: 0.9811 - val_loss: 0.2558 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1009 - accuracy: 0.9623 - val_loss: 0.2523 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1269 - accuracy: 0.9623 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1902 - accuracy: 0.9434 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1046 - accuracy: 0.9623 - val_loss: 0.2561 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0853 - accuracy: 0.9623 - val_loss: 0.2608 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1233 - accuracy: 0.9434 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1260 - accuracy: 0.9434 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 792us/step - loss: 0.1420 - accuracy: 0.9434 - val_loss: 0.2720 - val_accuracy: 0.8936\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1608 - accuracy: 0.9057 - val_loss: 0.2749 - val_accuracy: 0.8936\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1094 - accuracy: 0.9434 - val_loss: 0.2788 - val_accuracy: 0.8723\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0802 - accuracy: 0.9811 - val_loss: 0.2839 - val_accuracy: 0.8723\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.8723\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 0.2975 - val_accuracy: 0.8723\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0735 - accuracy: 0.9623 - val_loss: 0.3000 - val_accuracy: 0.8723\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 728us/step - loss: 0.1017 - accuracy: 0.9245 - val_loss: 0.2985 - val_accuracy: 0.8723\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1191 - accuracy: 0.9623 - val_loss: 0.2938 - val_accuracy: 0.8723\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0862 - accuracy: 0.9811 - val_loss: 0.2886 - val_accuracy: 0.8723\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1235 - accuracy: 0.9623 - val_loss: 0.2797 - val_accuracy: 0.8936\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0641 - accuracy: 0.9811 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0628 - accuracy: 0.9623 - val_loss: 0.2680 - val_accuracy: 0.8936\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1031 - accuracy: 0.9623 - val_loss: 0.2638 - val_accuracy: 0.8936\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0654 - accuracy: 0.9623 - val_loss: 0.2646 - val_accuracy: 0.8936\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.2683 - val_accuracy: 0.8936\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1697 - accuracy: 0.9434 - val_loss: 0.2754 - val_accuracy: 0.8936\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0733 - accuracy: 0.9811 - val_loss: 0.2803 - val_accuracy: 0.8936\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0895 - accuracy: 0.9434 - val_loss: 0.2823 - val_accuracy: 0.8723\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0521 - accuracy: 0.9811 - val_loss: 0.2847 - val_accuracy: 0.8723\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1047 - accuracy: 0.9623 - val_loss: 0.2862 - val_accuracy: 0.8723\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0973 - accuracy: 0.9623 - val_loss: 0.2836 - val_accuracy: 0.8723\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.2819 - val_accuracy: 0.8936\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0929 - accuracy: 0.9434 - val_loss: 0.2831 - val_accuracy: 0.8936\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0808 - accuracy: 0.9623 - val_loss: 0.2829 - val_accuracy: 0.8936\n",
      "Epoch 773/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.0685 - accuracy: 0.9623 - val_loss: 0.2822 - val_accuracy: 0.8936\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0906 - accuracy: 0.9623 - val_loss: 0.2793 - val_accuracy: 0.8936\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0671 - accuracy: 0.9623 - val_loss: 0.2729 - val_accuracy: 0.8936\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0831 - accuracy: 0.9623 - val_loss: 0.2665 - val_accuracy: 0.8936\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0523 - accuracy: 0.9811 - val_loss: 0.2632 - val_accuracy: 0.8936\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0706 - accuracy: 0.9623 - val_loss: 0.2603 - val_accuracy: 0.8936\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0875 - accuracy: 0.9623 - val_loss: 0.2572 - val_accuracy: 0.8936\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1310 - accuracy: 0.9434 - val_loss: 0.2545 - val_accuracy: 0.8936\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0984 - accuracy: 0.9434 - val_loss: 0.2499 - val_accuracy: 0.8936\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0950 - accuracy: 0.9623 - val_loss: 0.2484 - val_accuracy: 0.8936\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0560 - accuracy: 0.9811 - val_loss: 0.2517 - val_accuracy: 0.8936\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0882 - accuracy: 0.9623 - val_loss: 0.2561 - val_accuracy: 0.8936\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0922 - accuracy: 0.9623 - val_loss: 0.2566 - val_accuracy: 0.8936\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0504 - accuracy: 0.9811 - val_loss: 0.2569 - val_accuracy: 0.8936\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 0.2616 - val_accuracy: 0.8936\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0937 - accuracy: 0.9434 - val_loss: 0.2633 - val_accuracy: 0.8936\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0525 - accuracy: 0.9811 - val_loss: 0.2640 - val_accuracy: 0.8936\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0946 - accuracy: 0.9623 - val_loss: 0.2643 - val_accuracy: 0.8936\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0687 - accuracy: 0.9811 - val_loss: 0.2687 - val_accuracy: 0.8936\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0556 - accuracy: 0.9811 - val_loss: 0.2748 - val_accuracy: 0.8936\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1004 - accuracy: 0.9623 - val_loss: 0.2766 - val_accuracy: 0.8936\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0865 - accuracy: 0.9623 - val_loss: 0.2790 - val_accuracy: 0.8936\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.8936\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0439 - accuracy: 0.9811 - val_loss: 0.2823 - val_accuracy: 0.8936\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1240 - accuracy: 0.9623 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1284 - accuracy: 0.9623 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0900 - accuracy: 0.9434 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1121 - accuracy: 0.9245 - val_loss: 0.2622 - val_accuracy: 0.8936\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 0.2587 - val_accuracy: 0.8936\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.2520 - val_accuracy: 0.8936\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 707us/step - loss: 0.0659 - accuracy: 0.9623 - val_loss: 0.2472 - val_accuracy: 0.8936\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0867 - accuracy: 0.9623 - val_loss: 0.2441 - val_accuracy: 0.8936\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1105 - accuracy: 0.9434 - val_loss: 0.2392 - val_accuracy: 0.8936\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0823 - accuracy: 0.9434 - val_loss: 0.2359 - val_accuracy: 0.8936\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0472 - accuracy: 0.9811 - val_loss: 0.2348 - val_accuracy: 0.8936\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.2329 - val_accuracy: 0.8936\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.2303 - val_accuracy: 0.8936\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0912 - accuracy: 0.9623 - val_loss: 0.2277 - val_accuracy: 0.8936\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1262 - accuracy: 0.9623 - val_loss: 0.2272 - val_accuracy: 0.8936\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0448 - accuracy: 0.9811 - val_loss: 0.2273 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1018 - accuracy: 0.9434 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1244 - accuracy: 0.9057 - val_loss: 0.2428 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0751 - accuracy: 0.9623 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.2606 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0764 - accuracy: 0.9623 - val_loss: 0.2623 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1138 - accuracy: 0.9623 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0754 - accuracy: 0.9623 - val_loss: 0.2674 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0744 - accuracy: 0.9623 - val_loss: 0.2711 - val_accuracy: 0.8936\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 706us/step - loss: 0.0706 - accuracy: 0.9623 - val_loss: 0.2746 - val_accuracy: 0.8936\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1220 - accuracy: 0.9434 - val_loss: 0.2772 - val_accuracy: 0.8936\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0699 - accuracy: 0.9623 - val_loss: 0.2819 - val_accuracy: 0.8936\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0390 - accuracy: 0.9811 - val_loss: 0.2879 - val_accuracy: 0.8936\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.0922 - accuracy: 0.9434 - val_loss: 0.2923 - val_accuracy: 0.8936\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0585 - accuracy: 0.9811 - val_loss: 0.2938 - val_accuracy: 0.8936\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1241 - accuracy: 0.9623 - val_loss: 0.2921 - val_accuracy: 0.8936\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0324 - accuracy: 0.9811 - val_loss: 0.2859 - val_accuracy: 0.8936\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0594 - accuracy: 0.9623 - val_loss: 0.2801 - val_accuracy: 0.8936\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0784 - accuracy: 0.9623 - val_loss: 0.2748 - val_accuracy: 0.8936\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0717 - accuracy: 0.9623 - val_loss: 0.2723 - val_accuracy: 0.8936\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0460 - accuracy: 0.9811 - val_loss: 0.2701 - val_accuracy: 0.8936\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0976 - accuracy: 0.9434 - val_loss: 0.2678 - val_accuracy: 0.8936\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0669 - accuracy: 0.9623 - val_loss: 0.2652 - val_accuracy: 0.8936\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0507 - accuracy: 0.9623 - val_loss: 0.2618 - val_accuracy: 0.8936\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0619 - accuracy: 0.9811 - val_loss: 0.2599 - val_accuracy: 0.8936\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0795 - accuracy: 0.9623 - val_loss: 0.2562 - val_accuracy: 0.8936\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1022 - accuracy: 0.9245 - val_loss: 0.2568 - val_accuracy: 0.8936\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0454 - accuracy: 0.9811 - val_loss: 0.2594 - val_accuracy: 0.8936\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1076 - accuracy: 0.9434 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0772 - accuracy: 0.9623 - val_loss: 0.2633 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0898 - accuracy: 0.9434 - val_loss: 0.2636 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 725us/step - loss: 0.0779 - accuracy: 0.9811 - val_loss: 0.2643 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1357 - accuracy: 0.9245 - val_loss: 0.2664 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0482 - accuracy: 0.9811 - val_loss: 0.2663 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0884 - accuracy: 0.9623 - val_loss: 0.2640 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0635 - accuracy: 0.9811 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0487 - accuracy: 0.9811 - val_loss: 0.2554 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0742 - accuracy: 0.9623 - val_loss: 0.2526 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0703 - accuracy: 0.9623 - val_loss: 0.2488 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0349 - accuracy: 0.9811 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0672 - accuracy: 0.9811 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0813 - accuracy: 0.9623 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.2474 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0483 - accuracy: 0.9811 - val_loss: 0.2480 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0774 - accuracy: 0.9623 - val_loss: 0.2470 - val_accuracy: 0.8936\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 757us/step - loss: 0.1074 - accuracy: 0.9434 - val_loss: 0.2464 - val_accuracy: 0.8936\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0518 - accuracy: 0.9623 - val_loss: 0.2458 - val_accuracy: 0.8936\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1113 - accuracy: 0.9623 - val_loss: 0.2434 - val_accuracy: 0.8936\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 800us/step - loss: 0.0423 - accuracy: 0.9811 - val_loss: 0.2397 - val_accuracy: 0.8936\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.2380 - val_accuracy: 0.8936\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0348 - accuracy: 0.9811 - val_loss: 0.2372 - val_accuracy: 0.8936\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0819 - accuracy: 0.9434 - val_loss: 0.2360 - val_accuracy: 0.8936\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.8936\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.8936\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0483 - accuracy: 0.9811 - val_loss: 0.2358 - val_accuracy: 0.8936\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0915 - accuracy: 0.9623 - val_loss: 0.2358 - val_accuracy: 0.8936\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1223 - accuracy: 0.9623 - val_loss: 0.2339 - val_accuracy: 0.8936\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0648 - accuracy: 0.9811 - val_loss: 0.2321 - val_accuracy: 0.8936\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0562 - accuracy: 0.9811 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.0713 - accuracy: 0.9811 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0680 - accuracy: 0.9623 - val_loss: 0.2245 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0433 - accuracy: 0.9811 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9362\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0518 - accuracy: 0.9623 - val_loss: 0.2163 - val_accuracy: 0.9362\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9362\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0418 - accuracy: 0.9623 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0763 - accuracy: 0.9623 - val_loss: 0.2216 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0822 - accuracy: 0.9811 - val_loss: 0.2321 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0824 - accuracy: 0.9245 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.8936\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0736 - accuracy: 0.9434 - val_loss: 0.2644 - val_accuracy: 0.8936\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0702 - accuracy: 0.9623 - val_loss: 0.2727 - val_accuracy: 0.8936\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0391 - accuracy: 0.9811 - val_loss: 0.2782 - val_accuracy: 0.8936\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0413 - accuracy: 0.9811 - val_loss: 0.2810 - val_accuracy: 0.8936\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0444 - accuracy: 0.9811 - val_loss: 0.2839 - val_accuracy: 0.8936\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0709 - accuracy: 0.9623 - val_loss: 0.2865 - val_accuracy: 0.8936\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0597 - accuracy: 0.9811 - val_loss: 0.2877 - val_accuracy: 0.8936\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0461 - accuracy: 0.9811 - val_loss: 0.2889 - val_accuracy: 0.8936\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0817 - accuracy: 0.9623 - val_loss: 0.2881 - val_accuracy: 0.8936\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0487 - accuracy: 0.9811 - val_loss: 0.2895 - val_accuracy: 0.8936\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1596 - accuracy: 0.9434 - val_loss: 0.2922 - val_accuracy: 0.8936\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0667 - accuracy: 0.9623 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0585 - accuracy: 0.9434 - val_loss: 0.3037 - val_accuracy: 0.8936\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0304 - accuracy: 0.9811 - val_loss: 0.3076 - val_accuracy: 0.8936\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0571 - accuracy: 0.9811 - val_loss: 0.3101 - val_accuracy: 0.8936\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1033 - accuracy: 0.9811 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0767 - accuracy: 0.9623 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0647 - accuracy: 0.9811 - val_loss: 0.3006 - val_accuracy: 0.8936\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1088 - accuracy: 0.9434 - val_loss: 0.2914 - val_accuracy: 0.8936\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0547 - accuracy: 0.9811 - val_loss: 0.2857 - val_accuracy: 0.8936\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.8936\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.8936\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1244 - accuracy: 0.9434 - val_loss: 0.2798 - val_accuracy: 0.8936\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.1205 - accuracy: 0.9623 - val_loss: 0.2871 - val_accuracy: 0.8936\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0365 - accuracy: 0.9811 - val_loss: 0.2928 - val_accuracy: 0.8936\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0308 - accuracy: 0.9811 - val_loss: 0.2965 - val_accuracy: 0.8936\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0515 - accuracy: 0.9623 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0476 - accuracy: 0.9811 - val_loss: 0.3016 - val_accuracy: 0.8936\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2025 - accuracy: 0.9434 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1092 - accuracy: 0.9245 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0684 - accuracy: 0.9811 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0692 - accuracy: 0.9434 - val_loss: 0.2785 - val_accuracy: 0.8936\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1504 - accuracy: 0.9434 - val_loss: 0.2689 - val_accuracy: 0.8936\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0676 - accuracy: 0.9811 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0996 - accuracy: 0.9623 - val_loss: 0.2563 - val_accuracy: 0.8936\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1615 - accuracy: 0.9245 - val_loss: 0.2528 - val_accuracy: 0.8936\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0618 - accuracy: 0.9623 - val_loss: 0.2522 - val_accuracy: 0.8936\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0780 - accuracy: 0.9623 - val_loss: 0.2518 - val_accuracy: 0.8936\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0897 - accuracy: 0.9434 - val_loss: 0.2507 - val_accuracy: 0.8936\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0599 - accuracy: 0.9811 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0724 - accuracy: 0.9811 - val_loss: 0.2587 - val_accuracy: 0.8936\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0398 - accuracy: 0.9811 - val_loss: 0.2602 - val_accuracy: 0.8936\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.8936\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0707 - accuracy: 0.9434 - val_loss: 0.2599 - val_accuracy: 0.8936\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0836 - accuracy: 0.9623 - val_loss: 0.2591 - val_accuracy: 0.8936\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0681 - accuracy: 0.9623 - val_loss: 0.2549 - val_accuracy: 0.8936\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 0.2484 - val_accuracy: 0.8936\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1098 - accuracy: 0.9623 - val_loss: 0.2418 - val_accuracy: 0.8936\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1120 - accuracy: 0.9623 - val_loss: 0.2416 - val_accuracy: 0.8936\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0611 - accuracy: 0.9623 - val_loss: 0.2465 - val_accuracy: 0.8936\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0324 - accuracy: 0.9811 - val_loss: 0.2524 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.1161 - accuracy: 0.9623 - val_loss: 0.2532 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0475 - accuracy: 0.9811 - val_loss: 0.2517 - val_accuracy: 0.8936\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.2475 - val_accuracy: 0.8936\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.8936\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.8936\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0839 - accuracy: 0.9623 - val_loss: 0.2387 - val_accuracy: 0.8936\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0351 - accuracy: 0.9811 - val_loss: 0.2356 - val_accuracy: 0.8936\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0941 - accuracy: 0.9811 - val_loss: 0.2352 - val_accuracy: 0.8936\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0816 - accuracy: 0.9623 - val_loss: 0.2359 - val_accuracy: 0.8936\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.8936\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.8936\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0407 - accuracy: 0.9811 - val_loss: 0.2385 - val_accuracy: 0.8936\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0511 - accuracy: 0.9811 - val_loss: 0.2392 - val_accuracy: 0.8936\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.8936\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1295 - accuracy: 0.9623 - val_loss: 0.2412 - val_accuracy: 0.8936\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0500 - accuracy: 0.9811 - val_loss: 0.2418 - val_accuracy: 0.8936\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0465 - accuracy: 0.9811 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0959 - accuracy: 0.9623 - val_loss: 0.2437 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0851 - accuracy: 0.9434 - val_loss: 0.2454 - val_accuracy: 0.8936\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.8936\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0536 - accuracy: 0.9811 - val_loss: 0.2498 - val_accuracy: 0.8936\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.8936\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.8936\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.8936\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.8936\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0871 - accuracy: 0.9623 - val_loss: 0.2617 - val_accuracy: 0.8936\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0414 - accuracy: 0.9811 - val_loss: 0.2637 - val_accuracy: 0.8936\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.8936\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.8936\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0358 - accuracy: 0.9811 - val_loss: 0.2676 - val_accuracy: 0.8936\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.8936\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0535 - accuracy: 0.9623 - val_loss: 0.2650 - val_accuracy: 0.8936\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0458 - accuracy: 0.9811 - val_loss: 0.2624 - val_accuracy: 0.8936\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.8936\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0598 - accuracy: 0.9623 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.2626 - val_accuracy: 0.8936\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.2701 - val_accuracy: 0.8936\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0324 - accuracy: 0.9811 - val_loss: 0.2817 - val_accuracy: 0.8936\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0780 - accuracy: 0.9811 - val_loss: 0.2918 - val_accuracy: 0.8936\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.8936\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1314 - accuracy: 0.9623 - val_loss: 0.3027 - val_accuracy: 0.8936\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0969 - accuracy: 0.9434 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1479 - accuracy: 0.9811 - val_loss: 0.3031 - val_accuracy: 0.8936\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0861 - accuracy: 0.9434 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0842 - accuracy: 0.9623 - val_loss: 0.3040 - val_accuracy: 0.8936\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.8936\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0587 - accuracy: 0.9623 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0763 - accuracy: 0.9623 - val_loss: 0.3029 - val_accuracy: 0.8936\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0371 - accuracy: 0.9811 - val_loss: 0.3006 - val_accuracy: 0.8936\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0784 - accuracy: 0.9434 - val_loss: 0.2960 - val_accuracy: 0.8936\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.8936\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1072 - accuracy: 0.9434 - val_loss: 0.2819 - val_accuracy: 0.8936\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0265 - accuracy: 0.9811 - val_loss: 0.2738 - val_accuracy: 0.8936\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0434 - accuracy: 0.9811 - val_loss: 0.2684 - val_accuracy: 0.8723\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0659 - accuracy: 0.9623 - val_loss: 0.2652 - val_accuracy: 0.8723\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0789 - accuracy: 0.9623 - val_loss: 0.2649 - val_accuracy: 0.8936\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.0820 - accuracy: 0.9623 - val_loss: 0.2640 - val_accuracy: 0.8936\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0916 - accuracy: 0.9434 - val_loss: 0.2645 - val_accuracy: 0.8936\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0371 - accuracy: 0.9623 - val_loss: 0.2659 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x233ecbe1518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"traina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.plot(history_Adam_1.history['loss'], label = \"traina D\")\n",
    "plt.plot(history_Adam_1.history['val_loss'], label = \"test D\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test \")\n",
    "\n",
    "plt.plot(history_Adam_1.history['accuracy'], label = \"tarina\")\n",
    "plt.plot(history_Adam_1.history['val_accuracy'], label = \"test \")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X+QHOV95/H3FwlJruzWYSFhEX5IXDFk7bPPP04Wdrm0NiDfAZVDsS8kkKvEyeFa4jKV+Jw/YkOVc8kfHKlU+SopXLYHm3K4onBcl2ArZxEiAWZIXTCSfdgGtGZ1WIG18CFBwLsHEiXxvT96ere3t3t+dU93z/TnVbW1OzO90z2wer7P832+z9Pm7oiISP2cUfYFiIhIORQARERqSgFARKSmFABERGpKAUBEpKYUAEREakoBQESkphQARERqSgFARKSm1pZ9AZ1smpjwbWefXfZliEgdLC7CxETi42OLb1r6OXpY/FfC52D180V59tnvHXf3zb0cW+kAsO3sszl4yy1lX4aIjLtWK/g+Pb3qcbM1tfRzq5V4SOrblOHGG+2fej1WKSARqbc+Gv+0X4kqs/HvV+YAYGYXmNlDZnbIzJ40s99POMbM7C/M7LCZ/dDM3pP1vCIimfXZ+E9Ppzf+0dHBqMgjBXQK+AN3/76ZTQLfM7N97v5U5JirgEb761Lgi+3vIiLlirfaNWn8IYcRgLs/7+7fb/+8ABwCzosdthu4ywOPAmeZ2blZzy0iMrBoTid8HG3F+2j8R1WucwBmtg14N/Dd2EvnAc9FHs+zOkiE7zFjZgfN7OCxcDpdRCRPaakfCHr/scY/lNb4j2LvH3IMAGY2Afw18Cl3/3n85YRfSbwTjbs33X27u2/fXFYdlYiMrx7y/kmHjFvjDzkFADM7k6Dxv9vd/ybhkHnggsjj84GjeZxbRKRnPU76xg8Zx8Yf8qkCMuCrwCF3/3zKYXuA32pXA70PeMXdn896bhGRvg1Q6x81Lo0/5FMF9AHgN4Efmdnj7eduBi4EcPcvAXuBq4HDwKvA7+RwXhGR3iV15fus9R+nxh9yCADu/g8k5/ijxzjwyaznEhEZSErFTz/lnuPW+INWAovIuOtQ8RM+X8fGHxQARGScdZv0rXHjDwoAIjLueiz3rFvjDwoAIjKuUrbuXGr8WS73rGPjDwoAIjKOUsp50mr94z93em6cKACIyHhJ2cOhU63/uGzu1i8FABEZHyl7OHSr9Y+/RR0af1AAEJFxkWO5Z10oAIjI+FC5Z18UAERk9HWr+FHjn0gBQERGW5eKH5V7plMAEJHR1aXiR41/ZwoAIjKaeqj4Cb+p8U+mACAioyel4iet1j96aNKv15UCgIiMpoRJ3/B7fFpAjX8yBQARGS2dJn0Tyj3V+KdTABCR0ZFSz9mp1j/pVyWgACAio6FbxU+XWv+kx3WnACAi1del4qeXck81/qvlEgDM7E4ze8HMnkh5/UNm9oqZPd7++lwe5xWRGslQ7qnGP1nmm8K3fQ24HbirwzGPuPsv53Q+EamLhG0ekso9tblb/3IZAbh7C3gpj/cSEVmSUPHTZCZ43GPjr95/uiLnAN5vZj8ws/vM7F8VeF4RGUWdZnVjtf7Rl+K/KunySgF1831gq7svmtnVwDeBRtKBZjYDQYi/cOPGgi5PRCqlz3JPNf6DKWQE4O4/d/fF9s97gTPNbFPKsU133+7u2zdPTBRxeSJSJX2We6rxH1whAcDMtpiZtX/e0T7vi0WcW0RGUB/lniE1/v3LJQVkZvcAHwI2mdk88EfAmQDu/iXgV4FPmNkp4DXgOnf3PM4tImOkQ8VPp1p/Nf6DySUAuPv1XV6/naBMVEQkWZeKH1IqftT4D04rgUWkfAmTvr2Ue6rxz0YBQETK1UO5p/b3GQ4FABEpT4/lntriYTgUAESkXD2Ue8YPU+OfDwUAESlHvOKnQ7mn9vcZDgUAESleH+WeWug1PAoAIlKsDuWeWuhVLAUAESlOh3JPLfQqngKAiBSjS61/7CU1/gVQABCR4Ruw1l+N/3ApAIhIMZLKPTvU+qvxHz4FABEZrk7lnik3dVHjXwwFABEZnqSKn1i5Z0iNf/EUAERkOHqs+Il+D6nxL0ZRt4QUqYZbb4WFhdXPT07CzTcXfz3jqo9yT23xUB4FAKmXhQVIutVoUlCQwajxHxlKAYlIfvpc6BX/NSmWAoCI5KNLrX/aS5r0LY8CgIjkp0Otvxr/6lEAEJHs0mr9tdCr0nIJAGZ2p5m9YGZPpLxuZvYXZnbYzH5oZu/J47wifZuchMXF1V+Tk2Vf2eiK1/prodfIyKsK6GvA7cBdKa9fBTTaX5cCX2x/FylWWqnnrbfCZz+7+nmVh3aWNOmrhV4jI5cA4O4tM9vW4ZDdwF3u7sCjZnaWmZ3r7s/ncX6RzFQe2r8eKn5Cavyrqag5gPOA5yKP59vPicgoGmCVrxr/6ikqAFjCc554oNmMmR00s4PHFheHfFki0rcBF3qFz0t1FLUSeB64IPL4fOBo0oHu3gSaANu3bk0MElIh2lqhXrTKd6wUNQLYA/xWuxrofcAryv+PiTB3Hv9S7nx89bjQK6TGv7pyGQGY2T3Ah4BNZjYP/BFwJoC7fwnYC1wNHAZeBX4nj/OK5GZyMn0kI4F4S97HQi+ppryqgK7v8roDn8zjXCJDoXRVZ10WemmV72jSbqAicZrXWKmHhV5q/EeTAoDUW1Jj//LLsHYtbNmy8vk6zmtooddYUwCQbEY9d560AOyVV+D06XKup0q00GvsKQDUTd7pjbxTIlVJv5w+DT/96crn3IPrq0MaSI1/LSgA1E3Vtzyo0vWtWbPy8enT1fnvNEwD1Pqr8R9N2g5aRJZplW+taAQgErdmTdDbj88DxEcE4ybD7RzzbvzdwSz9seRDAUDqLWkSe2IimAg+L2G/wnHfnype0N9a/l7UQq9WC06ehF27gkbfHfbvh/XrNcrImwKA1FvahG7SvQHGWYZVvnk2yu5B4//YY8HjXbuCxv+xx2DHDo0E8qYAUDdVL9usyvVV5TqKkLbKl+IXepkFjT4EjX4YCHbsWB4RSH4UAOqm6iWMVbm+qlzHsHVa5VtSuWcYBMLGH9T4D4uqgETqqqKrfMOcf9T+/cHzki+NAERGTR6L5Sq60Cts/MOcf3QOADQSyJsCgJQrmoJQiUdvsi6Wq3Ctv1lQ7RPN+YdzAuvXq/HPmwKAdDaMrRmSGv1WS8GgCCNwR6/p6ZXVPmEQUOOfPwUA6SzvrRmSVhHFJa02UkDILqHx71TrH/+1IsUbezX+w6EAIIXxh1sr/iF/2WdW/cOeobl6JBAdHSgQDCal8ddNXepNAWDcVGU3zZhma4qF2V/g01P3ccfhy/CLGzRnp1m7FhqNlF+am2OGh5Yfx7unapX6k7TQC93Upc4UAMZNlXbTbHOHhUPPcc/se3j02MWs2/JmZmcv4cgR2LZtZb43WoEy3YAmQXRYMTKo+6ig30VqnRZ6aYO3WlMAkKEzg09P3cejxy7mwRffCf9vAxA0/jMzwetJKf9WK7n1mWk1Vz5Rt0DQz0guvtCL1bX+ZU/6SnlyCQBmdiXw58Aa4Cvuflvs9d8G/gwI77Bxu7t/JY9zy5DlsSVCK8j979p5kgf/Lmj8JyaWG39Y3dismogMRwZzT0MjqFqZIRIIlB5arUPFT9UmfaUcmQOAma0BvgB8GJgHDpjZHnd/KnboX7n7TVnPJwXLOm/QasHcHF/2GZo/eysQNP6Li9BswtRUcoVHvDe6pHEJLS5ZcazSQwm6VPxo0lcgnxHADuCwuz8DYGZfB3YD8QAgNeUXN2g+cg2zL25maipo9Gdn4fhxeP311TXeaUsCUkcFoeikcZ0DQdJnTpj0jbzU8bGMrzwCwHnAc5HH88ClCcf9BzObBp4G/rO7P5dwDGY2A8E49cKNG3O4vJqp0i6W7d7/Hcyw9tzNTG1e7vHPzCzv8R4fAcR7/932oF/KZYeTxgoEA036KvVTP3kEgKQlGvFtm/4WuMfdT5rZ7wJ/CVye9Gbu3oQgubt961Zt/9Svqu1i2WjQmtsJBI3+I48sNzq9rO5MaqDSGq1VgYDIhHERgaAKJbgJN+oNG/9e8v51iY8SyCMAzAMXRB6fDxyNHuDuL0Ye3gH8aQ7nlSpr9/6bzDDHJTQaKxt/6H91Z9IIICl3HVYPTdNamvQspHKo7BLchIqfeN4/SqkfySMAHAAaZnYRQZXPdcBvRA8ws3Pd/fn2w2uAQzmcVyquyQwtdub+vknbB/UcCBjTEtIe8/5K/UhU5gDg7qfM7CbgfoIy0Dvd/Ukz+xPgoLvvAX7PzK4BTgEvAb+d9bxSYe3eP1y21PuH/NvYXgIBRFJDVQkEw0oVKfUjfcplHYC77wX2xp77XOTnzwI1u8lqvYW9/9RtHnI0ciOCYW6wp9SP9EErgSVf8d5/++kiGpmRCwR5GLHUT/ym7rrJe7kUACR3Rfb+k+QSCAapGiqrBHeA1E/8V4vQasHJk8vVX+Hdv9avr36cHVcKAJKfDL3/YfQM44FgenqAqqF+AkHRJbgJJZ+9pn6K3uvHPWj8o7d2jN76Me+RgEYavVEAkFwN0vsfds8wqY3sebK4yHUE/Ujq0kdSP5GnKrHXT/TWjo89thwIord+zItGGr07o+wLkDGx1PuHuchePd3+wUV7hvv3r7wp+MmTweO8dEoNRbWYXgoGS5unJeWSBm1JJyeDzZDiX/2mitKWRkf2+okfmva4CNEgEMq78S/y72kcaAQguRmk919kzxB6Lx2F1XsNpW46129rmscGe3Epe/2UPfEbTb24w759K1/fvz/f/89F/z2NOo0AJLsBe/+hInqGcfE0UHyOIDwGWDEaWDEiCH8hy2hgUCl7/YTPV2Hit9Va7oWHjf+DD8KmTUEM3LFjZU89L2X8PY0qBQDJRZbKn3CYHpV3o5AmbWI42oAG86qxtFDSCKCIQJA08Rv5MFWZ+I2nYgB+8pPg+YsuCh7v2hUEgaQNAbOeu6y/p1GjFJBkk7HuP5qjDYfp4WMorufWKQgkTRTTAphaTgslDSfy1mPqpwoTv2mpmCuugA9/ePn/6TDmAKrw9zQqNAKQzLLs+WMW9ACjOdph9Qx70aliaMXrZY0GOvT+oy/Hf056PGxJqZho4x8ek/c5q/T3VHXmFR4Xbd+61Q/eckvZlyFpIjt+tho3LD09SENTxbrtbpPES6+1X1ixiCzpDbJeTPR977sPgIUTZ8KG9Zw4AWed+BlnGLy0fgsbNiz/6jHO4XNXHVj69V+59b28aeGFVad4bfIcvnnzgezX2hbtjYeKmoyt4t9TUW680b7n7tt7OVYpIMmmvd//3ByZVv7G/3FW4R9rvGOfvIgMYHpp7cDM9Gz/lULdNodLGUkcYzNsACYmWAA2nvwZbzgsbNgMka2GJo+/sOL0b1p4gRMTm1e9X1JQGFTZqZgq/j1VkQKADK7d+6dR7J4/RepnbmB6Gpqd5gaibxjVy+ZwacOQiQkWFmFyAngleGoy8lYLi1DCveBSUzGgVEyVaA5ABtNqBb1/doYVoGOtl7mBVmsIcwMpQWThxJlLjX/ojVg2N3wtmg4q0vT0yp5+GATGrZMwyjQCqJoq3FawR825ywCGtt9/1STtBhFv48MgME2rXZ2ToVLoxInEi2i2prg+8tTkRNDYnwWcEetZT04Ai5RGqZhqUwComrJvK9iLdgvYYueK0s866GWDOVi9r9CqVcTxX4hbXOx87Ib1K3r/sLLxj78mkkQpIBlI3Xr/cd32FUpbRezOil/wndNBTz++LxAs524ixzdbUzA9zTHOYfLEMTZzDI4fY/LEsaVzb1g8tvTahsVjvDZ5zoprf23yHDYsHlv1FT9Oxp9GANKflIVfddTvaIC5p9l36o/5xswDWKuFO3z+9U8yueH3Vt+QBoK0X7zxbwvLOpOCT7fsUp6lnjLaFACkf+3Sz7Ju+FI1neYGwscPPwyzpy7h+JEFfq15BbumplicfY57jryF67e9HZ/5r6vz40mNf5edPsvY6llGVy4BwMyuBP6c4KbwX3H322KvrwfuAv4N8CLw6+5+JI9zS4EiC79o9L/p2zjrNhowg6kpmGWSB49M8tiRc4B3s2PbC3x66j7skfQ3jjf+obSdPvX/Q3qVOQCY2RrgC8CHgXnggJntcfenIofdAPyzu19sZtcBfwr8etZzj6WybivYq5wWfo0j95WjAXf44AeXnwuDwJEjsNiuzt819b+5w9o3n5meXfF+zdZUe88hVjT+VdjpU8ZDHiOAHcBhd38GwMy+DuwGogFgN/Bf2j//D+B2MzOv8j4UZcmj1HOIpaR1n/xN02ot34Vqejpo/JtNOHwYbrhh5XMQFHotLkJzdpqpqSBQNJMa9bDh77KmrMidPmV85BEAzgOeizyeBy5NO8bdT5nZK8DZwPEczi9xwyglDSd/GzPMzQ1v8ncU93BJu9/t8ePBStiHHw6ef/314LnLL4d162B2NhgNhMwSWvCUylHl/SUPeQSApH+e8Z59L8cEB5rNQHDXjQs3bsx2ZZKrJjO05rZk7v2nNfLRXnS/93ItM3D0cheqVguefTa4GUr43PR0MCJYu3b5cZq0/L7y/pJFHgFgHrgg8vh84GjKMfNmthb4F8BLSW/m7k0IauK2b92qFFEVREo/o5O/g75VWiOf1IsONxPr1KBnCRx5CYNAdOfL6DYI4aTwww/DI48sPzczs3xMp5580udQ4y9Z5READgANM7sI+ClwHfAbsWP2AB8D/hH4VeBB5f9HTA6Tv2mpkrCRv+KK4Pl+7uXa7T2LGgmk3YUqfu0f/GDwPb4lUHxvoU6KavhHMR0n/ckcANo5/ZuA+wnKQO909yfN7E+Ag+6+B/gq8N/N7DBBz/+6rOeVYuUx+dtLqqRTL3rQ9xy2QbY+jufwO93KMTym0+t5q8KoSgFo+HJZB+Due4G9sec+F/n5BHBtHueSHuRZSprzyt9OjXyvveh+3rMIWbc+DiuEoqmghx/uHDSGaZijql4b9SoEoDrQSuBxlPeuoe30Tx7SGvkrroAHHhjsBiKDBo48xRvxMAj0cv54Y7dzZ7mN3bBGVb026lVJ69WBAoB0lVftf7dUybp1/feih3nnqX5TEINsfVzFxi48Z56jqn4+ZxXSenWhACDphpD+6ZQqGaQXPaw7TxWVgog3dnN7nuKM06e4cd0ebnrgDuzB4LW879cLyQHukUeCzx2OyCDIJpplG1X126iXndarCwUA6SzH9A90b+QH6UVnSb8kKbpXHm3szjh9ijfWrOXjm77JSVu+b2+e9+uF5AC3bx/85Cdw7Bg8/TS8/DKcdVbw2pvfnH1U1U+jXoW0Xh0oAEhHw9j6YRh3icrzPYtOQSQ1dl9c+I98YvLuoTR2aQHuwAF473vhoovgoYfgjTeCYy+9dHlEkGVU1WujXvYN5etEAUCS1Xzf/6JSEPHG7qsP/Hv+m3+Ke1/9dwBDCQLdAhwEwSA6F5DHqKrXRl03lC+OAoCkyzn9M0qKSkGsauwehE9M3A3AxBmvDq2xSwtwsPy5w3Pn8bn7bdTzTutJMgUASVXXnT+LTkEkNXbDTP9EJ7Wj5923L/h+4MBwPne/jfowUoWykgKArJbj3j+jqIwURPier02ekzjhm8f9esOJ3zCf/93vBpO773jH8pzApk3BPMCwPrca9WpRAJBkNb/xS1kpiGHdrzc+8btuXdD4v/zyclCAoKHfuVOpl7pQAJBEdU3/RI1TbzU+8RuKj3KSPuMof27p7IyyL0AqZin9Qy3TP+MsGgRCndZgyPhTAJDVGg1aBOmfOvb8qyi+efogm6mnVTZpY/b6UgpIVommf3Sv2fLlsS1F0ZVN2sp5NGgEIMtqnP7Jo4c9jHNEJ2/D3nrYcJ882ft1plU27diRf2VTq7VyZBFes+5dXD0aAchKNaz+KWLjt0HPkee2FEVUNlVxd1NJpwAgierS+BfRYGU9R57bUgy7sklbOY8WBQAJtNM/TWZWpH/GPf9fRIOV9RyjtjOmtnIeHZoDkGWNBjQaS9MAddGtPLLMc8Qnb2++OfgenROoGlUbjQ4FAFmhNbelNumfUBEN1qDnKHLyNg+jGLDqLFMKyMw2An8FbAOOAL/m7v+ccNxp4Efth8+6+zVZzjuWbr01/Ubued/jN0Vz7rJapX+gmPLIrOcYpZ0xtZXzaMk6B/AZ4AF3v83MPtN+/IcJx73m7u/KeK7xtrAAExPJzw9bWJ/XTv/UaQRQRIOVxzlGaVuKTgFL6wOqJWsA2A18qP3zXwLfITkAyAhozW0p+xJKUUQPe5R68XlIClhF3WdZepd1DuAt7v48QPt72p61G8zsoJk9ama/kvGcMgR13/ytiB72KPXi85bXgjbJV9cRgJntB5K6hrf0cZ4L3f2omf1L4EEz+5G7/5+U880AMwAXbtzYxylkIOHq38YMUK/Vv1IcrQ+opq4BwN13pb1mZv/XzM519+fN7Fxg9Z0sgvc42v7+jJl9B3g3kBgA3L0JNAG2b92qfkERGg1ac1uYo175fymW1gdUT9YU0B7gY+2fPwZ8K36Amb3ZzNa3f94EfAB4KuN5x8/kJCwurv6anBz6qeue/pFiaH1A9WSdBL4N+IaZ3QA8C1wLYGbbgd91948DbwW+bGZvEASc29xdASCuoFLPFWp+60cpTtG7kUpvMgUAd38RuCLh+YPAx9s//y/gHVnOI0NUw83fpHhaH1BN2guo5uLpH6muUa+hr1sp7CjQVhB1lbL3v/L/1TQue+zXuRS2ihQA6qymm79VVdoNY1RDL8OiFFDN1XHztyrqtkpWNfQyDBoB1FG4938NN3+rol56+EVsWS31oxFAXTUaQP02f6uiXlbJjtpNYWQ0aARQY+Hmb+r5l69TD1977MuwKADUTbtsJFr+2WopCJSt0yrZUbspjIwOpYDqqtFAm79VQy+rZFVDL8OgEUBNtea2MDennn8V9NrDVw295E0jgBpS+qd61MOXMigA1Enk1o9K/1SPevhSNKWAakqrf0VEI4Caac5dRgut/hURjQDqQ5u/iUiMAkCdaPM3EYlQAKiZcPM39fxFRAGgDqKrf9vpH5V/iogCQJ1o5ldEIjIFADO71syeNLM32jeCTzvuSjP7sZkdNrPPZDmnDE6rf0UkKusI4Ango0DqjenMbA3wBeAq4G3A9Wb2toznlV5F9/5nefWviEimdQDufgjAOi9Z3AEcdvdn2sd+HdgNPJXl3NKH9t7/0dW/GgWISBFzAOcBz0Uez7efkwKF6R8RkVDXAGBm+83siYSv3T2eI2l4kHoLCzObMbODZnbw2OJij6eQRAl7/6vnLyKhrikgd9/V7Zgu5oELIo/PB452OF8TaAJs37pV9zrKQ2TzN5V/ikioiBTQAaBhZheZ2TrgOmBPAeeVCKV/RCQuaxnoR8xsHng/8G0zu7/9/C+a2V4Adz8F3ATcDxwCvuHuT2a7bOkqkv7R6l8RSZK1Cuhe4N6E548CV0ce7wX2ZjmXDCiW/hERCWklcM1oFCAiIQWAMafVvyKSRjeEGUexzd8aKP0jIqtpBDDOYpu/aRQgIlEKAOMm0tXX6l8R6UQBYEwtpX9U/ikiKRQAxlUk/aPVvyKSRAFgTCn9IyLdKACME23+JiJ9UBnoONLqXxHpgUYANaBRgIgkUQAYF7HN30ANv4h0phTQuGmsvPWjiEgajQDGmMo/RaQTBYBxEEv/qPxTRHqhADBOGg2t/hWRnikAjCmVf4pINwoAo67D5m8aBYhIJwoAY0Kbv4lIvxQAxkVs8zcRkW4yBQAzu9bMnjSzN8xse4fjjpjZj8zscTM7mOWcEtGhpdcoQES6yToCeAL4KNBLn/Myd3+Xu6cGChmMVv+KyCAyrQR290MAZpbP1chgtPpXRAZQ1ByAA39vZt8zs5mCzjneUtI/Wv0rIr3qOgIws/3AloSXbnH3b/V4ng+4+1EzOwfYZ2az7p7YgrUDxAzAhRs39vj29dWcu4wWW6DR/VgRkaiuAcDdd2U9ibsfbX9/wczuBXaQMm/g7k2gCbB961bPeu6xF0n/TE+rAkhEejf0FJCZ/YKZTYY/A/+WYPJYBtUh/SMi0qusZaAfMbN54P3At83s/vbzv2hme9uHvQX4BzP7AfAY8G13/7ss55VA0uZvyv+LSK+yVgHdC9yb8PxR4Or2z88A78xyHknRTv80UPpHRPqnlcCjRq28iOREAWBExdM/Kv8UkX4pAIwq7f0vIhkpAIwSpX9EJEcKACMouvcPKP0jIoNRABhF7fQPqOEXkcGZe3UX25rZMeCfUl7eBBwv8HKqQp+7XvS56yWPz73V3Tf3cmClA0AnZnawjltL63PXiz53vRT9uZUCEhGpKQUAEZGaGuUA0Cz7Akqiz10v+tz1UujnHtk5ABERyWaURwAiIpLBSAcAM/szM5s1sx+a2b1mdlbZ11QEM7vWzJ40szfMbOwrJczsSjP7sZkdNrPPlH09RTCzO83sBTOr1b0zzOwCM3vIzA61/8Z/v+xrKoKZbTCzx8zsB+3P/cdFnHekAwCwD3i7u/9r4GngsyVfT1GeAD5Kyl3VxomZrQG+AFwFvA243szeVu5VFeJrwJVlX0QJTgF/4O5vBd4HfLIm/79PApe7+zuBdwFXmtn7hn3SkQ4A7v737n6q/fBR4Pwyr6co7n7I3X9c9nUUZAdw2N2fcffXga8Du0u+pqFr3zP7pbKvo2ju/ry7f7/98wJwCDiv3KsaPg8sth+e2f4a+gTtSAeAmP8E3Ff2RUjuzgOeizyepwYNgoCZbQPeDXy33CsphpmtMbPHgReAfe4+9M+d6Y5gRTCz/cCWhJducfdvtY+5hWDoeHeR1zZMvXzumrCE51S6NubMbAL4a+BT7v7zsq+nCO5+GnhXey7zXjN7u7sPdQ6o8gHA3Xd1et3MPgb8MnCFj1FNa7fPXSPzwAWRx+cDR0u6FimAmZ1J0Pjf7e5/U/b1FM3dXzaz7xDMAQ01AIx0CsjMrgT+ELjG3V8t+3pkKA4ADTO7yMzWAdcBe0q+JhkSMzOGgD1NAAAAuUlEQVTgq8Ahd/982ddTFDPbHFYxmtmbgF3A7LDPO9IBALgdmAT2mdnjZvalsi+oCGb2ETObB94PfNvM7i/7moalPcl/E3A/wYTgN9z9yXKvavjM7B7gH4FfMrN5M7uh7GsqyAeA3wQub/+bftzMri77ogpwLvCQmf2QoNOzz93/57BPqpXAIiI1NeojABERGZACgIhITSkAiIjUlAKAiEhNKQCIiNSUAoCISE0pAIiI1JQCgIhITf1/9+bMOWwi5ZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "\n",
    "# Zad.\n",
    "Do do modelu \n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.0001)))\n",
    "```\n",
    "\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.0001)))\n",
    "```\n",
    "\n",
    "w każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 7ms/step - loss: 0.8459 - accuracy: 0.5472 - val_loss: 0.8222 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.7929 - accuracy: 0.4906 - val_loss: 0.7746 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.8118 - accuracy: 0.4528 - val_loss: 0.7424 - val_accuracy: 0.6809\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.7252 - accuracy: 0.7925 - val_loss: 0.7842 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.7253 - accuracy: 0.5472 - val_loss: 0.8056 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.7264 - accuracy: 0.5472 - val_loss: 0.7341 - val_accuracy: 0.5532\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.6651 - accuracy: 0.7170 - val_loss: 0.6607 - val_accuracy: 0.7447\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.6277 - accuracy: 0.8491 - val_loss: 0.6463 - val_accuracy: 0.7234\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.6004 - accuracy: 0.8113 - val_loss: 0.6205 - val_accuracy: 0.7660\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5575 - accuracy: 0.8491 - val_loss: 0.5895 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.5164 - accuracy: 0.8302 - val_loss: 0.5746 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4876 - accuracy: 0.8302 - val_loss: 0.5671 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.4611 - accuracy: 0.8491 - val_loss: 0.5714 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.4383 - accuracy: 0.8491 - val_loss: 0.5875 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.4287 - accuracy: 0.8679 - val_loss: 0.6092 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4181 - accuracy: 0.8679 - val_loss: 0.6198 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4064 - accuracy: 0.8679 - val_loss: 0.6281 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3986 - accuracy: 0.8679 - val_loss: 0.6251 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3884 - accuracy: 0.8679 - val_loss: 0.6189 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.3780 - accuracy: 0.8679 - val_loss: 0.6014 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3680 - accuracy: 0.8679 - val_loss: 0.5755 - val_accuracy: 0.8085\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3591 - accuracy: 0.8868 - val_loss: 0.5565 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3538 - accuracy: 0.8868 - val_loss: 0.5450 - val_accuracy: 0.8298\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3436 - accuracy: 0.8868 - val_loss: 0.5483 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3489 - accuracy: 0.9057 - val_loss: 0.5637 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3361 - accuracy: 0.9057 - val_loss: 0.5544 - val_accuracy: 0.7872\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3360 - accuracy: 0.8868 - val_loss: 0.5375 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3275 - accuracy: 0.9057 - val_loss: 0.5387 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3249 - accuracy: 0.8868 - val_loss: 0.5453 - val_accuracy: 0.8298\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3209 - accuracy: 0.9057 - val_loss: 0.5471 - val_accuracy: 0.8298\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3179 - accuracy: 0.9057 - val_loss: 0.5473 - val_accuracy: 0.8298\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3160 - accuracy: 0.9057 - val_loss: 0.5552 - val_accuracy: 0.8298\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.3116 - accuracy: 0.8868 - val_loss: 0.5553 - val_accuracy: 0.8298\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3111 - accuracy: 0.8868 - val_loss: 0.5643 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3061 - accuracy: 0.8868 - val_loss: 0.5574 - val_accuracy: 0.8298\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.3034 - accuracy: 0.8868 - val_loss: 0.5540 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.3019 - accuracy: 0.8868 - val_loss: 0.5574 - val_accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2987 - accuracy: 0.8868 - val_loss: 0.5536 - val_accuracy: 0.8298\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2962 - accuracy: 0.9057 - val_loss: 0.5424 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2940 - accuracy: 0.9057 - val_loss: 0.5406 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2924 - accuracy: 0.9057 - val_loss: 0.5414 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2904 - accuracy: 0.9057 - val_loss: 0.5400 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2864 - accuracy: 0.9057 - val_loss: 0.5500 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2845 - accuracy: 0.9057 - val_loss: 0.5613 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2837 - accuracy: 0.9245 - val_loss: 0.5615 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2820 - accuracy: 0.9245 - val_loss: 0.5468 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2782 - accuracy: 0.9057 - val_loss: 0.5328 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2786 - accuracy: 0.9245 - val_loss: 0.5216 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2733 - accuracy: 0.9245 - val_loss: 0.5262 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2713 - accuracy: 0.9245 - val_loss: 0.5233 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.2704 - accuracy: 0.9245 - val_loss: 0.5265 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2671 - accuracy: 0.9245 - val_loss: 0.5148 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2643 - accuracy: 0.9245 - val_loss: 0.5014 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2617 - accuracy: 0.9245 - val_loss: 0.4951 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2604 - accuracy: 0.9245 - val_loss: 0.4910 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2574 - accuracy: 0.9245 - val_loss: 0.4948 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2558 - accuracy: 0.9245 - val_loss: 0.5062 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2537 - accuracy: 0.9623 - val_loss: 0.5042 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2505 - accuracy: 0.9623 - val_loss: 0.4942 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2475 - accuracy: 0.9623 - val_loss: 0.4863 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2464 - accuracy: 0.9434 - val_loss: 0.4856 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2424 - accuracy: 0.9434 - val_loss: 0.4739 - val_accuracy: 0.8511\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2414 - accuracy: 0.9245 - val_loss: 0.4687 - val_accuracy: 0.8511\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2386 - accuracy: 0.9245 - val_loss: 0.4716 - val_accuracy: 0.8511\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2354 - accuracy: 0.9434 - val_loss: 0.4863 - val_accuracy: 0.8511\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2329 - accuracy: 0.9623 - val_loss: 0.4942 - val_accuracy: 0.8511\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2320 - accuracy: 0.9623 - val_loss: 0.4902 - val_accuracy: 0.8511\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2290 - accuracy: 0.9623 - val_loss: 0.4738 - val_accuracy: 0.8511\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2244 - accuracy: 0.9623 - val_loss: 0.4597 - val_accuracy: 0.8511\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2215 - accuracy: 0.9623 - val_loss: 0.4436 - val_accuracy: 0.8511\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2200 - accuracy: 0.9623 - val_loss: 0.4300 - val_accuracy: 0.8511\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2177 - accuracy: 0.9245 - val_loss: 0.4259 - val_accuracy: 0.8511\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2144 - accuracy: 0.9623 - val_loss: 0.4347 - val_accuracy: 0.8723\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2118 - accuracy: 0.9811 - val_loss: 0.4358 - val_accuracy: 0.8936\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2100 - accuracy: 0.9811 - val_loss: 0.4206 - val_accuracy: 0.8936\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 603us/step - loss: 0.2063 - accuracy: 0.9811 - val_loss: 0.3936 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2026 - accuracy: 0.9811 - val_loss: 0.3793 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2013 - accuracy: 0.9623 - val_loss: 0.3756 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1968 - accuracy: 0.9623 - val_loss: 0.3832 - val_accuracy: 0.8723\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1941 - accuracy: 0.9811 - val_loss: 0.3845 - val_accuracy: 0.8723\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1898 - accuracy: 0.9811 - val_loss: 0.3926 - val_accuracy: 0.8936\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1903 - accuracy: 0.9811 - val_loss: 0.3962 - val_accuracy: 0.8936\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1881 - accuracy: 0.9811 - val_loss: 0.3776 - val_accuracy: 0.8936\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.1820 - accuracy: 0.9811 - val_loss: 0.3628 - val_accuracy: 0.8723\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1800 - accuracy: 0.9811 - val_loss: 0.3439 - val_accuracy: 0.8723\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1776 - accuracy: 0.9811 - val_loss: 0.3361 - val_accuracy: 0.8936\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1760 - accuracy: 0.9811 - val_loss: 0.3249 - val_accuracy: 0.8936\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1723 - accuracy: 0.9811 - val_loss: 0.3268 - val_accuracy: 0.8936\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1731 - accuracy: 0.9811 - val_loss: 0.3360 - val_accuracy: 0.8936\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1675 - accuracy: 0.9811 - val_loss: 0.3274 - val_accuracy: 0.8936\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1642 - accuracy: 0.9811 - val_loss: 0.3199 - val_accuracy: 0.8936\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1614 - accuracy: 0.9811 - val_loss: 0.3168 - val_accuracy: 0.8936\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1613 - accuracy: 0.9811 - val_loss: 0.3143 - val_accuracy: 0.8936\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1576 - accuracy: 0.9811 - val_loss: 0.3007 - val_accuracy: 0.8936\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1553 - accuracy: 0.9811 - val_loss: 0.2947 - val_accuracy: 0.8936\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1539 - accuracy: 0.9811 - val_loss: 0.2973 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1512 - accuracy: 0.9811 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1490 - accuracy: 0.9811 - val_loss: 0.2962 - val_accuracy: 0.9149\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1467 - accuracy: 0.9811 - val_loss: 0.2985 - val_accuracy: 0.9149\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1453 - accuracy: 0.9811 - val_loss: 0.2992 - val_accuracy: 0.9149\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1439 - accuracy: 0.9811 - val_loss: 0.2957 - val_accuracy: 0.9149\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1428 - accuracy: 0.9811 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1412 - accuracy: 0.9811 - val_loss: 0.2751 - val_accuracy: 0.9149\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1394 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9149\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1368 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9149\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1348 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 640us/step - loss: 0.1331 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1316 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.1273 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.8936\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 754us/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1236 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 978us/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1222 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 969us/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1174 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1159 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 819us/step - loss: 0.1151 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1124 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9362\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.1118 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9362\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9362\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9362\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9362\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1089 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9362\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.1088 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9362\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.8936\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.8936\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.1056 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9362\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9362\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1039 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1022 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.1017 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9362\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1005 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9362\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1010 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9362\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.8936\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0994 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.8936\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.8936\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 773us/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9362\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9362\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0959 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9362\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.8936\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9149\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0937 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9362\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9362\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.8936\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 741us/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.8936\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.8936\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.8936\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.8936\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.8936\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0900 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.8936\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.8936\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.8936\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.8936\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.8936\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.8936\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.8936\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.8936\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.8936\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.8936\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.8936\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.8936\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0859 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.8936\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.8936\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.8936\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.8936\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.8936\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.8936\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.8936\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.8936\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.8936\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.8936\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.8936\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0827 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.8936\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.8936\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.8936\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.8936\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0809 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.8936\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.8936\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.8936\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.8936\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.8936\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.8936\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0788 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.8936\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.8936\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.8936\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.8936\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.8936\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.8936\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.8936\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.8936\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.8936\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.8936\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8936\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.8936\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.8936\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.8936\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 602us/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.8936\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0747 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.8936\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.8936\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.8936\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.8936\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.8936\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.8936\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.8936\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.8936\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.8936\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.8936\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.8936\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.8936\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.8936\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 725us/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.8936\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.8936\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.8936\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.8936\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.8936\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.8936\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.8936\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0692 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.8936\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.8936\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.8936\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.8936\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.8936\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.8936\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.8936\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.8936\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.8936\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.8936\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0680 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.8936\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.8936\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.8936\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.8936\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.8936\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.8936\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.8936\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.8936\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.8936\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.8936\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.8936\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.8936\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.8936\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.2894 - val_accuracy: 0.8936\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.8936\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.8936\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.8936\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.8936\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8936\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.8936\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.8936\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.8936\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8936\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8936\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.8936\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.8936\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.8936\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8936\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.8936\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.8936\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.8936\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.8936\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.8936\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.8936\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.8936\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.8936\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.8936\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.8936\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.8936\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.8936\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.8936\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.8936\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.8936\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8936\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.8936\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8936\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.8936\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.8936\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8936\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.8936\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.8936\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.8936\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8936\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.8936\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.8936\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8936\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.8936\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 0.8936\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.8936\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.8936\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.8936\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 583us/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.8936\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.8936\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.8936\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.8936\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8936\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8936\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.8936\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.8936\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.8936\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.8936\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.8936\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.8936\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.8936\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.8936\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8936\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.8936\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.3109 - val_accuracy: 0.8936\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.8936\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.8936\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.8936\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.8936\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.8936\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.8936\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.8936\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.8936\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.8936\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.8936\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.8936\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.8936\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.8936\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.8936\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.8936\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.8936\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.8936\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 603us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.8936\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.8936\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.8936\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.8936\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.8936\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.8936\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.3113 - val_accuracy: 0.8936\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.8936\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 602us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.8936\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.8936\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8936\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.8936\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 0.8936\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.8936\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.8936\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.8936\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.8936\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.8936\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.8936\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8936\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.8936\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.8936\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.8936\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.8936\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.8936\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.8936\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.8936\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 0.8936\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 0.8936\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.8936\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8936\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.8936\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.8936\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.8936\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.8936\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.8936\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.3046 - val_accuracy: 0.8936\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.8936\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.8936\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.8936\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.8936\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.8936\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.8936\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.8936\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.8936\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.8936\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.8936\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.3087 - val_accuracy: 0.8936\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.8936\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 602us/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 0.8936\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.8936\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.8936\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.8936\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.8936\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.8936\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.8936\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.8936\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.8936\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.8936\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.8936\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.8936\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.8936\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.8936\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.8936\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.8936\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.8936\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3048 - val_accuracy: 0.8936\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.8936\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.8936\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.8936\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8936\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.8936\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.8936\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.8936\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.8936\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.8936\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.3018 - val_accuracy: 0.8936\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.8936\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.8936\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.8936\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8936\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.8936\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.8936\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.8936\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.2977 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.8936\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.8936\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.8936\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.8936\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.8936\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.8936\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.8936\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8936\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.8936\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.8936\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.8936\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 640us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.8936\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0455 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 603us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0438 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.2630 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 1.00 - 0s 640us/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.2621 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9149\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2499 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.2482 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 640us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2414 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 602us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2380 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 640us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.2327 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 639us/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2301 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9362\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9362\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9362\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9362\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9362\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 640us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9362\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9362\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9362\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9362\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9362\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9362\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.9362\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9362\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9362\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9362\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9362\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9362\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9362\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9362\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9362\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9362\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9362\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 603us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9362\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9362\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9362\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9362\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9362\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9362\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9362\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9362\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9362\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9362\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9362\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9362\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9362\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9362\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9362\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9362\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9362\n",
      "Epoch 947/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9362\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9362\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9362\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9362\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9362\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9362\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9362\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9362\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9362\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9362\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9362\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9362\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9362\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9362\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9362\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9362\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9362\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9362\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9362\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9362\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9362\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9362\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9362\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9362\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9362\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9362\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9362\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9362\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9362\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9362\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9362\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9362\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9362\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9362\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2189 - val_accuracy: 0.9362\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9362\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9362\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9362\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9362\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9362\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.9362\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9362\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9362\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x233efb05f28>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "from keras.regularizers import l1\n",
    "\n",
    "\n",
    "history_Adam_2 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],), activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(500,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(200,activation=\"sigmoid\", activity_regularizer=l1(0.00001)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "# plt.plot(history_Adam_1.history['loss'], label = \"tarina dropout\")\n",
    "# plt.plot(history_Adam_1.history['val_loss'], label = \"test dropout\")\n",
    "\n",
    "plt.plot(history_Adam_2.history['loss'], label = \"tarina l1\")\n",
    "plt.plot(history_Adam_2.history['val_loss'], label = \"test l1\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
