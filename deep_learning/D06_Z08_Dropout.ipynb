{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               4200      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 2s 64us/step - loss: 0.5859 - accuracy: 0.7283 - val_loss: 0.5339 - val_accuracy: 0.7543\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.5561 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7543\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.5409 - accuracy: 0.7586 - val_loss: 0.5043 - val_accuracy: 0.7861\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.5266 - accuracy: 0.7634 - val_loss: 0.4897 - val_accuracy: 0.7818\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.5102 - accuracy: 0.7676 - val_loss: 0.4703 - val_accuracy: 0.7785\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4960 - accuracy: 0.7703 - val_loss: 0.4500 - val_accuracy: 0.7779\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4754 - accuracy: 0.7710 - val_loss: 0.4289 - val_accuracy: 0.7799\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4596 - accuracy: 0.7770 - val_loss: 0.4122 - val_accuracy: 0.7788\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.4466 - accuracy: 0.7755 - val_loss: 0.3995 - val_accuracy: 0.7782\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4404 - accuracy: 0.7791 - val_loss: 0.3957 - val_accuracy: 0.7812\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4351 - accuracy: 0.7833 - val_loss: 0.3914 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4318 - accuracy: 0.7866 - val_loss: 0.3876 - val_accuracy: 0.7889\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4263 - accuracy: 0.7867 - val_loss: 0.3852 - val_accuracy: 0.7920\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4244 - accuracy: 0.7877 - val_loss: 0.3823 - val_accuracy: 0.7921\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4208 - accuracy: 0.7913 - val_loss: 0.3797 - val_accuracy: 0.8033\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4216 - accuracy: 0.7902 - val_loss: 0.3788 - val_accuracy: 0.8099\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4151 - accuracy: 0.7939 - val_loss: 0.3759 - val_accuracy: 0.8230\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4155 - accuracy: 0.7955 - val_loss: 0.3736 - val_accuracy: 0.8226\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4131 - accuracy: 0.7949 - val_loss: 0.3723 - val_accuracy: 0.8343\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4117 - accuracy: 0.7942 - val_loss: 0.3715 - val_accuracy: 0.8269\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.4107 - accuracy: 0.7978 - val_loss: 0.3704 - val_accuracy: 0.8317\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4121 - accuracy: 0.7981 - val_loss: 0.3702 - val_accuracy: 0.8321\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.4085 - accuracy: 0.7985 - val_loss: 0.3688 - val_accuracy: 0.8317\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 52us/step - loss: 0.4093 - accuracy: 0.8008 - val_loss: 0.3690 - val_accuracy: 0.8323\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.4083 - accuracy: 0.8008 - val_loss: 0.3674 - val_accuracy: 0.8327\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4080 - accuracy: 0.7994 - val_loss: 0.3670 - val_accuracy: 0.8320\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4079 - accuracy: 0.8006 - val_loss: 0.3665 - val_accuracy: 0.8343\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4062 - accuracy: 0.8009 - val_loss: 0.3654 - val_accuracy: 0.8369\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 2s 62us/step - loss: 0.4045 - accuracy: 0.8017 - val_loss: 0.3653 - val_accuracy: 0.8373\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4039 - accuracy: 0.8015 - val_loss: 0.3648 - val_accuracy: 0.8338\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4051 - accuracy: 0.8044 - val_loss: 0.3645 - val_accuracy: 0.8351\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4025 - accuracy: 0.8049 - val_loss: 0.3644 - val_accuracy: 0.8354\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4044 - accuracy: 0.8037 - val_loss: 0.3642 - val_accuracy: 0.8349\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4040 - accuracy: 0.8048 - val_loss: 0.3637 - val_accuracy: 0.8347\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4032 - accuracy: 0.8025 - val_loss: 0.3633 - val_accuracy: 0.8348\n",
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4048 - accuracy: 0.8026 - val_loss: 0.3635 - val_accuracy: 0.8360\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 60us/step - loss: 0.4020 - accuracy: 0.8033 - val_loss: 0.3627 - val_accuracy: 0.8353\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.4043 - accuracy: 0.8025 - val_loss: 0.3628 - val_accuracy: 0.8371\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.4004 - accuracy: 0.8055 - val_loss: 0.3621 - val_accuracy: 0.8356\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4023 - accuracy: 0.8053 - val_loss: 0.3619 - val_accuracy: 0.8358\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4022 - accuracy: 0.8063 - val_loss: 0.3619 - val_accuracy: 0.8357\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4027 - accuracy: 0.8029 - val_loss: 0.3617 - val_accuracy: 0.8358\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 2s 54us/step - loss: 0.4019 - accuracy: 0.8059 - val_loss: 0.3617 - val_accuracy: 0.8365\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.4036 - accuracy: 0.8032 - val_loss: 0.3616 - val_accuracy: 0.8360\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.4024 - accuracy: 0.8059 - val_loss: 0.3598 - val_accuracy: 0.8360\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 2s 58us/step - loss: 0.3985 - accuracy: 0.8094 - val_loss: 0.3597 - val_accuracy: 0.8370\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3973 - accuracy: 0.8070 - val_loss: 0.3595 - val_accuracy: 0.8361\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.3978 - accuracy: 0.8113 - val_loss: 0.3592 - val_accuracy: 0.8364\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 2s 53us/step - loss: 0.3967 - accuracy: 0.8061 - val_loss: 0.3592 - val_accuracy: 0.8365\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3980 - accuracy: 0.8071 - val_loss: 0.3589 - val_accuracy: 0.8366\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 2s 55us/step - loss: 0.4006 - accuracy: 0.8065 - val_loss: 0.3590 - val_accuracy: 0.8363\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 2s 57us/step - loss: 0.4004 - accuracy: 0.8051 - val_loss: 0.3590 - val_accuracy: 0.8363\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 2s 56us/step - loss: 0.3993 - accuracy: 0.8054 - val_loss: 0.3589 - val_accuracy: 0.8367\n",
      "Epoch 00053: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fdc9108b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, save_best_model, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do do modelu \n",
    "```python\n",
    "model.add(Dropout(0.8))\n",
    "```\n",
    "po każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.7459 - accuracy: 0.3962 - val_loss: 0.7312 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6830 - accuracy: 0.5472 - val_loss: 0.6734 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.6909 - accuracy: 0.3774 - val_loss: 0.6491 - val_accuracy: 0.7447\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.6412 - accuracy: 0.7170 - val_loss: 0.6619 - val_accuracy: 0.4681\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6149 - accuracy: 0.5472 - val_loss: 0.6448 - val_accuracy: 0.5532\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5900 - accuracy: 0.6415 - val_loss: 0.5997 - val_accuracy: 0.7234\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5509 - accuracy: 0.8491 - val_loss: 0.5622 - val_accuracy: 0.7660\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5219 - accuracy: 0.8302 - val_loss: 0.5414 - val_accuracy: 0.7660\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.4899 - accuracy: 0.8302 - val_loss: 0.5123 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.4444 - accuracy: 0.8679 - val_loss: 0.4888 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.4030 - accuracy: 0.8491 - val_loss: 0.4741 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.3804 - accuracy: 0.8302 - val_loss: 0.4693 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.3520 - accuracy: 0.8491 - val_loss: 0.4814 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.3337 - accuracy: 0.8491 - val_loss: 0.5048 - val_accuracy: 0.7660\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.3392 - accuracy: 0.8679 - val_loss: 0.5302 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.3170 - accuracy: 0.8679 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.3118 - accuracy: 0.8679 - val_loss: 0.5114 - val_accuracy: 0.7660\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.3038 - accuracy: 0.8679 - val_loss: 0.5035 - val_accuracy: 0.7660\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2946 - accuracy: 0.8868 - val_loss: 0.5028 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2871 - accuracy: 0.8868 - val_loss: 0.5080 - val_accuracy: 0.7872\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2813 - accuracy: 0.8868 - val_loss: 0.5091 - val_accuracy: 0.7872\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.4927 - val_accuracy: 0.8085\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2633 - accuracy: 0.8868 - val_loss: 0.4808 - val_accuracy: 0.8085\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.4630 - val_accuracy: 0.8298\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2535 - accuracy: 0.9057 - val_loss: 0.4511 - val_accuracy: 0.8085\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2527 - accuracy: 0.9057 - val_loss: 0.4530 - val_accuracy: 0.8085\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2525 - accuracy: 0.9057 - val_loss: 0.4553 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2446 - accuracy: 0.9057 - val_loss: 0.4779 - val_accuracy: 0.7872\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2463 - accuracy: 0.9057 - val_loss: 0.4979 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2454 - accuracy: 0.9057 - val_loss: 0.4895 - val_accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2389 - accuracy: 0.9057 - val_loss: 0.4709 - val_accuracy: 0.8085\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2350 - accuracy: 0.8868 - val_loss: 0.4614 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2329 - accuracy: 0.9057 - val_loss: 0.4631 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2296 - accuracy: 0.9057 - val_loss: 0.4670 - val_accuracy: 0.8085\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2279 - accuracy: 0.9057 - val_loss: 0.4733 - val_accuracy: 0.8085\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2251 - accuracy: 0.8868 - val_loss: 0.4901 - val_accuracy: 0.8085\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2266 - accuracy: 0.9057 - val_loss: 0.5031 - val_accuracy: 0.8085\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2223 - accuracy: 0.9057 - val_loss: 0.4907 - val_accuracy: 0.8085\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.2196 - accuracy: 0.9057 - val_loss: 0.4750 - val_accuracy: 0.8298\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2219 - accuracy: 0.8868 - val_loss: 0.4671 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2161 - accuracy: 0.9057 - val_loss: 0.4822 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2169 - accuracy: 0.8868 - val_loss: 0.4896 - val_accuracy: 0.8085\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2133 - accuracy: 0.8868 - val_loss: 0.4770 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2099 - accuracy: 0.8868 - val_loss: 0.4723 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2107 - accuracy: 0.8868 - val_loss: 0.4602 - val_accuracy: 0.8298\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.2114 - accuracy: 0.9057 - val_loss: 0.4636 - val_accuracy: 0.8298\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2033 - accuracy: 0.9057 - val_loss: 0.4860 - val_accuracy: 0.8085\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.2133 - accuracy: 0.9057 - val_loss: 0.5145 - val_accuracy: 0.8085\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2109 - accuracy: 0.9245 - val_loss: 0.5026 - val_accuracy: 0.8085\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2069 - accuracy: 0.9057 - val_loss: 0.4628 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2011 - accuracy: 0.9057 - val_loss: 0.4511 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2047 - accuracy: 0.9057 - val_loss: 0.4523 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1954 - accuracy: 0.9057 - val_loss: 0.4771 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1909 - accuracy: 0.9057 - val_loss: 0.5088 - val_accuracy: 0.8085\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1996 - accuracy: 0.9434 - val_loss: 0.5268 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.2056 - accuracy: 0.9245 - val_loss: 0.5046 - val_accuracy: 0.8085\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1938 - accuracy: 0.9434 - val_loss: 0.4829 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1876 - accuracy: 0.9245 - val_loss: 0.4623 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1887 - accuracy: 0.9245 - val_loss: 0.4404 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1910 - accuracy: 0.9057 - val_loss: 0.4373 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1903 - accuracy: 0.9057 - val_loss: 0.4560 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1859 - accuracy: 0.9434 - val_loss: 0.4702 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1813 - accuracy: 0.9245 - val_loss: 0.4665 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1811 - accuracy: 0.9245 - val_loss: 0.4679 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1779 - accuracy: 0.9434 - val_loss: 0.4544 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1818 - accuracy: 0.9245 - val_loss: 0.4393 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1746 - accuracy: 0.9245 - val_loss: 0.4465 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1734 - accuracy: 0.9245 - val_loss: 0.4594 - val_accuracy: 0.8298\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1769 - accuracy: 0.9434 - val_loss: 0.4617 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.1692 - accuracy: 0.9623 - val_loss: 0.4392 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1704 - accuracy: 0.9245 - val_loss: 0.4148 - val_accuracy: 0.8298\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.1697 - accuracy: 0.9245 - val_loss: 0.4106 - val_accuracy: 0.8511\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.1658 - accuracy: 0.9245 - val_loss: 0.4209 - val_accuracy: 0.8298\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1613 - accuracy: 0.9434 - val_loss: 0.4422 - val_accuracy: 0.8298\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1635 - accuracy: 0.9811 - val_loss: 0.4677 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1695 - accuracy: 0.9434 - val_loss: 0.4647 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.1621 - accuracy: 0.9811 - val_loss: 0.4313 - val_accuracy: 0.8298\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1569 - accuracy: 0.9434 - val_loss: 0.3997 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1668 - accuracy: 0.9245 - val_loss: 0.3857 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1560 - accuracy: 0.9245 - val_loss: 0.4047 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1538 - accuracy: 0.9434 - val_loss: 0.4284 - val_accuracy: 0.8298\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1504 - accuracy: 0.9811 - val_loss: 0.4246 - val_accuracy: 0.8298\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1482 - accuracy: 0.9811 - val_loss: 0.4150 - val_accuracy: 0.8298\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1442 - accuracy: 0.9623 - val_loss: 0.4071 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1420 - accuracy: 0.9623 - val_loss: 0.3981 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1403 - accuracy: 0.9623 - val_loss: 0.3866 - val_accuracy: 0.8511\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.1382 - accuracy: 0.9623 - val_loss: 0.3847 - val_accuracy: 0.8511\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1362 - accuracy: 0.9623 - val_loss: 0.3811 - val_accuracy: 0.8511\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1332 - accuracy: 0.9623 - val_loss: 0.3857 - val_accuracy: 0.8511\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1376 - accuracy: 0.9811 - val_loss: 0.3896 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1327 - accuracy: 0.9811 - val_loss: 0.3655 - val_accuracy: 0.8511\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1267 - accuracy: 0.9623 - val_loss: 0.3587 - val_accuracy: 0.8511\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1248 - accuracy: 0.9623 - val_loss: 0.3573 - val_accuracy: 0.8511\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1219 - accuracy: 0.9811 - val_loss: 0.3634 - val_accuracy: 0.8723\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.1195 - accuracy: 0.9811 - val_loss: 0.3639 - val_accuracy: 0.8723\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1180 - accuracy: 0.9811 - val_loss: 0.3554 - val_accuracy: 0.8723\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1175 - accuracy: 0.9811 - val_loss: 0.3456 - val_accuracy: 0.8723\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1126 - accuracy: 0.9811 - val_loss: 0.3482 - val_accuracy: 0.8723\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1109 - accuracy: 0.9811 - val_loss: 0.3481 - val_accuracy: 0.8723\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.1077 - accuracy: 0.9811 - val_loss: 0.3345 - val_accuracy: 0.8723\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1064 - accuracy: 0.9811 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.1071 - accuracy: 0.9623 - val_loss: 0.3065 - val_accuracy: 0.8723\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.1011 - accuracy: 0.9811 - val_loss: 0.3200 - val_accuracy: 0.8723\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1011 - accuracy: 0.9811 - val_loss: 0.3301 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0976 - accuracy: 0.9811 - val_loss: 0.3086 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0959 - accuracy: 0.9811 - val_loss: 0.2883 - val_accuracy: 0.8723\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 452us/step - loss: 0.0905 - accuracy: 0.9811 - val_loss: 0.2857 - val_accuracy: 0.8936\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0888 - accuracy: 0.9811 - val_loss: 0.2769 - val_accuracy: 0.8936\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0858 - accuracy: 0.9811 - val_loss: 0.2548 - val_accuracy: 0.8936\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0876 - accuracy: 0.9811 - val_loss: 0.2383 - val_accuracy: 0.8936\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0864 - accuracy: 0.9811 - val_loss: 0.2434 - val_accuracy: 0.8936\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0792 - accuracy: 0.9811 - val_loss: 0.2367 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0779 - accuracy: 0.9811 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0742 - accuracy: 0.9811 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0722 - accuracy: 0.9811 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0688 - accuracy: 0.9811 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0674 - accuracy: 0.9811 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0641 - accuracy: 0.9811 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0621 - accuracy: 0.9811 - val_loss: 0.2076 - val_accuracy: 0.8936\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.8936\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.1987 - val_accuracy: 0.9149\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9149\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0592 - accuracy: 0.9623 - val_loss: 0.2203 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 0.2039 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9149\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9149\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9149\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9149\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9149\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 0.9149\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.8936\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.8936\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1713 - val_accuracy: 0.9149\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9149\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9362\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9362\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9149\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9362\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9149\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9362\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9149\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.8936\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.1744 - val_accuracy: 0.8936\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9362\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9362\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9149\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9362\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9362\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9362\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9149\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 0.9362\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9362\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.8936\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9149\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9149\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9149\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.8936\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.8936\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9149\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9149\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1879 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.8936\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.8936\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.8936\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.8936\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.8936\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.8936\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 0.9149\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9149\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9149\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.8936\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9149\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1841 - val_accuracy: 0.8936\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 451us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.8936\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1921 - val_accuracy: 0.8936\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.8936\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9149\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.8936\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.8936\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.8936\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.8936\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.8936\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.8936\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.8936\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 0.8936\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.8936\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 489us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9149\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9149\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9149\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9149\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9149\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.8936\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9149\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9149\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9149\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.8936\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.8936\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 0.9149\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9149\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9149\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9149\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9149\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9149\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.8936\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9149\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9149\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9149\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1965 - val_accuracy: 0.9149\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1966 - val_accuracy: 0.9149\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9149\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9149\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9149\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9149\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 0.9149\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.8936\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2078 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9149\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.8936\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2070 - val_accuracy: 0.9149\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9149\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9149\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9149\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9149\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9149\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2194 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2175 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 489us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2500 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2540 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 452us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2560 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2658 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2716 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.9796e-04 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 9.9273e-04 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2715 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.6247e-04 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.8073e-04 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 9.4930e-04 - accuracy: 1.0000 - val_loss: 0.2725 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 9.5894e-04 - accuracy: 1.0000 - val_loss: 0.2727 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.3992e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 9.5158e-04 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.3782e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 9.4018e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 9.3456e-04 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.2030e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 9.1475e-04 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 9.0828e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.1761e-04 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.0565e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.0419e-04 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 9.1807e-04 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.9213e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.7973e-04 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.8222e-04 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.9423e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.1318e-04 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.8592e-04 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.7635e-04 - accuracy: 1.0000 - val_loss: 0.2774 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.6438e-04 - accuracy: 1.0000 - val_loss: 0.2782 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 8.5276e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.5633e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.4896e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.5955e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 8.7055e-04 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 8.3501e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.1090e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.3534e-04 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.2467e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 8.8949e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 9.0003e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 8.5882e-04 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.2190e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.1554e-04 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 8.1262e-04 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.2352e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 414us/step - loss: 8.0704e-04 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.8781e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.8681e-04 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.7992e-04 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.9014e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.9444e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 8.0759e-04 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9149\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.9082e-04 - accuracy: 1.0000 - val_loss: 0.2850 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.6106e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.7267e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.5609e-04 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.9070e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 7.7374e-04 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.5002e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.3802e-04 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.2767e-04 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.3794e-04 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 7.5170e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.5708e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.4678e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 7.5197e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 7.1895e-04 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.4100e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.1277e-04 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.1841e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 7.0332e-04 - accuracy: 1.0000 - val_loss: 0.2881 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 7.2973e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 6.9999e-04 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 6.9447e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.8898e-04 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.8506e-04 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.8250e-04 - accuracy: 1.0000 - val_loss: 0.2904 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 6.8039e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.9086e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.7457e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.8219e-04 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.7199e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.8925e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.6868e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.9501e-04 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.8601e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.8010e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.6497e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 6.4992e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.4441e-04 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.6908e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.5446e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 6.4024e-04 - accuracy: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.3303e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.3666e-04 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.4667e-04 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.5991e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 6.3771e-04 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.5787e-04 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.2008e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.1996e-04 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.1864e-04 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 6.1360e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 6.1074e-04 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.0356e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.0208e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 6.0792e-04 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.0046e-04 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.9760e-04 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 6.0070e-04 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 6.0021e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 6.0332e-04 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.8942e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.8226e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.8410e-04 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.8509e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.9678e-04 - accuracy: 1.0000 - val_loss: 0.3013 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 5.9033e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.8396e-04 - accuracy: 1.0000 - val_loss: 0.3011 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.9759e-04 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.6522e-04 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.6262e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.6854e-04 - accuracy: 1.0000 - val_loss: 0.2992 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.5891e-04 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 5.5929e-04 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.5881e-04 - accuracy: 1.0000 - val_loss: 0.2988 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.6792e-04 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.5815e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 5.6715e-04 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.4764e-04 - accuracy: 1.0000 - val_loss: 0.3005 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.4400e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.5886e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.4973e-04 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.4253e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.3517e-04 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.3442e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.3229e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.3573e-04 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 5.2348e-04 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.2239e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.2258e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.2427e-04 - accuracy: 1.0000 - val_loss: 0.3028 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.2232e-04 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 5.1735e-04 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.1116e-04 - accuracy: 1.0000 - val_loss: 0.3053 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.0995e-04 - accuracy: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.2255e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.0731e-04 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.1830e-04 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 5.1177e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 5.0557e-04 - accuracy: 1.0000 - val_loss: 0.3069 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.9719e-04 - accuracy: 1.0000 - val_loss: 0.3058 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.9984e-04 - accuracy: 1.0000 - val_loss: 0.3056 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.9718e-04 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.9957e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 5.0770e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.9403e-04 - accuracy: 1.0000 - val_loss: 0.3062 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 4.9183e-04 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.9893e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.8355e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.8168e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9149\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.8641e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.7850e-04 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.7568e-04 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.7804e-04 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.7863e-04 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.8719e-04 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.9384e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 4.8003e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.6664e-04 - accuracy: 1.0000 - val_loss: 0.3104 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.6409e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.6292e-04 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.6242e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.6966e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.6913e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.7331e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.6727e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.6333e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.5073e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.4899e-04 - accuracy: 1.0000 - val_loss: 0.3100 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.4680e-04 - accuracy: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 4.4914e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 4.5534e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.4672e-04 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.4530e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.4069e-04 - accuracy: 1.0000 - val_loss: 0.3133 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.3774e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.3474e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.3238e-04 - accuracy: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.3578e-04 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.3606e-04 - accuracy: 1.0000 - val_loss: 0.3110 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.3329e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.2949e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.4196e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.2333e-04 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.2282e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.2160e-04 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.2743e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1675e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.2209e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1365e-04 - accuracy: 1.0000 - val_loss: 0.3164 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.1325e-04 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.1853e-04 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 4.1403e-04 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1114e-04 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.0884e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 4.0947e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.1562e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.2216e-04 - accuracy: 1.0000 - val_loss: 0.3209 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1049e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.0300e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.9224e-04 - accuracy: 1.0000 - val_loss: 0.3166 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.9413e-04 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.2732e-04 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 4.1933e-04 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.0551e-04 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.9611e-04 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.9013e-04 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.8757e-04 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.8549e-04 - accuracy: 1.0000 - val_loss: 0.3207 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.8691e-04 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.9202e-04 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 4.0885e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.9576e-04 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.9805e-04 - accuracy: 1.0000 - val_loss: 0.3208 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.7729e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.7600e-04 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.7531e-04 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.7480e-04 - accuracy: 1.0000 - val_loss: 0.3198 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.7992e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.8340e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.6945e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 3.7503e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 3.6700e-04 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.7361e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.6417e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.6693e-04 - accuracy: 1.0000 - val_loss: 0.3232 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.7431e-04 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.6165e-04 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.6020e-04 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.5863e-04 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5702e-04 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5573e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5460e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.5972e-04 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.5486e-04 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5116e-04 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.5088e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.5976e-04 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5920e-04 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4754e-04 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5046e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.4490e-04 - accuracy: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.4435e-04 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.5453e-04 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4475e-04 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4303e-04 - accuracy: 1.0000 - val_loss: 0.3258 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.4100e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.3751e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.3659e-04 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.3892e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.3939e-04 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.3907e-04 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.3901e-04 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.2978e-04 - accuracy: 1.0000 - val_loss: 0.3286 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2379e-04 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.3006e-04 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.5224e-04 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.4280e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.3638e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9149\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.2351e-04 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 3.2350e-04 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.1964e-04 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.2872e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.3725e-04 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.3907e-04 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.3668e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.2228e-04 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0976e-04 - accuracy: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 3.3211e-04 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2243e-04 - accuracy: 1.0000 - val_loss: 0.3260 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.2838e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.1799e-04 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0611e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.2707e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.2472e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.1939e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0902e-04 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0408e-04 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.1834e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.0603e-04 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.1124e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0395e-04 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.9633e-04 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.1353e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 3.0073e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0195e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0156e-04 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 3.0939e-04 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.0149e-04 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.9485e-04 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 3.0044e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.9334e-04 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8999e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.9250e-04 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8981e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.9602e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8960e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.8548e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.8402e-04 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8433e-04 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8636e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.9157e-04 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.8643e-04 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7971e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.7427e-04 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7851e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.8097e-04 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.9751e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.9173e-04 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7880e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8845e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.7230e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.8567e-04 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.7771e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.7612e-04 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.8110e-04 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.6845e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7618e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.7013e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6694e-04 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6684e-04 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.6572e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6462e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.6826e-04 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.6136e-04 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.6393e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.6570e-04 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5919e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.6243e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5717e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.5678e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5901e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5656e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5478e-04 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5513e-04 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.5518e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5446e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5324e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.5332e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.5053e-04 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4945e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4932e-04 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5135e-04 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.5444e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.5349e-04 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4682e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4581e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4476e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4387e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4734e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.4250e-04 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4598e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.4541e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.4044e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3950e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.4221e-04 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3844e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.3941e-04 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.3835e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 2.4449e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3865e-04 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.3887e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.3576e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.3275e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3303e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.4159e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.3871e-04 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3355e-04 - accuracy: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.9149\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.3399e-04 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3097e-04 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.3548e-04 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2872e-04 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2838e-04 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.3077e-04 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2655e-04 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.2590e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2844e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2627e-04 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2365e-04 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2353e-04 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.2294e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2506e-04 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2165e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.2591e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1975e-04 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.1908e-04 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2147e-04 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1907e-04 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1758e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1689e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1761e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1803e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.2020e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1610e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1507e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1432e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1286e-04 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9149\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.1182e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.1118e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9149\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.1073e-04 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9149\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1358e-04 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.1413e-04 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0903e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0843e-04 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0787e-04 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0728e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 2.0948e-04 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0629e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0581e-04 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0926e-04 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.0479e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0433e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0342e-04 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0321e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0278e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.0232e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0445e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0104e-04 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0076e-04 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.0036e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0227e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9929e-04 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9821e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9788e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9760e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 2.0017e-04 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9633e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 2.0017e-04 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.9730e-04 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9446e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9420e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9553e-04 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 433us/step - loss: 1.9311e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9149\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.9288e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9542e-04 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9221e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.9516e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.9258e-04 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.8975e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8938e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8914e-04 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.9074e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.9178e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8819e-04 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8697e-04 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8645e-04 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.8597e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8854e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8520e-04 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8787e-04 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8402e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.8504e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8309e-04 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8633e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8246e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8504e-04 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8309e-04 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8445e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8281e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.8125e-04 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9149\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8341e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9149\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7914e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7871e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9149\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.8080e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9149\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7887e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7731e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9149\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7654e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7706e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7656e-04 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7707e-04 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7943e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7644e-04 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7455e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7335e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7308e-04 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7248e-04 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.7305e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9149\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7393e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 1.7722e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7409e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.7119e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.6976e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.7475e-04 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9149\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.7115e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.6962e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9149\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.6965e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.6934e-04 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 470us/step - loss: 1.6861e-04 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.7046e-04 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fdc8961400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularyzacja\n",
    "\n",
    "# Zad.\n",
    "Do do modelu \n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l1(0.0001)))\n",
    "```\n",
    "\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.00001)))\n",
    "```\n",
    "* \n",
    "```python\n",
    "model.add(Dense( ... , activity_regularizer=l2(0.0001)))\n",
    "```\n",
    "\n",
    "w każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
