{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "# from tensorflow import keras as keras \n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>wage_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country wage_class  \n",
       "0          2174             0              40  United-States      <=50K  \n",
       "1             0             0              13  United-States      <=50K  \n",
       "2             0             0              40  United-States      <=50K  \n",
       "3             0             0              40  United-States      <=50K  \n",
       "4             0             0              40           Cuba      <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15060, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                500       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 9,931\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 30162 samples, validate on 15060 samples\n",
      "Epoch 1/100\n",
      "30162/30162 [==============================] - 3s 97us/step - loss: 0.7272 - accuracy: 0.4959 - val_loss: 0.5989 - val_accuracy: 0.7502\n",
      "Epoch 2/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.5701 - accuracy: 0.7295 - val_loss: 0.4967 - val_accuracy: 0.8331\n",
      "Epoch 3/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.5029 - accuracy: 0.7739 - val_loss: 0.4456 - val_accuracy: 0.8274\n",
      "Epoch 4/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.4637 - accuracy: 0.7863 - val_loss: 0.4189 - val_accuracy: 0.8181\n",
      "Epoch 5/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.4433 - accuracy: 0.7881 - val_loss: 0.4004 - val_accuracy: 0.8207\n",
      "Epoch 6/100\n",
      "30162/30162 [==============================] - 2s 75us/step - loss: 0.4280 - accuracy: 0.7919 - val_loss: 0.3888 - val_accuracy: 0.8210\n",
      "Epoch 7/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.4193 - accuracy: 0.7989 - val_loss: 0.3779 - val_accuracy: 0.8309\n",
      "Epoch 8/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.4086 - accuracy: 0.8028 - val_loss: 0.3704 - val_accuracy: 0.8372\n",
      "Epoch 9/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.4017 - accuracy: 0.8087 - val_loss: 0.3647 - val_accuracy: 0.8400\n",
      "Epoch 10/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3998 - accuracy: 0.8068 - val_loss: 0.3617 - val_accuracy: 0.8428\n",
      "Epoch 11/100\n",
      "30162/30162 [==============================] - 3s 92us/step - loss: 0.3967 - accuracy: 0.8082 - val_loss: 0.3601 - val_accuracy: 0.8418\n",
      "Epoch 12/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3927 - accuracy: 0.8113 - val_loss: 0.3575 - val_accuracy: 0.8433\n",
      "Epoch 13/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3967 - accuracy: 0.8081 - val_loss: 0.3562 - val_accuracy: 0.8449\n",
      "Epoch 14/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3909 - accuracy: 0.8133 - val_loss: 0.3541 - val_accuracy: 0.8453\n",
      "Epoch 15/100\n",
      "30162/30162 [==============================] - 2s 82us/step - loss: 0.3919 - accuracy: 0.8146 - val_loss: 0.3529 - val_accuracy: 0.8453\n",
      "Epoch 16/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3872 - accuracy: 0.8152 - val_loss: 0.3526 - val_accuracy: 0.8451\n",
      "Epoch 17/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3904 - accuracy: 0.8115 - val_loss: 0.3513 - val_accuracy: 0.8459\n",
      "Epoch 18/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3864 - accuracy: 0.8156 - val_loss: 0.3494 - val_accuracy: 0.8439\n",
      "Epoch 19/100\n",
      "30162/30162 [==============================] - 2s 75us/step - loss: 0.3897 - accuracy: 0.8125 - val_loss: 0.3496 - val_accuracy: 0.8452\n",
      "Epoch 20/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3862 - accuracy: 0.8144 - val_loss: 0.3487 - val_accuracy: 0.8444\n",
      "Epoch 21/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3894 - accuracy: 0.8114 - val_loss: 0.3482 - val_accuracy: 0.8444\n",
      "Epoch 22/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.3881 - accuracy: 0.8140 - val_loss: 0.3483 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3883 - accuracy: 0.8128 - val_loss: 0.3483 - val_accuracy: 0.8452\n",
      "Epoch 24/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3851 - accuracy: 0.8176 - val_loss: 0.3475 - val_accuracy: 0.8448\n",
      "Epoch 25/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3845 - accuracy: 0.8165 - val_loss: 0.3473 - val_accuracy: 0.8449\n",
      "Epoch 26/100\n",
      "30162/30162 [==============================] - 2s 75us/step - loss: 0.3839 - accuracy: 0.8164 - val_loss: 0.3474 - val_accuracy: 0.8449\n",
      "Epoch 27/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3847 - accuracy: 0.8141 - val_loss: 0.3471 - val_accuracy: 0.8452\n",
      "Epoch 28/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3852 - accuracy: 0.8167 - val_loss: 0.3469 - val_accuracy: 0.8449\n",
      "Epoch 29/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3830 - accuracy: 0.8171 - val_loss: 0.3461 - val_accuracy: 0.8448\n",
      "Epoch 30/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3844 - accuracy: 0.8150 - val_loss: 0.3466 - val_accuracy: 0.8448\n",
      "Epoch 31/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3873 - accuracy: 0.8131 - val_loss: 0.3464 - val_accuracy: 0.8446\n",
      "Epoch 32/100\n",
      "30162/30162 [==============================] - 2s 71us/step - loss: 0.3840 - accuracy: 0.8168 - val_loss: 0.3463 - val_accuracy: 0.8447\n",
      "Epoch 33/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3831 - accuracy: 0.8167 - val_loss: 0.3464 - val_accuracy: 0.8452\n",
      "Epoch 34/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3846 - accuracy: 0.8149 - val_loss: 0.3460 - val_accuracy: 0.8446\n",
      "Epoch 35/100\n",
      "30162/30162 [==============================] - 2s 65us/step - loss: 0.3849 - accuracy: 0.8148 - val_loss: 0.3462 - val_accuracy: 0.8446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "30162/30162 [==============================] - 2s 70us/step - loss: 0.3832 - accuracy: 0.8171 - val_loss: 0.3461 - val_accuracy: 0.8444\n",
      "Epoch 37/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3851 - accuracy: 0.8157 - val_loss: 0.3458 - val_accuracy: 0.8444\n",
      "Epoch 38/100\n",
      "30162/30162 [==============================] - 2s 73us/step - loss: 0.3841 - accuracy: 0.8175 - val_loss: 0.3462 - val_accuracy: 0.8456\n",
      "Epoch 39/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3832 - accuracy: 0.8151 - val_loss: 0.3459 - val_accuracy: 0.8444\n",
      "Epoch 40/100\n",
      "30162/30162 [==============================] - 2s 69us/step - loss: 0.3841 - accuracy: 0.8168 - val_loss: 0.3456 - val_accuracy: 0.8445\n",
      "Epoch 41/100\n",
      "30162/30162 [==============================] - 2s 76us/step - loss: 0.3833 - accuracy: 0.8150 - val_loss: 0.3460 - val_accuracy: 0.8446\n",
      "Epoch 42/100\n",
      "30162/30162 [==============================] - 2s 77us/step - loss: 0.3829 - accuracy: 0.8186 - val_loss: 0.3457 - val_accuracy: 0.8443\n",
      "Epoch 43/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3859 - accuracy: 0.8145 - val_loss: 0.3457 - val_accuracy: 0.8444\n",
      "Epoch 44/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3824 - accuracy: 0.8169 - val_loss: 0.3454 - val_accuracy: 0.8446\n",
      "Epoch 45/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3845 - accuracy: 0.8173 - val_loss: 0.3459 - val_accuracy: 0.8442\n",
      "Epoch 46/100\n",
      "30162/30162 [==============================] - 2s 75us/step - loss: 0.3826 - accuracy: 0.8156 - val_loss: 0.3458 - val_accuracy: 0.8442\n",
      "Epoch 47/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3839 - accuracy: 0.8151 - val_loss: 0.3456 - val_accuracy: 0.8450\n",
      "Epoch 48/100\n",
      "30162/30162 [==============================] - 2s 67us/step - loss: 0.3833 - accuracy: 0.8147 - val_loss: 0.3453 - val_accuracy: 0.8446\n",
      "Epoch 49/100\n",
      "30162/30162 [==============================] - 2s 75us/step - loss: 0.3803 - accuracy: 0.8194 - val_loss: 0.3458 - val_accuracy: 0.8456\n",
      "Epoch 50/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3842 - accuracy: 0.8179 - val_loss: 0.3459 - val_accuracy: 0.8457\n",
      "Epoch 51/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3836 - accuracy: 0.8154 - val_loss: 0.3454 - val_accuracy: 0.8446\n",
      "Epoch 52/100\n",
      "30162/30162 [==============================] - 2s 76us/step - loss: 0.3820 - accuracy: 0.8163 - val_loss: 0.3453 - val_accuracy: 0.8446\n",
      "Epoch 53/100\n",
      "30162/30162 [==============================] - 2s 68us/step - loss: 0.3815 - accuracy: 0.8191 - val_loss: 0.3456 - val_accuracy: 0.8443\n",
      "Epoch 54/100\n",
      "30162/30162 [==============================] - 2s 81us/step - loss: 0.3827 - accuracy: 0.8171 - val_loss: 0.3455 - val_accuracy: 0.8446\n",
      "Epoch 55/100\n",
      "30162/30162 [==============================] - 2s 80us/step - loss: 0.3862 - accuracy: 0.8140 - val_loss: 0.3455 - val_accuracy: 0.8442\n",
      "Epoch 56/100\n",
      "30162/30162 [==============================] - 2s 66us/step - loss: 0.3819 - accuracy: 0.8183 - val_loss: 0.3452 - val_accuracy: 0.8448\n",
      "Epoch 57/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.3840 - accuracy: 0.8177 - val_loss: 0.3450 - val_accuracy: 0.8450\n",
      "Epoch 58/100\n",
      "30162/30162 [==============================] - 2s 74us/step - loss: 0.3837 - accuracy: 0.8154 - val_loss: 0.3451 - val_accuracy: 0.8450\n",
      "Epoch 59/100\n",
      "30162/30162 [==============================] - 2s 79us/step - loss: 0.3817 - accuracy: 0.8161 - val_loss: 0.3455 - val_accuracy: 0.8440\n",
      "Epoch 60/100\n",
      "30162/30162 [==============================] - 2s 76us/step - loss: 0.3831 - accuracy: 0.8160 - val_loss: 0.3454 - val_accuracy: 0.8446\n",
      "Epoch 61/100\n",
      "30162/30162 [==============================] - 3s 92us/step - loss: 0.3831 - accuracy: 0.8162 - val_loss: 0.3456 - val_accuracy: 0.8443\n",
      "Epoch 62/100\n",
      "30162/30162 [==============================] - 2s 81us/step - loss: 0.3841 - accuracy: 0.8157 - val_loss: 0.3450 - val_accuracy: 0.8446\n",
      "Epoch 63/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3806 - accuracy: 0.8175 - val_loss: 0.3455 - val_accuracy: 0.8443\n",
      "Epoch 64/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3858 - accuracy: 0.8164 - val_loss: 0.3453 - val_accuracy: 0.8446\n",
      "Epoch 65/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3829 - accuracy: 0.8136 - val_loss: 0.3452 - val_accuracy: 0.8448\n",
      "Epoch 66/100\n",
      "30162/30162 [==============================] - 2s 78us/step - loss: 0.3832 - accuracy: 0.8164 - val_loss: 0.3454 - val_accuracy: 0.8442\n",
      "Epoch 67/100\n",
      "30162/30162 [==============================] - 2s 72us/step - loss: 0.3794 - accuracy: 0.8210 - val_loss: 0.3455 - val_accuracy: 0.8449\n",
      "Epoch 00067: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27263437978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100, use_bias=False,input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "Adam = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=Adam, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_Adam, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_Adam.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad.\n",
    "Do poniższego modelu dodaj\n",
    " \n",
    "```python\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "```\n",
    "\n",
    "w każdej warstwie.\n",
    "\n",
    "Zwizualizuj wyniki dla obu modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=5)\n",
    "# split into train and test\n",
    "# n_train = 30\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.70, random_state=2)\n",
    "\n",
    "n_train=53\n",
    "X_train, X_test = X[:n_train, :], X[n_train:, :]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "plt.scatter(X_train[:,0],X_train[:,1], c=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1000)              3000      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               100200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 603,901\n",
      "Trainable params: 603,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5094 - val_loss: 0.7139 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.7046 - accuracy: 0.4528 - val_loss: 0.6621 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6659 - accuracy: 0.4906 - val_loss: 0.6870 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.6494 - accuracy: 0.5472 - val_loss: 0.6713 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 639us/step - loss: 0.6190 - accuracy: 0.6604 - val_loss: 0.6086 - val_accuracy: 0.7447\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5808 - accuracy: 0.8113 - val_loss: 0.5816 - val_accuracy: 0.7660\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.5513 - accuracy: 0.8491 - val_loss: 0.5549 - val_accuracy: 0.7447\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.5019 - accuracy: 0.8302 - val_loss: 0.5250 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.4581 - accuracy: 0.8302 - val_loss: 0.4970 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4158 - accuracy: 0.8491 - val_loss: 0.4800 - val_accuracy: 0.7447\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3771 - accuracy: 0.8491 - val_loss: 0.4810 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3558 - accuracy: 0.8491 - val_loss: 0.4898 - val_accuracy: 0.7447\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3336 - accuracy: 0.8679 - val_loss: 0.4995 - val_accuracy: 0.7447\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3234 - accuracy: 0.8679 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3128 - accuracy: 0.8679 - val_loss: 0.5438 - val_accuracy: 0.7660\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3078 - accuracy: 0.8679 - val_loss: 0.5424 - val_accuracy: 0.7872\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2959 - accuracy: 0.8679 - val_loss: 0.5462 - val_accuracy: 0.7872\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2901 - accuracy: 0.8679 - val_loss: 0.5404 - val_accuracy: 0.7872\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2754 - accuracy: 0.8679 - val_loss: 0.5137 - val_accuracy: 0.7872\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.4861 - val_accuracy: 0.8085\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2599 - accuracy: 0.8868 - val_loss: 0.4643 - val_accuracy: 0.8298\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2551 - accuracy: 0.8868 - val_loss: 0.4558 - val_accuracy: 0.8298\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2535 - accuracy: 0.9057 - val_loss: 0.4545 - val_accuracy: 0.8085\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2525 - accuracy: 0.9057 - val_loss: 0.4880 - val_accuracy: 0.8085\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2429 - accuracy: 0.9057 - val_loss: 0.4895 - val_accuracy: 0.7872\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2407 - accuracy: 0.9057 - val_loss: 0.4758 - val_accuracy: 0.8085\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2345 - accuracy: 0.8868 - val_loss: 0.4519 - val_accuracy: 0.8085\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2332 - accuracy: 0.9057 - val_loss: 0.4371 - val_accuracy: 0.8085\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2321 - accuracy: 0.9057 - val_loss: 0.4448 - val_accuracy: 0.8085\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2281 - accuracy: 0.9057 - val_loss: 0.4643 - val_accuracy: 0.8298\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.2243 - accuracy: 0.8868 - val_loss: 0.4922 - val_accuracy: 0.8085\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2239 - accuracy: 0.8868 - val_loss: 0.4989 - val_accuracy: 0.8085\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2213 - accuracy: 0.9057 - val_loss: 0.4837 - val_accuracy: 0.8085\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2149 - accuracy: 0.8868 - val_loss: 0.4574 - val_accuracy: 0.8298\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2172 - accuracy: 0.9057 - val_loss: 0.4468 - val_accuracy: 0.8085\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2179 - accuracy: 0.9057 - val_loss: 0.4564 - val_accuracy: 0.8298\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.2119 - accuracy: 0.9057 - val_loss: 0.4801 - val_accuracy: 0.8085\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2210 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.8085\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2206 - accuracy: 0.9057 - val_loss: 0.5117 - val_accuracy: 0.8085\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2080 - accuracy: 0.9245 - val_loss: 0.4630 - val_accuracy: 0.8298\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2053 - accuracy: 0.9057 - val_loss: 0.4398 - val_accuracy: 0.8298\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2111 - accuracy: 0.9057 - val_loss: 0.4427 - val_accuracy: 0.8298\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2059 - accuracy: 0.9057 - val_loss: 0.4513 - val_accuracy: 0.8298\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.2005 - accuracy: 0.9057 - val_loss: 0.4650 - val_accuracy: 0.8298\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.1977 - accuracy: 0.9245 - val_loss: 0.4753 - val_accuracy: 0.8085\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2033 - accuracy: 0.9245 - val_loss: 0.4735 - val_accuracy: 0.8085\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2031 - accuracy: 0.9057 - val_loss: 0.4423 - val_accuracy: 0.8298\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1957 - accuracy: 0.9245 - val_loss: 0.4377 - val_accuracy: 0.8298\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1940 - accuracy: 0.9245 - val_loss: 0.4492 - val_accuracy: 0.8298\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2020 - accuracy: 0.9057 - val_loss: 0.4619 - val_accuracy: 0.8298\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 565us/step - loss: 0.1896 - accuracy: 0.9057 - val_loss: 0.4487 - val_accuracy: 0.8298\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1900 - accuracy: 0.9245 - val_loss: 0.4320 - val_accuracy: 0.8298\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1924 - accuracy: 0.9057 - val_loss: 0.4341 - val_accuracy: 0.8298\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1917 - accuracy: 0.9057 - val_loss: 0.4605 - val_accuracy: 0.8298\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1861 - accuracy: 0.9434 - val_loss: 0.4751 - val_accuracy: 0.8298\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1840 - accuracy: 0.9245 - val_loss: 0.4669 - val_accuracy: 0.8298\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1826 - accuracy: 0.9245 - val_loss: 0.4661 - val_accuracy: 0.8298\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1801 - accuracy: 0.9434 - val_loss: 0.4520 - val_accuracy: 0.8298\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1812 - accuracy: 0.9245 - val_loss: 0.4449 - val_accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1777 - accuracy: 0.9245 - val_loss: 0.4555 - val_accuracy: 0.8298\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1746 - accuracy: 0.9434 - val_loss: 0.4634 - val_accuracy: 0.8298\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1743 - accuracy: 0.9434 - val_loss: 0.4678 - val_accuracy: 0.8298\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1748 - accuracy: 0.9434 - val_loss: 0.4593 - val_accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1709 - accuracy: 0.9623 - val_loss: 0.4571 - val_accuracy: 0.8298\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1690 - accuracy: 0.9623 - val_loss: 0.4437 - val_accuracy: 0.8298\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1666 - accuracy: 0.9434 - val_loss: 0.4362 - val_accuracy: 0.8298\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1662 - accuracy: 0.9245 - val_loss: 0.4266 - val_accuracy: 0.8298\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1639 - accuracy: 0.9245 - val_loss: 0.4292 - val_accuracy: 0.8298\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1618 - accuracy: 0.9434 - val_loss: 0.4402 - val_accuracy: 0.8298\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1601 - accuracy: 0.9623 - val_loss: 0.4373 - val_accuracy: 0.8298\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1621 - accuracy: 0.9623 - val_loss: 0.4330 - val_accuracy: 0.8298\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1603 - accuracy: 0.9245 - val_loss: 0.4058 - val_accuracy: 0.8511\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1557 - accuracy: 0.9245 - val_loss: 0.4045 - val_accuracy: 0.8511\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1519 - accuracy: 0.9245 - val_loss: 0.3981 - val_accuracy: 0.8511\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1521 - accuracy: 0.9245 - val_loss: 0.3967 - val_accuracy: 0.8511\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1482 - accuracy: 0.9623 - val_loss: 0.3892 - val_accuracy: 0.8511\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1463 - accuracy: 0.9434 - val_loss: 0.3954 - val_accuracy: 0.8511\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1465 - accuracy: 0.9434 - val_loss: 0.3941 - val_accuracy: 0.8511\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1397 - accuracy: 0.9623 - val_loss: 0.4100 - val_accuracy: 0.8511\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1389 - accuracy: 0.9811 - val_loss: 0.4189 - val_accuracy: 0.8511\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1396 - accuracy: 0.9811 - val_loss: 0.4080 - val_accuracy: 0.8511\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1371 - accuracy: 0.9623 - val_loss: 0.3956 - val_accuracy: 0.8723\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1320 - accuracy: 0.9623 - val_loss: 0.3868 - val_accuracy: 0.8723\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1303 - accuracy: 0.9811 - val_loss: 0.3733 - val_accuracy: 0.8511\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1270 - accuracy: 0.9811 - val_loss: 0.3650 - val_accuracy: 0.8511\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1244 - accuracy: 0.9811 - val_loss: 0.3635 - val_accuracy: 0.8723\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1215 - accuracy: 0.9811 - val_loss: 0.3652 - val_accuracy: 0.8723\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1196 - accuracy: 0.9811 - val_loss: 0.3632 - val_accuracy: 0.8723\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.1172 - accuracy: 0.9811 - val_loss: 0.3507 - val_accuracy: 0.8723\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.1151 - accuracy: 0.9623 - val_loss: 0.3373 - val_accuracy: 0.8723\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.1121 - accuracy: 0.9623 - val_loss: 0.3366 - val_accuracy: 0.8723\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.1107 - accuracy: 0.9623 - val_loss: 0.3400 - val_accuracy: 0.8723\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1068 - accuracy: 0.9811 - val_loss: 0.3586 - val_accuracy: 0.8936\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1067 - accuracy: 0.9811 - val_loss: 0.3476 - val_accuracy: 0.8936\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.1068 - accuracy: 0.9811 - val_loss: 0.3263 - val_accuracy: 0.8936\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0990 - accuracy: 0.9811 - val_loss: 0.3175 - val_accuracy: 0.8936\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0955 - accuracy: 0.9811 - val_loss: 0.2979 - val_accuracy: 0.8723\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0933 - accuracy: 0.9811 - val_loss: 0.2766 - val_accuracy: 0.8723\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0915 - accuracy: 0.9811 - val_loss: 0.2641 - val_accuracy: 0.8723\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0890 - accuracy: 0.9811 - val_loss: 0.2635 - val_accuracy: 0.8936\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0846 - accuracy: 0.9811 - val_loss: 0.2770 - val_accuracy: 0.8936\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0840 - accuracy: 0.9811 - val_loss: 0.2819 - val_accuracy: 0.8936\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0853 - accuracy: 0.9811 - val_loss: 0.2684 - val_accuracy: 0.8936\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0798 - accuracy: 0.9811 - val_loss: 0.2622 - val_accuracy: 0.8936\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0758 - accuracy: 0.9811 - val_loss: 0.2596 - val_accuracy: 0.8936\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0729 - accuracy: 0.9811 - val_loss: 0.2408 - val_accuracy: 0.9149\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 0.0734 - accuracy: 0.9811 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0683 - accuracy: 0.9811 - val_loss: 0.2179 - val_accuracy: 0.9149\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.2223 - val_accuracy: 0.9149\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0657 - accuracy: 0.9623 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0665 - accuracy: 0.9623 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.1954 - val_accuracy: 0.9149\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.8936\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.8936\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.9149\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.2298 - val_accuracy: 0.9149\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9149\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9149\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.8936\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.8936\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.8936\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9149\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9149\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0435 - accuracy: 0.9811 - val_loss: 0.2131 - val_accuracy: 0.9149\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0445 - accuracy: 0.9811 - val_loss: 0.1917 - val_accuracy: 0.9149\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9149\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9149\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.1709 - val_accuracy: 0.9149\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9149\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9149\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9149\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9149\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9149\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.8936\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.8936\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9149\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9149\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.9149\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9149\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9362\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9149\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.8936\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9149\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9362\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9362\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9149\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9149\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.8936\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1802 - val_accuracy: 0.9149\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9362\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9149\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9362\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9362\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9149\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.8936\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9149\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 0.9149\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9149\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9149\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9362\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 565us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9149\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9149\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9149\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9149\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9362\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9362\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9362\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9149\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9149\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9149\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9149\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9149\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.9149\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9362\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9149\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9149\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 0.9149\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.8936\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9149\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9149\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9149\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9149\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.8936\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9149\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.8936\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9149\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9362\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9362\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9149\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.8936\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9149\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.8936\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.8936\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.8936\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9149\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9149\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9149\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.8936\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9149\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.9149\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9149\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9149\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9362\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9362\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9149\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9149\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9149\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9149\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9149\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9149\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 0.9149\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9149\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.8936\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 0.9149\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9149\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9149\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.8936\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.8936\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.8936\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9149\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.8936\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.8936\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.8936\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.8936\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9149\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.8936\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9149\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9149\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9149\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9149\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9149\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9149\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9149\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1992 - val_accuracy: 0.9149\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9149\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9149\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2034 - val_accuracy: 0.9149\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9149\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9149\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.8936\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.8936\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.8936\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9149\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.8936\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.8936\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.8936\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9149\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9149\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2061 - val_accuracy: 0.9149\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9149\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9149\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9149\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9149\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.9149\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9149\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9149\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.9149\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9149\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9149\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9149\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9149\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9149\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9362\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9149\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2046 - val_accuracy: 0.9149\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2062 - val_accuracy: 0.9149\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9149\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9149\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.9362\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9149\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9149\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9149\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9149\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9149\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9149\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9149\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9149\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 674us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9149\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9149\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9149\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9149\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9149\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9149\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 0.9149\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9149\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9149\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9149\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9149\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9149\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9149\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9149\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9149\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9149\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.9149\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9149\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2261 - val_accuracy: 0.9149\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9149\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9149\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9149\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.9149\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9149\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9149\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9149\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2246 - val_accuracy: 0.9149\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9149\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9149\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9149\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9149\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9149\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9149\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9149\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 838us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9149\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 632us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9149\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9149\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 640us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9149\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9149\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9149\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 591us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9149\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 822us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9149\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.9149\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9149\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9149\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 706us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9149\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9149\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9149\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9149\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 633us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9149\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9149\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9149\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9149\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9149\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2357 - val_accuracy: 0.9149\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9149\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.9149\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9149\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9149\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9149\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9149\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 0.9149\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9149\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9149\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9149\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9149\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9149\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.9149\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9149\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9149\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9149\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9149\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9149\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9149\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9149\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9149\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9149\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9149\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9149\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.9149\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9149\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9149\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9149\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9149\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 583us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9149\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9149\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9149\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9149\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9149\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9149\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9149\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9149\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9149\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9149\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9149\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9149\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9149\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9149\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9149\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9149\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9149\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9149\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 0.9149\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9149\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 668us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9149\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9149\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9149\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 0.9149\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2513 - val_accuracy: 0.9149\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9149\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9149\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9149\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9149\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9149\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9149\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.9149\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9149\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9149\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 0.9149\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 599us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9149\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9149\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9149\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9149\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9149\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9149\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9149\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9149\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9149\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9149\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9149\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9149\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9149\n",
      "Epoch 443/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 734us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9149\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9149\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9149\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9149\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9149\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2562 - val_accuracy: 0.9149\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9149\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9149\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 865us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 0.9149\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9149\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9149\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9149\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9149\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9149\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 789us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9149\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 778us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 0.9149\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 648us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9149\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9149\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9149\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9149\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9149\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9149\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2670 - val_accuracy: 0.9149\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9149\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.9110e-04 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9149\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 9.7720e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9149\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 9.6816e-04 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9149\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 9.6735e-04 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.6438e-04 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9149\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 9.5607e-04 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 9.4547e-04 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9149\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 9.7944e-04 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9149\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.7741e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9149\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 9.2940e-04 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9149\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.2574e-04 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 0.9149\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.4201e-04 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9149\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 9.1602e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9149\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 9.5688e-04 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9149\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.5334e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 9.0079e-04 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9149\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 9.2719e-04 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9149\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 9.0234e-04 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9149\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 9.4019e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9149\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 8.8979e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9149\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 9.1479e-04 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9149\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 8.7069e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9149\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 8.8791e-04 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 0.9149\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 8.6142e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9149\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.5805e-04 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9149\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.9065e-04 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.5557e-04 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 8.8481e-04 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9149\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 8.4145e-04 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9149\n",
      "Epoch 498/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 772us/step - loss: 8.3334e-04 - accuracy: 1.0000 - val_loss: 0.2746 - val_accuracy: 0.9149\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.2776e-04 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 8.5253e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9149\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 8.1870e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9149\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 8.2896e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 8.1274e-04 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9149\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 8.1374e-04 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9149\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 8.4351e-04 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 0.9149\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 8.0968e-04 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9149\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 7.9172e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9149\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 7.9646e-04 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9149\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 7.9493e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9149\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 8.0495e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 7.7631e-04 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9149\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 7.7218e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9149\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 7.8059e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9149\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 7.7625e-04 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 0.9149\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 7.8489e-04 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9149\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 8.0545e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9149\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 7.5611e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9149\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 7.4755e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 7.5602e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9149\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 869us/step - loss: 7.4125e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9149\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 7.4422e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9149\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 876us/step - loss: 7.4288e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 673us/step - loss: 7.4992e-04 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9149\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 7.2239e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9149\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 7.2501e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 7.3078e-04 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9149\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 7.3640e-04 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9149\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 7.2755e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9149\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 7.4725e-04 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9149\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 7.0148e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9149\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 6.9970e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9149\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 7.1899e-04 - accuracy: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9149\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 6.9481e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9149\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 6.8860e-04 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9149\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 6.8613e-04 - accuracy: 1.0000 - val_loss: 0.2815 - val_accuracy: 0.9149\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 7.0397e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9149\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.7859e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9149\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 7.0504e-04 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9149\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 6.9195e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9149\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 6.9176e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9149\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.9153e-04 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9149\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 752us/step - loss: 6.6004e-04 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9149\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.5673e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9149\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 6.6814e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.5042e-04 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 0.9149\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 6.4871e-04 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9149\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 6.4534e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9149\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.5674e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 6.3962e-04 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9149\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.3498e-04 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9149\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 722us/step - loss: 6.6081e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9149\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 6.3704e-04 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 6.2862e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9149\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.1605e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9149\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.2389e-04 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9149\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 6.3692e-04 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9149\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 599us/step - loss: 6.4348e-04 - accuracy: 1.0000 - val_loss: 0.2930 - val_accuracy: 0.9149\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 6.5065e-04 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9149\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 647us/step - loss: 6.1838e-04 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9149\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 6.0919e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 6.2549e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 6.0096e-04 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9149\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 6.1468e-04 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9149\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 6.1602e-04 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 0.9149\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 6.1155e-04 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 0.9149\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 5.8985e-04 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9149\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 5.9664e-04 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9149\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 6.0724e-04 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9149\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 5.8368e-04 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9149\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.8747e-04 - accuracy: 1.0000 - val_loss: 0.2915 - val_accuracy: 0.9149\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 6.0327e-04 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9149\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.9433e-04 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9149\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 819us/step - loss: 5.9634e-04 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.9149\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 726us/step - loss: 5.6830e-04 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9149\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.6557e-04 - accuracy: 1.0000 - val_loss: 0.2924 - val_accuracy: 0.9149\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 5.7452e-04 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9149\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.6031e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9149\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 684us/step - loss: 5.8095e-04 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9149\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 5.5745e-04 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9149\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.5683e-04 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9149\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 5.5082e-04 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 0.9149\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.5157e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9149\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 886us/step - loss: 5.5494e-04 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9149\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.6615e-04 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9149\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.5581e-04 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9149\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.6315e-04 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9149\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.3522e-04 - accuracy: 1.0000 - val_loss: 0.2947 - val_accuracy: 0.9149\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 5.4669e-04 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9149\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 5.3117e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9149\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.2772e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9149\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.2654e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9149\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.3645e-04 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.2181e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 5.2089e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9149\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.3150e-04 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9149\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.2903e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9149\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 5.1381e-04 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.9149\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 5.0962e-04 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9149\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.0770e-04 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9149\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 5.1342e-04 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9149\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.0461e-04 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9149\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 5.0494e-04 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9149\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 5.1501e-04 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.9149\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9837e-04 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9149\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.0511e-04 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9149\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 5.0839e-04 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9149\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 734us/step - loss: 5.0690e-04 - accuracy: 1.0000 - val_loss: 0.2978 - val_accuracy: 0.9149\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 4.9849e-04 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9149\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 4.8692e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.9149\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 5.0100e-04 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 0.9149\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.8360e-04 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.9149\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 4.9464e-04 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9149\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.7802e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9149\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.7600e-04 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9149\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.7415e-04 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 0.9149\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.7193e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9149\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.8126e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9149\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.7394e-04 - accuracy: 1.0000 - val_loss: 0.3017 - val_accuracy: 0.9149\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.8764e-04 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9149\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.7756e-04 - accuracy: 1.0000 - val_loss: 0.3037 - val_accuracy: 0.9149\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.6591e-04 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9149\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.7866e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9149\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.6056e-04 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9149\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.5809e-04 - accuracy: 1.0000 - val_loss: 0.3020 - val_accuracy: 0.9149\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 4.5465e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9149\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 4.5859e-04 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 0.9149\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.5086e-04 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.4739e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9149\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.7937e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9149\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.6886e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9149\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.6071e-04 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9149\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.5663e-04 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9149\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.6105e-04 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9149\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.3724e-04 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 0.9149\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.3598e-04 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9149\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.3438e-04 - accuracy: 1.0000 - val_loss: 0.3049 - val_accuracy: 0.9149\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.4023e-04 - accuracy: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9149\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 4.4447e-04 - accuracy: 1.0000 - val_loss: 0.3045 - val_accuracy: 0.9149\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 4.2958e-04 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9149\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.2758e-04 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9149\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.2490e-04 - accuracy: 1.0000 - val_loss: 0.3072 - val_accuracy: 0.9149\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.2352e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9149\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.2815e-04 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9149\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.2398e-04 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.2041e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.2368e-04 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.2111e-04 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9149\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.3128e-04 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9149\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.1226e-04 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9149\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.1009e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9149\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.0828e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9149\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.0632e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9149\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.1312e-04 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 0.9149\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.1697e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9149\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.0308e-04 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9149\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 4.0060e-04 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9149\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.0912e-04 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9149\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 4.0266e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.9547e-04 - accuracy: 1.0000 - val_loss: 0.3088 - val_accuracy: 0.9149\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 4.1384e-04 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 0.9149\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.9816e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.9623e-04 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9149\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.9267e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9149\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.9281e-04 - accuracy: 1.0000 - val_loss: 0.3097 - val_accuracy: 0.9149\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 4.0498e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.8640e-04 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9149\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.9333e-04 - accuracy: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9149\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.8297e-04 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9149\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.8206e-04 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9149\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.8054e-04 - accuracy: 1.0000 - val_loss: 0.3121 - val_accuracy: 0.9149\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.8739e-04 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9149\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.7659e-04 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9149\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.7528e-04 - accuracy: 1.0000 - val_loss: 0.3125 - val_accuracy: 0.9149\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.8158e-04 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9149\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.8327e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9149\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.8112e-04 - accuracy: 1.0000 - val_loss: 0.3123 - val_accuracy: 0.9149\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.6922e-04 - accuracy: 1.0000 - val_loss: 0.3127 - val_accuracy: 0.9149\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.6770e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9149\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.7425e-04 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9149\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.7484e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.7192e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9149\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.6695e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.6157e-04 - accuracy: 1.0000 - val_loss: 0.3152 - val_accuracy: 0.9149\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.7625e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.6238e-04 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 0.9149\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.6312e-04 - accuracy: 1.0000 - val_loss: 0.3165 - val_accuracy: 0.9149\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.7171e-04 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9149\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.5368e-04 - accuracy: 1.0000 - val_loss: 0.3142 - val_accuracy: 0.9149\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.5766e-04 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9149\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.5331e-04 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9149\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.5100e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.5212e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9149\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.5702e-04 - accuracy: 1.0000 - val_loss: 0.3134 - val_accuracy: 0.9149\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.5273e-04 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9149\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.4731e-04 - accuracy: 1.0000 - val_loss: 0.3132 - val_accuracy: 0.9149\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.4547e-04 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9149\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.4219e-04 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9149\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.4158e-04 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9149\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.3832e-04 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9149\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.3836e-04 - accuracy: 1.0000 - val_loss: 0.3181 - val_accuracy: 0.9149\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.5553e-04 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9149\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.4848e-04 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9149\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.3948e-04 - accuracy: 1.0000 - val_loss: 0.3172 - val_accuracy: 0.9149\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.3246e-04 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9149\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.4540e-04 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9149\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.4077e-04 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9149\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.3046e-04 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9149\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.2623e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9149\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.2541e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.2625e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9149\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 3.4520e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.4135e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9149\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.2672e-04 - accuracy: 1.0000 - val_loss: 0.3217 - val_accuracy: 0.9149\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.3386e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9149\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.2210e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9149\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 621us/step - loss: 3.1716e-04 - accuracy: 1.0000 - val_loss: 0.3188 - val_accuracy: 0.9149\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 3.1622e-04 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9149\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.1917e-04 - accuracy: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9149\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.1730e-04 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9149\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.1728e-04 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9149\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.2166e-04 - accuracy: 1.0000 - val_loss: 0.3189 - val_accuracy: 0.9149\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.1687e-04 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9149\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.9149\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.1009e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9149\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 3.0758e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9149\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.0573e-04 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9149\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.0480e-04 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.9149\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.0446e-04 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9149\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.0862e-04 - accuracy: 1.0000 - val_loss: 0.3236 - val_accuracy: 0.9149\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.1181e-04 - accuracy: 1.0000 - val_loss: 0.3226 - val_accuracy: 0.9149\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 3.0049e-04 - accuracy: 1.0000 - val_loss: 0.3228 - val_accuracy: 0.9149\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.9947e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9149\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.9853e-04 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.9149\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 3.0248e-04 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 0.9149\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 3.0528e-04 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9149\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 2.9568e-04 - accuracy: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9149\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.9872e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9149\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 3.0249e-04 - accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9149\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.9263e-04 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9149\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.9191e-04 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 0.9149\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.9067e-04 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9149\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.9362e-04 - accuracy: 1.0000 - val_loss: 0.3255 - val_accuracy: 0.9149\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.8934e-04 - accuracy: 1.0000 - val_loss: 0.3265 - val_accuracy: 0.9149\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.8807e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9149\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.8984e-04 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9149\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.9100e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9149\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.9495e-04 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9149\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.8808e-04 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9149\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.9070e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9149\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.8468e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9149\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.9186e-04 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9149\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.8656e-04 - accuracy: 1.0000 - val_loss: 0.3267 - val_accuracy: 0.9149\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.8193e-04 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9149\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.7678e-04 - accuracy: 1.0000 - val_loss: 0.3290 - val_accuracy: 0.9149\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.7434e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9149\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.7864e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.9507e-04 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9149\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.9285e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9149\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.8610e-04 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9149\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 2.7543e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.7237e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.7060e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9149\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.6935e-04 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9149\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.7135e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9149\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.6843e-04 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9149\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.6743e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9149\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.6892e-04 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9149\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.8117e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9149\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.7317e-04 - accuracy: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9149\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.7865e-04 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.6179e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.7070e-04 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9149\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.6632e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9149\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.6935e-04 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9149\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.5813e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.6323e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9149\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.5901e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5566e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9149\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5535e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9149\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5485e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.6368e-04 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9149\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.5587e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9149\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.5264e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9149\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5023e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9149\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.6089e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9149\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.5277e-04 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9149\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.5118e-04 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.9149\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5060e-04 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9149\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5075e-04 - accuracy: 1.0000 - val_loss: 0.3299 - val_accuracy: 0.9149\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 2.5097e-04 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9149\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5129e-04 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.9149\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.5049e-04 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9149\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.4610e-04 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9149\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.5092e-04 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9149\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.4333e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9149\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 2.4853e-04 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9149\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.4025e-04 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9149\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.4313e-04 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9149\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.3901e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9149\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.3750e-04 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9149\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.3656e-04 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9149\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.3763e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.3965e-04 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9149\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.4497e-04 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9149\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.3730e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9149\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 2.3465e-04 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9149\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.3034e-04 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9149\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.2955e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9149\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.4485e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9149\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.4235e-04 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9149\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.3680e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9149\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.2837e-04 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9149\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.2413e-04 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9149\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.2770e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9149\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.3132e-04 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9149\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.3490e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9149\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.3974e-04 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 0.9149\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.3026e-04 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9149\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.3580e-04 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9149\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.2212e-04 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9149\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.2299e-04 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9149\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.2437e-04 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9149\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.2711e-04 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9149\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 2.2287e-04 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9149\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 2.2214e-04 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9149\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1951e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9149\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1903e-04 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9149\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.1573e-04 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9149\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1653e-04 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9149\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1756e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.2837e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9149\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.2388e-04 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9149\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1908e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9149\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 584us/step - loss: 2.2217e-04 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9149\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.1853e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9149\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.1256e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.1375e-04 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9149\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1033e-04 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9149\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.0974e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9149\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.0969e-04 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9149\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.1081e-04 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9149\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.1357e-04 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9149\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1539e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9149\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.1512e-04 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9149\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.0885e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9149\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.0485e-04 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9149\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.1314e-04 - accuracy: 1.0000 - val_loss: 0.3427 - val_accuracy: 0.9149\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.0550e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 2.0746e-04 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9149\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.0637e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 2.0977e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 2.0874e-04 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9149\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 2.0220e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.0271e-04 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9149\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 2.0586e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9149\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.0357e-04 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9149\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9904e-04 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9149\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9988e-04 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9149\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.9740e-04 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9149\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 2.0319e-04 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9149\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9767e-04 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9149\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9842e-04 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9149\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.9513e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9149\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9457e-04 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9149\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9445e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.9466e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9149\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9446e-04 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9149\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9659e-04 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9149\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.9270e-04 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9149\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.9222e-04 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9149\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.9479e-04 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9149\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.9243e-04 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9149\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.9027e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9007e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.9252e-04 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9149\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8922e-04 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9149\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9461e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9149\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8758e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9149\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8921e-04 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.9182e-04 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9149\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.8859e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9149\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8518e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9149\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.8381e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9149\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8429e-04 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9149\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8530e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9149\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.8894e-04 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9149\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8415e-04 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9149\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.8202e-04 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9149\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8144e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9149\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8740e-04 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9149\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8216e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9149\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8160e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9149\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.8001e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9149\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.8332e-04 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9149\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8013e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.7754e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.7738e-04 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9149\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.7639e-04 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9149\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.7657e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.9149\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.7749e-04 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9149\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.7938e-04 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9149\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.8127e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9149\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.8108e-04 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9149\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.7417e-04 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9149\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.7723e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9149\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7245e-04 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9149\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.7449e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9149\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.7262e-04 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9149\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7097e-04 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9149\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.7532e-04 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9149\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.7106e-04 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9149\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.7012e-04 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9149\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6929e-04 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9149\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.6983e-04 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9149\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.6824e-04 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9149\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.7225e-04 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9149\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6840e-04 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6755e-04 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9149\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6777e-04 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9149\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6621e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9149\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.6562e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9149\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6584e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9149\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6842e-04 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9149\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6911e-04 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9149\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9149\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6331e-04 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9149\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.6476e-04 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9149\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6258e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9149\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.6517e-04 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9149\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6218e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9149\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.6205e-04 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9149\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6049e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9149\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 1.6054e-04 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9149\n",
      "Epoch 934/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 1.6025e-04 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9149\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.6141e-04 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9149\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6072e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9149\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.6111e-04 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9149\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.6296e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9149\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.5946e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9149\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.5981e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.5715e-04 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9149\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.5638e-04 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9149\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.5606e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9149\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.5656e-04 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9149\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.5606e-04 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9149\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.5667e-04 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9149\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 508us/step - loss: 1.5806e-04 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9149\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5562e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9149\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.5310e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9149\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5306e-04 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9149\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.5269e-04 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9149\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5930e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9149\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5706e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9149\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5615e-04 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9149\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5295e-04 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9149\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.4942e-04 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9149\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4750e-04 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9149\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.5036e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 564us/step - loss: 1.5234e-04 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5668e-04 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9149\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.5865e-04 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9149\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.5897e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9149\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.5006e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9149\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4681e-04 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9149\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.4520e-04 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9149\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.5300e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9149\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.5220e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9149\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4914e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9149\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.4737e-04 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9149\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4513e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9149\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.4466e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9149\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4754e-04 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9149\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.4604e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9149\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4359e-04 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9149\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4337e-04 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9149\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4304e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9149\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4418e-04 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9149\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4223e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9149\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4181e-04 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9149\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4141e-04 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9149\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4140e-04 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9149\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4247e-04 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9149\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.4467e-04 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9149\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.4157e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9149\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 1.4316e-04 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9149\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4078e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9149\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 1.3891e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9149\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3842e-04 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 526us/step - loss: 1.3891e-04 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9149\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 565us/step - loss: 1.4137e-04 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9149\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 1.3808e-04 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9149\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3765e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9149\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3664e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9149\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.3619e-04 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9149\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3589e-04 - accuracy: 1.0000 - val_loss: 0.3651 - val_accuracy: 0.9149\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3560e-04 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9149\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 1.3534e-04 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9149\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3689e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9149\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 1.3537e-04 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9149\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 1.3426e-04 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x272647cb9e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "history_Adam = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000,activation=\"relu\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dense(200,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 1000)              2000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               500000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               100000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 609,001\n",
      "Trainable params: 605,601\n",
      "Non-trainable params: 3,400\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.7781 - accuracy: 0.4528 - val_loss: 0.7403 - val_accuracy: 0.4468\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5462 - accuracy: 0.7736 - val_loss: 0.7230 - val_accuracy: 0.4468\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.4553 - accuracy: 0.7736 - val_loss: 0.7110 - val_accuracy: 0.4468\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.4085 - accuracy: 0.8491 - val_loss: 0.6980 - val_accuracy: 0.4468\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.4403 - accuracy: 0.8113 - val_loss: 0.6889 - val_accuracy: 0.4468\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3551 - accuracy: 0.8113 - val_loss: 0.6820 - val_accuracy: 0.4468\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3188 - accuracy: 0.8679 - val_loss: 0.6756 - val_accuracy: 0.4468\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3027 - accuracy: 0.8679 - val_loss: 0.6681 - val_accuracy: 0.5319\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.3273 - accuracy: 0.8491 - val_loss: 0.6615 - val_accuracy: 0.6596\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2493 - accuracy: 0.8679 - val_loss: 0.6563 - val_accuracy: 0.7234\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2988 - accuracy: 0.8868 - val_loss: 0.6510 - val_accuracy: 0.7447\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 865us/step - loss: 0.2444 - accuracy: 0.9245 - val_loss: 0.6459 - val_accuracy: 0.7872\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2796 - accuracy: 0.8868 - val_loss: 0.6417 - val_accuracy: 0.7872\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2592 - accuracy: 0.8868 - val_loss: 0.6380 - val_accuracy: 0.8085\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2938 - accuracy: 0.8679 - val_loss: 0.6334 - val_accuracy: 0.7872\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.3587 - accuracy: 0.8491 - val_loss: 0.6296 - val_accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2628 - accuracy: 0.8679 - val_loss: 0.6264 - val_accuracy: 0.7660\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3207 - accuracy: 0.8679 - val_loss: 0.6226 - val_accuracy: 0.7660\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3118 - accuracy: 0.8491 - val_loss: 0.6190 - val_accuracy: 0.7660\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2853 - accuracy: 0.8868 - val_loss: 0.6151 - val_accuracy: 0.7660\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2692 - accuracy: 0.9057 - val_loss: 0.6126 - val_accuracy: 0.7660\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2479 - accuracy: 0.9057 - val_loss: 0.6096 - val_accuracy: 0.7660\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2671 - accuracy: 0.8679 - val_loss: 0.6072 - val_accuracy: 0.7660\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 978us/step - loss: 0.2335 - accuracy: 0.9057 - val_loss: 0.6054 - val_accuracy: 0.7660\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2624 - accuracy: 0.8868 - val_loss: 0.6036 - val_accuracy: 0.7660\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3552 - accuracy: 0.8302 - val_loss: 0.6007 - val_accuracy: 0.7660\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.8868 - val_loss: 0.6000 - val_accuracy: 0.7660\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 800us/step - loss: 0.3110 - accuracy: 0.8868 - val_loss: 0.5998 - val_accuracy: 0.7660\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 850us/step - loss: 0.3308 - accuracy: 0.8491 - val_loss: 0.6009 - val_accuracy: 0.7872\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2743 - accuracy: 0.8679 - val_loss: 0.6011 - val_accuracy: 0.7872\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3702 - accuracy: 0.8491 - val_loss: 0.6008 - val_accuracy: 0.7660\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3410 - accuracy: 0.8302 - val_loss: 0.5987 - val_accuracy: 0.7872\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3718 - accuracy: 0.8113 - val_loss: 0.5954 - val_accuracy: 0.7872\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.3224 - accuracy: 0.8491 - val_loss: 0.5945 - val_accuracy: 0.7872\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.2548 - accuracy: 0.9245 - val_loss: 0.5947 - val_accuracy: 0.7660\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2978 - accuracy: 0.9057 - val_loss: 0.5933 - val_accuracy: 0.7872\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3062 - accuracy: 0.8679 - val_loss: 0.5911 - val_accuracy: 0.8085\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2614 - accuracy: 0.9057 - val_loss: 0.5879 - val_accuracy: 0.8085\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 957us/step - loss: 0.2786 - accuracy: 0.8679 - val_loss: 0.5862 - val_accuracy: 0.7660\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2788 - accuracy: 0.8868 - val_loss: 0.5857 - val_accuracy: 0.7447\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2804 - accuracy: 0.9057 - val_loss: 0.5873 - val_accuracy: 0.8085\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 841us/step - loss: 0.2763 - accuracy: 0.8868 - val_loss: 0.5906 - val_accuracy: 0.7872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2847 - accuracy: 0.8679 - val_loss: 0.5920 - val_accuracy: 0.7447\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2647 - accuracy: 0.8679 - val_loss: 0.5919 - val_accuracy: 0.7447\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3058 - accuracy: 0.9245 - val_loss: 0.5909 - val_accuracy: 0.7447\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2706 - accuracy: 0.8679 - val_loss: 0.5914 - val_accuracy: 0.7447\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2657 - accuracy: 0.8302 - val_loss: 0.5940 - val_accuracy: 0.7234\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3567 - accuracy: 0.8679 - val_loss: 0.5975 - val_accuracy: 0.7234\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3105 - accuracy: 0.9057 - val_loss: 0.5998 - val_accuracy: 0.7234\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2862 - accuracy: 0.8491 - val_loss: 0.6047 - val_accuracy: 0.6809\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2739 - accuracy: 0.8868 - val_loss: 0.6079 - val_accuracy: 0.6809\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2961 - accuracy: 0.9057 - val_loss: 0.6068 - val_accuracy: 0.6809\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2639 - accuracy: 0.8679 - val_loss: 0.6062 - val_accuracy: 0.7021\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2748 - accuracy: 0.9057 - val_loss: 0.6013 - val_accuracy: 0.7021\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2568 - accuracy: 0.9057 - val_loss: 0.5983 - val_accuracy: 0.7234\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1992 - accuracy: 0.9057 - val_loss: 0.5921 - val_accuracy: 0.7234\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2384 - accuracy: 0.9057 - val_loss: 0.5831 - val_accuracy: 0.7021\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2640 - accuracy: 0.8868 - val_loss: 0.5720 - val_accuracy: 0.7660\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3521 - accuracy: 0.8302 - val_loss: 0.5628 - val_accuracy: 0.7872\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2509 - accuracy: 0.9057 - val_loss: 0.5560 - val_accuracy: 0.7872\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3383 - accuracy: 0.8679 - val_loss: 0.5485 - val_accuracy: 0.7872\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2398 - accuracy: 0.8868 - val_loss: 0.5433 - val_accuracy: 0.8085\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2902 - accuracy: 0.8679 - val_loss: 0.5393 - val_accuracy: 0.8085\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3097 - accuracy: 0.8679 - val_loss: 0.5378 - val_accuracy: 0.7872\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2187 - accuracy: 0.8868 - val_loss: 0.5369 - val_accuracy: 0.7872\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2654 - accuracy: 0.9057 - val_loss: 0.5354 - val_accuracy: 0.7872\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2788 - accuracy: 0.8679 - val_loss: 0.5331 - val_accuracy: 0.7872\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3089 - accuracy: 0.8679 - val_loss: 0.5304 - val_accuracy: 0.8085\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2450 - accuracy: 0.9245 - val_loss: 0.5283 - val_accuracy: 0.7872\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2927 - accuracy: 0.9245 - val_loss: 0.5274 - val_accuracy: 0.7660\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8491 - val_loss: 0.5269 - val_accuracy: 0.7660\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.3350 - accuracy: 0.9057 - val_loss: 0.5269 - val_accuracy: 0.7660\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2373 - accuracy: 0.9057 - val_loss: 0.5278 - val_accuracy: 0.7872\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8679 - val_loss: 0.5280 - val_accuracy: 0.7872\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 906us/step - loss: 0.2887 - accuracy: 0.8491 - val_loss: 0.5274 - val_accuracy: 0.7872\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2672 - accuracy: 0.9057 - val_loss: 0.5271 - val_accuracy: 0.7660\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3035 - accuracy: 0.8868 - val_loss: 0.5260 - val_accuracy: 0.7872\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3173 - accuracy: 0.8302 - val_loss: 0.5250 - val_accuracy: 0.7447\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3330 - accuracy: 0.8302 - val_loss: 0.5247 - val_accuracy: 0.7447\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2579 - accuracy: 0.9057 - val_loss: 0.5238 - val_accuracy: 0.7447\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2202 - accuracy: 0.8679 - val_loss: 0.5232 - val_accuracy: 0.7447\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2477 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7234\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2522 - accuracy: 0.9057 - val_loss: 0.5229 - val_accuracy: 0.7234\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2703 - accuracy: 0.9245 - val_loss: 0.5239 - val_accuracy: 0.7447\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2171 - accuracy: 0.9057 - val_loss: 0.5231 - val_accuracy: 0.7447\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2458 - accuracy: 0.8679 - val_loss: 0.5218 - val_accuracy: 0.7447\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2770 - accuracy: 0.8679 - val_loss: 0.5214 - val_accuracy: 0.7447\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3200 - accuracy: 0.8491 - val_loss: 0.5207 - val_accuracy: 0.7447\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3066 - accuracy: 0.9245 - val_loss: 0.5193 - val_accuracy: 0.7447\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2732 - accuracy: 0.8491 - val_loss: 0.5172 - val_accuracy: 0.7447\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.3310 - accuracy: 0.8679 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 978us/step - loss: 0.2480 - accuracy: 0.9057 - val_loss: 0.5138 - val_accuracy: 0.7872\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8868 - val_loss: 0.5143 - val_accuracy: 0.7872\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2290 - accuracy: 0.8868 - val_loss: 0.5154 - val_accuracy: 0.7872\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.3509 - accuracy: 0.8491 - val_loss: 0.5148 - val_accuracy: 0.8085\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 854us/step - loss: 0.2628 - accuracy: 0.8868 - val_loss: 0.5137 - val_accuracy: 0.8085\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8868 - val_loss: 0.5086 - val_accuracy: 0.8085\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 994us/step - loss: 0.2565 - accuracy: 0.8679 - val_loss: 0.5042 - val_accuracy: 0.8085\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 753us/step - loss: 0.2486 - accuracy: 0.9057 - val_loss: 0.5005 - val_accuracy: 0.8085\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 857us/step - loss: 0.3511 - accuracy: 0.8491 - val_loss: 0.4978 - val_accuracy: 0.7872\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3018 - accuracy: 0.8868 - val_loss: 0.4959 - val_accuracy: 0.7872\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2403 - accuracy: 0.9057 - val_loss: 0.4947 - val_accuracy: 0.7872\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 841us/step - loss: 0.2250 - accuracy: 0.9057 - val_loss: 0.4954 - val_accuracy: 0.7872\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.4115 - accuracy: 0.8491 - val_loss: 0.4966 - val_accuracy: 0.7660\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 845us/step - loss: 0.3407 - accuracy: 0.8679 - val_loss: 0.4973 - val_accuracy: 0.7447\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2612 - accuracy: 0.8491 - val_loss: 0.4995 - val_accuracy: 0.7447\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.3361 - accuracy: 0.8302 - val_loss: 0.5005 - val_accuracy: 0.7660\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3048 - accuracy: 0.8868 - val_loss: 0.5042 - val_accuracy: 0.7447\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.1814 - accuracy: 0.9245 - val_loss: 0.5082 - val_accuracy: 0.7447\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 816us/step - loss: 0.3217 - accuracy: 0.8491 - val_loss: 0.5119 - val_accuracy: 0.7447\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2660 - accuracy: 0.8679 - val_loss: 0.5138 - val_accuracy: 0.7660\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2667 - accuracy: 0.8868 - val_loss: 0.5181 - val_accuracy: 0.7447\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 803us/step - loss: 0.2604 - accuracy: 0.9057 - val_loss: 0.5243 - val_accuracy: 0.7447\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 865us/step - loss: 0.2415 - accuracy: 0.9057 - val_loss: 0.5280 - val_accuracy: 0.7447\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2438 - accuracy: 0.9057 - val_loss: 0.5327 - val_accuracy: 0.7447\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2530 - accuracy: 0.8868 - val_loss: 0.5354 - val_accuracy: 0.7447\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 914us/step - loss: 0.3278 - accuracy: 0.8868 - val_loss: 0.5318 - val_accuracy: 0.7447\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2535 - accuracy: 0.9057 - val_loss: 0.5302 - val_accuracy: 0.7447\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3710 - accuracy: 0.8679 - val_loss: 0.5287 - val_accuracy: 0.7447\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3433 - accuracy: 0.8679 - val_loss: 0.5301 - val_accuracy: 0.7447\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3518 - accuracy: 0.8491 - val_loss: 0.5354 - val_accuracy: 0.7447\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3426 - accuracy: 0.8868 - val_loss: 0.5451 - val_accuracy: 0.7660\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3079 - accuracy: 0.8868 - val_loss: 0.5541 - val_accuracy: 0.7447\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3063 - accuracy: 0.8868 - val_loss: 0.5640 - val_accuracy: 0.7234\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3412 - accuracy: 0.8679 - val_loss: 0.5738 - val_accuracy: 0.7234\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2131 - accuracy: 0.8868 - val_loss: 0.5809 - val_accuracy: 0.7234\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3077 - accuracy: 0.8868 - val_loss: 0.5891 - val_accuracy: 0.7021\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2853 - accuracy: 0.9245 - val_loss: 0.5943 - val_accuracy: 0.7021\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2761 - accuracy: 0.8679 - val_loss: 0.5987 - val_accuracy: 0.7021\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3764 - accuracy: 0.8113 - val_loss: 0.5984 - val_accuracy: 0.6809\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2383 - accuracy: 0.8868 - val_loss: 0.5913 - val_accuracy: 0.7021\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2387 - accuracy: 0.8868 - val_loss: 0.5851 - val_accuracy: 0.7234\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3296 - accuracy: 0.8491 - val_loss: 0.5808 - val_accuracy: 0.7447\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2383 - accuracy: 0.9245 - val_loss: 0.5798 - val_accuracy: 0.7447\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2896 - accuracy: 0.9057 - val_loss: 0.5722 - val_accuracy: 0.7660\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3377 - accuracy: 0.8491 - val_loss: 0.5680 - val_accuracy: 0.7660\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2824 - accuracy: 0.8679 - val_loss: 0.5619 - val_accuracy: 0.7660\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3450 - accuracy: 0.8868 - val_loss: 0.5590 - val_accuracy: 0.7660\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3081 - accuracy: 0.9057 - val_loss: 0.5631 - val_accuracy: 0.7660\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2212 - accuracy: 0.8679 - val_loss: 0.5659 - val_accuracy: 0.7660\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3166 - accuracy: 0.8679 - val_loss: 0.5640 - val_accuracy: 0.7660\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.3168 - accuracy: 0.8491 - val_loss: 0.5601 - val_accuracy: 0.7660\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2757 - accuracy: 0.9057 - val_loss: 0.5573 - val_accuracy: 0.7660\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.3187 - accuracy: 0.8491 - val_loss: 0.5536 - val_accuracy: 0.7660\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 959us/step - loss: 0.3361 - accuracy: 0.8679 - val_loss: 0.5501 - val_accuracy: 0.7660\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.3427 - accuracy: 0.8868 - val_loss: 0.5464 - val_accuracy: 0.7660\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2860 - accuracy: 0.9057 - val_loss: 0.5424 - val_accuracy: 0.7447\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.3545 - accuracy: 0.8113 - val_loss: 0.5320 - val_accuracy: 0.7447\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2344 - accuracy: 0.9245 - val_loss: 0.5250 - val_accuracy: 0.7447\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 940us/step - loss: 0.3414 - accuracy: 0.8491 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2147 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.7447\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2590 - accuracy: 0.8868 - val_loss: 0.5090 - val_accuracy: 0.7447\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2861 - accuracy: 0.8679 - val_loss: 0.5029 - val_accuracy: 0.7447\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2025 - accuracy: 0.9245 - val_loss: 0.4976 - val_accuracy: 0.7447\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 790us/step - loss: 0.3292 - accuracy: 0.8679 - val_loss: 0.4918 - val_accuracy: 0.7447\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3083 - accuracy: 0.8679 - val_loss: 0.4898 - val_accuracy: 0.7447\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 752us/step - loss: 0.2770 - accuracy: 0.9245 - val_loss: 0.4872 - val_accuracy: 0.7447\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2866 - accuracy: 0.9057 - val_loss: 0.4864 - val_accuracy: 0.7447\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2762 - accuracy: 0.9057 - val_loss: 0.4877 - val_accuracy: 0.7447\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2872 - accuracy: 0.8679 - val_loss: 0.4884 - val_accuracy: 0.7447\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2523 - accuracy: 0.8868 - val_loss: 0.4914 - val_accuracy: 0.7447\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8679 - val_loss: 0.4955 - val_accuracy: 0.7447\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.8679 - val_loss: 0.4958 - val_accuracy: 0.7447\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3001 - accuracy: 0.8491 - val_loss: 0.4971 - val_accuracy: 0.7447\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2983 - accuracy: 0.9057 - val_loss: 0.4980 - val_accuracy: 0.7447\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8868 - val_loss: 0.4981 - val_accuracy: 0.7447\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.3074 - accuracy: 0.8679 - val_loss: 0.4977 - val_accuracy: 0.7447\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2346 - accuracy: 0.8868 - val_loss: 0.4951 - val_accuracy: 0.7447\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.8679 - val_loss: 0.4937 - val_accuracy: 0.7447\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2821 - accuracy: 0.8491 - val_loss: 0.4932 - val_accuracy: 0.7660\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2765 - accuracy: 0.8868 - val_loss: 0.4935 - val_accuracy: 0.7660\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2860 - accuracy: 0.8679 - val_loss: 0.4966 - val_accuracy: 0.7660\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 755us/step - loss: 0.3138 - accuracy: 0.8113 - val_loss: 0.4978 - val_accuracy: 0.7660\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2193 - accuracy: 0.9057 - val_loss: 0.4990 - val_accuracy: 0.7660\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2573 - accuracy: 0.8491 - val_loss: 0.4966 - val_accuracy: 0.7660\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2418 - accuracy: 0.9057 - val_loss: 0.4968 - val_accuracy: 0.7447\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3527 - accuracy: 0.8679 - val_loss: 0.4955 - val_accuracy: 0.7447\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2893 - accuracy: 0.9057 - val_loss: 0.4957 - val_accuracy: 0.7447\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 831us/step - loss: 0.3202 - accuracy: 0.8302 - val_loss: 0.4984 - val_accuracy: 0.7447\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2918 - accuracy: 0.9057 - val_loss: 0.5014 - val_accuracy: 0.7660\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2332 - accuracy: 0.9245 - val_loss: 0.5021 - val_accuracy: 0.7660\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3070 - accuracy: 0.9057 - val_loss: 0.5055 - val_accuracy: 0.7660\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2508 - accuracy: 0.8491 - val_loss: 0.5097 - val_accuracy: 0.7660\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3793 - accuracy: 0.8679 - val_loss: 0.5138 - val_accuracy: 0.7660\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2414 - accuracy: 0.9057 - val_loss: 0.5117 - val_accuracy: 0.7660\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3537 - accuracy: 0.8868 - val_loss: 0.5089 - val_accuracy: 0.7660\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2372 - accuracy: 0.8868 - val_loss: 0.5049 - val_accuracy: 0.7660\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2941 - accuracy: 0.8868 - val_loss: 0.5006 - val_accuracy: 0.7660\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3192 - accuracy: 0.8868 - val_loss: 0.4974 - val_accuracy: 0.7660\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2352 - accuracy: 0.8679 - val_loss: 0.4913 - val_accuracy: 0.7660\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2697 - accuracy: 0.8679 - val_loss: 0.4834 - val_accuracy: 0.7660\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2367 - accuracy: 0.8868 - val_loss: 0.4793 - val_accuracy: 0.7660\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2682 - accuracy: 0.9057 - val_loss: 0.4817 - val_accuracy: 0.7447\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3445 - accuracy: 0.8868 - val_loss: 0.4824 - val_accuracy: 0.7447\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2572 - accuracy: 0.8868 - val_loss: 0.4828 - val_accuracy: 0.7447\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3474 - accuracy: 0.8302 - val_loss: 0.4792 - val_accuracy: 0.7447\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3289 - accuracy: 0.8302 - val_loss: 0.4781 - val_accuracy: 0.7447\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3083 - accuracy: 0.8868 - val_loss: 0.4743 - val_accuracy: 0.7447\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2498 - accuracy: 0.9057 - val_loss: 0.4737 - val_accuracy: 0.7447\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2747 - accuracy: 0.8679 - val_loss: 0.4720 - val_accuracy: 0.7447\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2436 - accuracy: 0.9245 - val_loss: 0.4707 - val_accuracy: 0.7447\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2687 - accuracy: 0.9057 - val_loss: 0.4687 - val_accuracy: 0.7447\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3541 - accuracy: 0.8302 - val_loss: 0.4667 - val_accuracy: 0.7447\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2713 - accuracy: 0.8679 - val_loss: 0.4662 - val_accuracy: 0.7447\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2514 - accuracy: 0.9057 - val_loss: 0.4664 - val_accuracy: 0.7447\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2486 - accuracy: 0.9057 - val_loss: 0.4680 - val_accuracy: 0.7447\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3345 - accuracy: 0.8868 - val_loss: 0.4646 - val_accuracy: 0.7447\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2993 - accuracy: 0.8679 - val_loss: 0.4664 - val_accuracy: 0.7660\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2639 - accuracy: 0.8868 - val_loss: 0.4666 - val_accuracy: 0.7447\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2619 - accuracy: 0.8679 - val_loss: 0.4671 - val_accuracy: 0.7447\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 866us/step - loss: 0.2999 - accuracy: 0.8679 - val_loss: 0.4676 - val_accuracy: 0.7447\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2523 - accuracy: 0.8868 - val_loss: 0.4689 - val_accuracy: 0.7447\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.3107 - accuracy: 0.9057 - val_loss: 0.4706 - val_accuracy: 0.7447\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2578 - accuracy: 0.8679 - val_loss: 0.4699 - val_accuracy: 0.7660\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2933 - accuracy: 0.9057 - val_loss: 0.4701 - val_accuracy: 0.7660\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2750 - accuracy: 0.8868 - val_loss: 0.4674 - val_accuracy: 0.7660\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3747 - accuracy: 0.7736 - val_loss: 0.4635 - val_accuracy: 0.7660\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2565 - accuracy: 0.9057 - val_loss: 0.4626 - val_accuracy: 0.7660\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2228 - accuracy: 0.9245 - val_loss: 0.4627 - val_accuracy: 0.7660\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2110 - accuracy: 0.9057 - val_loss: 0.4631 - val_accuracy: 0.7660\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2331 - accuracy: 0.9057 - val_loss: 0.4628 - val_accuracy: 0.7660\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.8868 - val_loss: 0.4607 - val_accuracy: 0.7660\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2446 - accuracy: 0.8868 - val_loss: 0.4596 - val_accuracy: 0.7660\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3185 - accuracy: 0.8868 - val_loss: 0.4573 - val_accuracy: 0.7660\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2073 - accuracy: 0.9245 - val_loss: 0.4548 - val_accuracy: 0.7660\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3777 - accuracy: 0.7925 - val_loss: 0.4551 - val_accuracy: 0.7660\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3372 - accuracy: 0.7925 - val_loss: 0.4532 - val_accuracy: 0.7660\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3118 - accuracy: 0.8868 - val_loss: 0.4516 - val_accuracy: 0.7660\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3451 - accuracy: 0.8679 - val_loss: 0.4505 - val_accuracy: 0.7660\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2408 - accuracy: 0.8679 - val_loss: 0.4476 - val_accuracy: 0.7660\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.2975 - accuracy: 0.9057 - val_loss: 0.4433 - val_accuracy: 0.7660\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 857us/step - loss: 0.2647 - accuracy: 0.9245 - val_loss: 0.4408 - val_accuracy: 0.7660\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3403 - accuracy: 0.8113 - val_loss: 0.4376 - val_accuracy: 0.7660\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2483 - accuracy: 0.9057 - val_loss: 0.4366 - val_accuracy: 0.7660\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2914 - accuracy: 0.9057 - val_loss: 0.4361 - val_accuracy: 0.7660\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2629 - accuracy: 0.8868 - val_loss: 0.4377 - val_accuracy: 0.7660\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2135 - accuracy: 0.8868 - val_loss: 0.4395 - val_accuracy: 0.7660\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2715 - accuracy: 0.8868 - val_loss: 0.4391 - val_accuracy: 0.7660\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2309 - accuracy: 0.9434 - val_loss: 0.4388 - val_accuracy: 0.7660\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2597 - accuracy: 0.9057 - val_loss: 0.4386 - val_accuracy: 0.7660\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3340 - accuracy: 0.8302 - val_loss: 0.4399 - val_accuracy: 0.7660\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2834 - accuracy: 0.8491 - val_loss: 0.4401 - val_accuracy: 0.7660\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.1994 - accuracy: 0.9245 - val_loss: 0.4388 - val_accuracy: 0.7660\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2671 - accuracy: 0.8868 - val_loss: 0.4375 - val_accuracy: 0.8085\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3197 - accuracy: 0.9057 - val_loss: 0.4377 - val_accuracy: 0.8085\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3111 - accuracy: 0.8868 - val_loss: 0.4353 - val_accuracy: 0.8085\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 931us/step - loss: 0.2976 - accuracy: 0.9245 - val_loss: 0.4305 - val_accuracy: 0.7872\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3426 - accuracy: 0.8679 - val_loss: 0.4301 - val_accuracy: 0.7660\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2822 - accuracy: 0.8679 - val_loss: 0.4292 - val_accuracy: 0.7660\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2555 - accuracy: 0.8679 - val_loss: 0.4290 - val_accuracy: 0.7872\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2822 - accuracy: 0.9057 - val_loss: 0.4306 - val_accuracy: 0.8085\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 0.9434 - val_loss: 0.4351 - val_accuracy: 0.7872\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.3105 - accuracy: 0.8679 - val_loss: 0.4389 - val_accuracy: 0.7660\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2015 - accuracy: 0.9057 - val_loss: 0.4440 - val_accuracy: 0.7660\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2812 - accuracy: 0.8868 - val_loss: 0.4495 - val_accuracy: 0.7660\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8868 - val_loss: 0.4551 - val_accuracy: 0.7660\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3518 - accuracy: 0.8491 - val_loss: 0.4600 - val_accuracy: 0.7660\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.3042 - accuracy: 0.8491 - val_loss: 0.4644 - val_accuracy: 0.7660\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2997 - accuracy: 0.8679 - val_loss: 0.4649 - val_accuracy: 0.7660\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2993 - accuracy: 0.8679 - val_loss: 0.4663 - val_accuracy: 0.7660\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 940us/step - loss: 0.2749 - accuracy: 0.9057 - val_loss: 0.4701 - val_accuracy: 0.7872\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2360 - accuracy: 0.9245 - val_loss: 0.4768 - val_accuracy: 0.7872\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2905 - accuracy: 0.8868 - val_loss: 0.4832 - val_accuracy: 0.7872\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3567 - accuracy: 0.8113 - val_loss: 0.4899 - val_accuracy: 0.7660\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3849 - accuracy: 0.8302 - val_loss: 0.4888 - val_accuracy: 0.7660\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2734 - accuracy: 0.8679 - val_loss: 0.4901 - val_accuracy: 0.7660\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 753us/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.4891 - val_accuracy: 0.7660\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2472 - accuracy: 0.8679 - val_loss: 0.4897 - val_accuracy: 0.7660\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3414 - accuracy: 0.8491 - val_loss: 0.4884 - val_accuracy: 0.7660\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2608 - accuracy: 0.9245 - val_loss: 0.4891 - val_accuracy: 0.7660\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2443 - accuracy: 0.8868 - val_loss: 0.4900 - val_accuracy: 0.7660\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3005 - accuracy: 0.8679 - val_loss: 0.4865 - val_accuracy: 0.7660\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 876us/step - loss: 0.2445 - accuracy: 0.8868 - val_loss: 0.4803 - val_accuracy: 0.7872\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2566 - accuracy: 0.9057 - val_loss: 0.4750 - val_accuracy: 0.7872\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2649 - accuracy: 0.8868 - val_loss: 0.4711 - val_accuracy: 0.7872\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2770 - accuracy: 0.8868 - val_loss: 0.4684 - val_accuracy: 0.7872\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2891 - accuracy: 0.8679 - val_loss: 0.4658 - val_accuracy: 0.7872\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2537 - accuracy: 0.8868 - val_loss: 0.4651 - val_accuracy: 0.7872\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2511 - accuracy: 0.9057 - val_loss: 0.4634 - val_accuracy: 0.7872\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2464 - accuracy: 0.9245 - val_loss: 0.4642 - val_accuracy: 0.7872\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3045 - accuracy: 0.8868 - val_loss: 0.4661 - val_accuracy: 0.7872\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2224 - accuracy: 0.9057 - val_loss: 0.4664 - val_accuracy: 0.7872\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2366 - accuracy: 0.9057 - val_loss: 0.4640 - val_accuracy: 0.7872\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 893us/step - loss: 0.3286 - accuracy: 0.8679 - val_loss: 0.4646 - val_accuracy: 0.7872\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2680 - accuracy: 0.9057 - val_loss: 0.4659 - val_accuracy: 0.7872\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2747 - accuracy: 0.8868 - val_loss: 0.4647 - val_accuracy: 0.8085\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2490 - accuracy: 0.8302 - val_loss: 0.4650 - val_accuracy: 0.8085\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 865us/step - loss: 0.2130 - accuracy: 0.9245 - val_loss: 0.4643 - val_accuracy: 0.8085\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.3968 - accuracy: 0.8302 - val_loss: 0.4638 - val_accuracy: 0.8085\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2926 - accuracy: 0.8302 - val_loss: 0.4651 - val_accuracy: 0.8085\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.2942 - accuracy: 0.8679 - val_loss: 0.4656 - val_accuracy: 0.8085\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2234 - accuracy: 0.9245 - val_loss: 0.4651 - val_accuracy: 0.8085\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3281 - accuracy: 0.8679 - val_loss: 0.4663 - val_accuracy: 0.8085\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2984 - accuracy: 0.9057 - val_loss: 0.4660 - val_accuracy: 0.8085\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2826 - accuracy: 0.8679 - val_loss: 0.4640 - val_accuracy: 0.8085\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2505 - accuracy: 0.9057 - val_loss: 0.4638 - val_accuracy: 0.8085\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2957 - accuracy: 0.9057 - val_loss: 0.4644 - val_accuracy: 0.8085\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2709 - accuracy: 0.8679 - val_loss: 0.4649 - val_accuracy: 0.8085\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3064 - accuracy: 0.9057 - val_loss: 0.4661 - val_accuracy: 0.8085\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2498 - accuracy: 0.9057 - val_loss: 0.4672 - val_accuracy: 0.8085\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2850 - accuracy: 0.8491 - val_loss: 0.4667 - val_accuracy: 0.8085\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.2349 - accuracy: 0.9245 - val_loss: 0.4645 - val_accuracy: 0.8085\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2089 - accuracy: 0.9057 - val_loss: 0.4599 - val_accuracy: 0.8085\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2460 - accuracy: 0.8868 - val_loss: 0.4557 - val_accuracy: 0.8085\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2794 - accuracy: 0.9057 - val_loss: 0.4520 - val_accuracy: 0.8085\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2415 - accuracy: 0.9057 - val_loss: 0.4491 - val_accuracy: 0.8085\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2296 - accuracy: 0.8679 - val_loss: 0.4472 - val_accuracy: 0.8085\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2555 - accuracy: 0.9245 - val_loss: 0.4455 - val_accuracy: 0.8085\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2784 - accuracy: 0.8491 - val_loss: 0.4425 - val_accuracy: 0.8085\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2491 - accuracy: 0.8491 - val_loss: 0.4420 - val_accuracy: 0.8085\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2400 - accuracy: 0.8868 - val_loss: 0.4412 - val_accuracy: 0.8085\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2635 - accuracy: 0.9057 - val_loss: 0.4385 - val_accuracy: 0.8085\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.3199 - accuracy: 0.8679 - val_loss: 0.4385 - val_accuracy: 0.8298\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2288 - accuracy: 0.9057 - val_loss: 0.4349 - val_accuracy: 0.8298\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2031 - accuracy: 0.9245 - val_loss: 0.4324 - val_accuracy: 0.8298\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2791 - accuracy: 0.9057 - val_loss: 0.4323 - val_accuracy: 0.8298\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2524 - accuracy: 0.9057 - val_loss: 0.4323 - val_accuracy: 0.8085\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2855 - accuracy: 0.8679 - val_loss: 0.4340 - val_accuracy: 0.8298\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2393 - accuracy: 0.8868 - val_loss: 0.4367 - val_accuracy: 0.8298\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2500 - accuracy: 0.9057 - val_loss: 0.4379 - val_accuracy: 0.8085\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3063 - accuracy: 0.8679 - val_loss: 0.4401 - val_accuracy: 0.8085\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2987 - accuracy: 0.8679 - val_loss: 0.4413 - val_accuracy: 0.8085\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 847us/step - loss: 0.3041 - accuracy: 0.8868 - val_loss: 0.4437 - val_accuracy: 0.8085\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2765 - accuracy: 0.8868 - val_loss: 0.4472 - val_accuracy: 0.8085\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3110 - accuracy: 0.8868 - val_loss: 0.4496 - val_accuracy: 0.8085\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3031 - accuracy: 0.9057 - val_loss: 0.4484 - val_accuracy: 0.8085\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2831 - accuracy: 0.8679 - val_loss: 0.4490 - val_accuracy: 0.8085\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2225 - accuracy: 0.9057 - val_loss: 0.4504 - val_accuracy: 0.8085\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2484 - accuracy: 0.9057 - val_loss: 0.4496 - val_accuracy: 0.8085\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2891 - accuracy: 0.8868 - val_loss: 0.4490 - val_accuracy: 0.8085\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3039 - accuracy: 0.8868 - val_loss: 0.4501 - val_accuracy: 0.8085\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2742 - accuracy: 0.8868 - val_loss: 0.4507 - val_accuracy: 0.8085\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3133 - accuracy: 0.8679 - val_loss: 0.4501 - val_accuracy: 0.8085\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2653 - accuracy: 0.8679 - val_loss: 0.4474 - val_accuracy: 0.8085\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2758 - accuracy: 0.9057 - val_loss: 0.4457 - val_accuracy: 0.8085\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2223 - accuracy: 0.9057 - val_loss: 0.4428 - val_accuracy: 0.8085\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2926 - accuracy: 0.8868 - val_loss: 0.4395 - val_accuracy: 0.8085\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3563 - accuracy: 0.8491 - val_loss: 0.4378 - val_accuracy: 0.8298\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2361 - accuracy: 0.9057 - val_loss: 0.4396 - val_accuracy: 0.8085\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3366 - accuracy: 0.8679 - val_loss: 0.4409 - val_accuracy: 0.8085\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2439 - accuracy: 0.9057 - val_loss: 0.4417 - val_accuracy: 0.8085\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2631 - accuracy: 0.8679 - val_loss: 0.4460 - val_accuracy: 0.8085\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2467 - accuracy: 0.8868 - val_loss: 0.4529 - val_accuracy: 0.8085\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2692 - accuracy: 0.8491 - val_loss: 0.4583 - val_accuracy: 0.8085\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2350 - accuracy: 0.9245 - val_loss: 0.4639 - val_accuracy: 0.8085\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2677 - accuracy: 0.9057 - val_loss: 0.4718 - val_accuracy: 0.7872\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2402 - accuracy: 0.8868 - val_loss: 0.4818 - val_accuracy: 0.7872\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2947 - accuracy: 0.8679 - val_loss: 0.4866 - val_accuracy: 0.7872\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2653 - accuracy: 0.9057 - val_loss: 0.4877 - val_accuracy: 0.7872\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2890 - accuracy: 0.8491 - val_loss: 0.4870 - val_accuracy: 0.7872\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3208 - accuracy: 0.8302 - val_loss: 0.4838 - val_accuracy: 0.7872\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2775 - accuracy: 0.8679 - val_loss: 0.4790 - val_accuracy: 0.7872\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2758 - accuracy: 0.8491 - val_loss: 0.4720 - val_accuracy: 0.8085\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2727 - accuracy: 0.8679 - val_loss: 0.4655 - val_accuracy: 0.8085\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2797 - accuracy: 0.9057 - val_loss: 0.4565 - val_accuracy: 0.8085\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2689 - accuracy: 0.9245 - val_loss: 0.4545 - val_accuracy: 0.8085\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1896 - accuracy: 0.9057 - val_loss: 0.4559 - val_accuracy: 0.8085\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2202 - accuracy: 0.9434 - val_loss: 0.4623 - val_accuracy: 0.8085\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3097 - accuracy: 0.8868 - val_loss: 0.4703 - val_accuracy: 0.8085\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2900 - accuracy: 0.8679 - val_loss: 0.4775 - val_accuracy: 0.8085\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2544 - accuracy: 0.8868 - val_loss: 0.4770 - val_accuracy: 0.8085\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2301 - accuracy: 0.9245 - val_loss: 0.4738 - val_accuracy: 0.8085\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2590 - accuracy: 0.8679 - val_loss: 0.4688 - val_accuracy: 0.8085\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2149 - accuracy: 0.9057 - val_loss: 0.4687 - val_accuracy: 0.8085\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2344 - accuracy: 0.9057 - val_loss: 0.4690 - val_accuracy: 0.8085\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3461 - accuracy: 0.8679 - val_loss: 0.4679 - val_accuracy: 0.8085\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2576 - accuracy: 0.9057 - val_loss: 0.4668 - val_accuracy: 0.8085\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3010 - accuracy: 0.8491 - val_loss: 0.4651 - val_accuracy: 0.8085\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2796 - accuracy: 0.8868 - val_loss: 0.4615 - val_accuracy: 0.8085\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3520 - accuracy: 0.8491 - val_loss: 0.4571 - val_accuracy: 0.8085\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2696 - accuracy: 0.8868 - val_loss: 0.4548 - val_accuracy: 0.8085\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2705 - accuracy: 0.8679 - val_loss: 0.4525 - val_accuracy: 0.8085\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2810 - accuracy: 0.9057 - val_loss: 0.4535 - val_accuracy: 0.8085\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3045 - accuracy: 0.8868 - val_loss: 0.4494 - val_accuracy: 0.8085\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2258 - accuracy: 0.9245 - val_loss: 0.4473 - val_accuracy: 0.8085\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.2143 - accuracy: 0.9057 - val_loss: 0.4466 - val_accuracy: 0.8085\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2052 - accuracy: 0.9245 - val_loss: 0.4453 - val_accuracy: 0.8085\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2324 - accuracy: 0.9057 - val_loss: 0.4445 - val_accuracy: 0.8085\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 828us/step - loss: 0.2971 - accuracy: 0.8868 - val_loss: 0.4419 - val_accuracy: 0.8085\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3115 - accuracy: 0.8679 - val_loss: 0.4402 - val_accuracy: 0.8085\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2124 - accuracy: 0.9434 - val_loss: 0.4354 - val_accuracy: 0.8298\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 890us/step - loss: 0.2339 - accuracy: 0.9057 - val_loss: 0.4321 - val_accuracy: 0.8298\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 854us/step - loss: 0.2327 - accuracy: 0.9245 - val_loss: 0.4285 - val_accuracy: 0.8298\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3082 - accuracy: 0.9245 - val_loss: 0.4284 - val_accuracy: 0.8298\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2711 - accuracy: 0.8679 - val_loss: 0.4290 - val_accuracy: 0.8298\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 800us/step - loss: 0.2083 - accuracy: 0.9245 - val_loss: 0.4286 - val_accuracy: 0.8298\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 864us/step - loss: 0.2653 - accuracy: 0.9057 - val_loss: 0.4282 - val_accuracy: 0.8298\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3180 - accuracy: 0.8491 - val_loss: 0.4294 - val_accuracy: 0.8298\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 852us/step - loss: 0.2561 - accuracy: 0.8868 - val_loss: 0.4331 - val_accuracy: 0.8085\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2528 - accuracy: 0.8868 - val_loss: 0.4380 - val_accuracy: 0.8085\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2538 - accuracy: 0.9057 - val_loss: 0.4404 - val_accuracy: 0.8085\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2884 - accuracy: 0.8868 - val_loss: 0.4428 - val_accuracy: 0.8085\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2304 - accuracy: 0.8868 - val_loss: 0.4444 - val_accuracy: 0.8085\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3030 - accuracy: 0.9057 - val_loss: 0.4457 - val_accuracy: 0.8085\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2867 - accuracy: 0.8868 - val_loss: 0.4446 - val_accuracy: 0.8085\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2914 - accuracy: 0.8491 - val_loss: 0.4462 - val_accuracy: 0.8085\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2630 - accuracy: 0.8868 - val_loss: 0.4473 - val_accuracy: 0.8085\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2896 - accuracy: 0.8868 - val_loss: 0.4491 - val_accuracy: 0.8298\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2242 - accuracy: 0.8679 - val_loss: 0.4447 - val_accuracy: 0.8085\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2390 - accuracy: 0.9057 - val_loss: 0.4332 - val_accuracy: 0.7872\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3083 - accuracy: 0.8679 - val_loss: 0.4245 - val_accuracy: 0.7872\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2931 - accuracy: 0.8868 - val_loss: 0.4146 - val_accuracy: 0.8085\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2551 - accuracy: 0.8868 - val_loss: 0.4072 - val_accuracy: 0.8085\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2297 - accuracy: 0.9057 - val_loss: 0.4001 - val_accuracy: 0.8298\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3264 - accuracy: 0.8679 - val_loss: 0.3980 - val_accuracy: 0.8298\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2934 - accuracy: 0.9245 - val_loss: 0.3993 - val_accuracy: 0.8298\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2281 - accuracy: 0.9245 - val_loss: 0.4017 - val_accuracy: 0.8298\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2257 - accuracy: 0.9245 - val_loss: 0.4023 - val_accuracy: 0.8298\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3072 - accuracy: 0.8491 - val_loss: 0.4023 - val_accuracy: 0.8298\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2232 - accuracy: 0.9245 - val_loss: 0.4017 - val_accuracy: 0.8298\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2214 - accuracy: 0.9245 - val_loss: 0.3994 - val_accuracy: 0.8298\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2642 - accuracy: 0.9057 - val_loss: 0.3958 - val_accuracy: 0.8298\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2939 - accuracy: 0.8302 - val_loss: 0.3947 - val_accuracy: 0.8085\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2350 - accuracy: 0.9057 - val_loss: 0.3922 - val_accuracy: 0.8085\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2065 - accuracy: 0.8868 - val_loss: 0.3888 - val_accuracy: 0.8085\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3138 - accuracy: 0.8491 - val_loss: 0.3885 - val_accuracy: 0.8085\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2364 - accuracy: 0.9057 - val_loss: 0.3876 - val_accuracy: 0.8085\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2310 - accuracy: 0.8868 - val_loss: 0.3892 - val_accuracy: 0.8085\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2219 - accuracy: 0.9057 - val_loss: 0.3930 - val_accuracy: 0.8085\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2672 - accuracy: 0.9245 - val_loss: 0.3956 - val_accuracy: 0.8085\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2322 - accuracy: 0.9057 - val_loss: 0.3985 - val_accuracy: 0.8085\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3144 - accuracy: 0.8491 - val_loss: 0.4038 - val_accuracy: 0.8085\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2232 - accuracy: 0.8868 - val_loss: 0.4047 - val_accuracy: 0.8085\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2101 - accuracy: 0.9245 - val_loss: 0.4027 - val_accuracy: 0.8085\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2315 - accuracy: 0.8868 - val_loss: 0.4027 - val_accuracy: 0.8085\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 793us/step - loss: 0.2697 - accuracy: 0.8679 - val_loss: 0.4055 - val_accuracy: 0.8085\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2322 - accuracy: 0.9057 - val_loss: 0.4066 - val_accuracy: 0.8085\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2715 - accuracy: 0.9057 - val_loss: 0.4081 - val_accuracy: 0.8085\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2532 - accuracy: 0.8491 - val_loss: 0.4085 - val_accuracy: 0.8085\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2430 - accuracy: 0.8868 - val_loss: 0.4079 - val_accuracy: 0.8298\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2484 - accuracy: 0.8868 - val_loss: 0.4058 - val_accuracy: 0.8298\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2594 - accuracy: 0.9245 - val_loss: 0.4044 - val_accuracy: 0.8298\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3040 - accuracy: 0.9057 - val_loss: 0.4052 - val_accuracy: 0.8298\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 997us/step - loss: 0.2795 - accuracy: 0.9057 - val_loss: 0.4046 - val_accuracy: 0.8298\n",
      "Epoch 435/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 895us/step - loss: 0.2428 - accuracy: 0.8868 - val_loss: 0.4047 - val_accuracy: 0.8298\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 885us/step - loss: 0.2662 - accuracy: 0.8491 - val_loss: 0.4069 - val_accuracy: 0.8298\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8302 - val_loss: 0.4116 - val_accuracy: 0.8298\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2890 - accuracy: 0.8679 - val_loss: 0.4168 - val_accuracy: 0.8085\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1949 - accuracy: 0.9057 - val_loss: 0.4212 - val_accuracy: 0.8085\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2486 - accuracy: 0.9057 - val_loss: 0.4262 - val_accuracy: 0.8085\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2665 - accuracy: 0.8868 - val_loss: 0.4329 - val_accuracy: 0.8085\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2853 - accuracy: 0.8868 - val_loss: 0.4412 - val_accuracy: 0.8085\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3306 - accuracy: 0.8679 - val_loss: 0.4534 - val_accuracy: 0.8085\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2902 - accuracy: 0.8868 - val_loss: 0.4655 - val_accuracy: 0.8085\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 744us/step - loss: 0.2078 - accuracy: 0.9434 - val_loss: 0.4653 - val_accuracy: 0.7872\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2983 - accuracy: 0.8868 - val_loss: 0.4621 - val_accuracy: 0.8085\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2526 - accuracy: 0.8868 - val_loss: 0.4588 - val_accuracy: 0.8085\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2769 - accuracy: 0.9057 - val_loss: 0.4579 - val_accuracy: 0.8085\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3902 - accuracy: 0.8302 - val_loss: 0.4537 - val_accuracy: 0.8085\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 699us/step - loss: 0.2839 - accuracy: 0.9057 - val_loss: 0.4445 - val_accuracy: 0.8085\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2454 - accuracy: 0.9057 - val_loss: 0.4354 - val_accuracy: 0.8085\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2110 - accuracy: 0.9245 - val_loss: 0.4279 - val_accuracy: 0.8085\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1887 - accuracy: 0.9434 - val_loss: 0.4210 - val_accuracy: 0.8085\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3074 - accuracy: 0.8302 - val_loss: 0.4175 - val_accuracy: 0.8085\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2808 - accuracy: 0.8679 - val_loss: 0.4136 - val_accuracy: 0.8085\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2873 - accuracy: 0.8491 - val_loss: 0.4193 - val_accuracy: 0.8085\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3409 - accuracy: 0.8679 - val_loss: 0.4236 - val_accuracy: 0.8085\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2828 - accuracy: 0.8868 - val_loss: 0.4285 - val_accuracy: 0.8085\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 639us/step - loss: 0.1884 - accuracy: 0.9245 - val_loss: 0.4294 - val_accuracy: 0.8085\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2688 - accuracy: 0.9057 - val_loss: 0.4285 - val_accuracy: 0.8085\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3811 - accuracy: 0.7925 - val_loss: 0.4313 - val_accuracy: 0.8085\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2086 - accuracy: 0.9245 - val_loss: 0.4431 - val_accuracy: 0.7872\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2952 - accuracy: 0.9057 - val_loss: 0.4516 - val_accuracy: 0.7872\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2664 - accuracy: 0.8679 - val_loss: 0.4561 - val_accuracy: 0.8085\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2413 - accuracy: 0.9057 - val_loss: 0.4561 - val_accuracy: 0.8085\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2973 - accuracy: 0.8868 - val_loss: 0.4536 - val_accuracy: 0.7872\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2954 - accuracy: 0.8868 - val_loss: 0.4478 - val_accuracy: 0.7872\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3821 - accuracy: 0.8868 - val_loss: 0.4406 - val_accuracy: 0.7872\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3030 - accuracy: 0.9057 - val_loss: 0.4381 - val_accuracy: 0.8085\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1929 - accuracy: 0.9245 - val_loss: 0.4368 - val_accuracy: 0.8085\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3247 - accuracy: 0.8302 - val_loss: 0.4361 - val_accuracy: 0.8085\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2186 - accuracy: 0.9245 - val_loss: 0.4403 - val_accuracy: 0.7872\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2710 - accuracy: 0.8491 - val_loss: 0.4430 - val_accuracy: 0.7872\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2608 - accuracy: 0.8868 - val_loss: 0.4472 - val_accuracy: 0.7872\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2101 - accuracy: 0.8868 - val_loss: 0.4460 - val_accuracy: 0.7872\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3210 - accuracy: 0.8491 - val_loss: 0.4468 - val_accuracy: 0.7872\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2510 - accuracy: 0.8868 - val_loss: 0.4501 - val_accuracy: 0.7872\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1769 - accuracy: 0.9057 - val_loss: 0.4564 - val_accuracy: 0.7872\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2622 - accuracy: 0.8868 - val_loss: 0.4536 - val_accuracy: 0.7872\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2573 - accuracy: 0.8302 - val_loss: 0.4450 - val_accuracy: 0.7872\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2400 - accuracy: 0.8679 - val_loss: 0.4369 - val_accuracy: 0.8085\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2113 - accuracy: 0.9245 - val_loss: 0.4269 - val_accuracy: 0.8085\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2094 - accuracy: 0.9245 - val_loss: 0.4206 - val_accuracy: 0.8085\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2481 - accuracy: 0.8868 - val_loss: 0.4147 - val_accuracy: 0.8085\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.96 - 0s 753us/step - loss: 0.2616 - accuracy: 0.9057 - val_loss: 0.4127 - val_accuracy: 0.8085\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2237 - accuracy: 0.9245 - val_loss: 0.4074 - val_accuracy: 0.8085\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2376 - accuracy: 0.9245 - val_loss: 0.4032 - val_accuracy: 0.8085\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2348 - accuracy: 0.9245 - val_loss: 0.3999 - val_accuracy: 0.8085\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3318 - accuracy: 0.84 - 0s 677us/step - loss: 0.2742 - accuracy: 0.8679 - val_loss: 0.3975 - val_accuracy: 0.8085\n",
      "Epoch 490/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.2200 - accuracy: 0.8868 - val_loss: 0.3967 - val_accuracy: 0.8085\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2175 - accuracy: 0.9057 - val_loss: 0.3976 - val_accuracy: 0.8085\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2906 - accuracy: 0.8868 - val_loss: 0.3979 - val_accuracy: 0.8085\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2389 - accuracy: 0.8868 - val_loss: 0.4007 - val_accuracy: 0.8085\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2880 - accuracy: 0.9057 - val_loss: 0.4052 - val_accuracy: 0.8085\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1684 - accuracy: 0.9434 - val_loss: 0.4066 - val_accuracy: 0.8085\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2726 - accuracy: 0.8868 - val_loss: 0.4044 - val_accuracy: 0.8085\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3564 - accuracy: 0.8679 - val_loss: 0.4005 - val_accuracy: 0.8085\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2943 - accuracy: 0.8679 - val_loss: 0.3950 - val_accuracy: 0.8085\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2780 - accuracy: 0.8868 - val_loss: 0.3920 - val_accuracy: 0.8085\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2301 - accuracy: 0.8679 - val_loss: 0.3919 - val_accuracy: 0.8085\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2364 - accuracy: 0.8868 - val_loss: 0.3872 - val_accuracy: 0.8298\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2857 - accuracy: 0.8679 - val_loss: 0.3822 - val_accuracy: 0.8298\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2942 - accuracy: 0.8679 - val_loss: 0.3753 - val_accuracy: 0.8298\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2686 - accuracy: 0.8679 - val_loss: 0.3697 - val_accuracy: 0.8298\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2590 - accuracy: 0.8868 - val_loss: 0.3654 - val_accuracy: 0.8298\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2635 - accuracy: 0.8302 - val_loss: 0.3594 - val_accuracy: 0.8511\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2234 - accuracy: 0.9057 - val_loss: 0.3567 - val_accuracy: 0.8511\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3818 - accuracy: 0.8679 - val_loss: 0.3604 - val_accuracy: 0.8511\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2488 - accuracy: 0.8868 - val_loss: 0.3597 - val_accuracy: 0.8723\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2033 - accuracy: 0.9057 - val_loss: 0.3557 - val_accuracy: 0.8723\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3509 - accuracy: 0.8868 - val_loss: 0.3499 - val_accuracy: 0.8723\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2149 - accuracy: 0.9057 - val_loss: 0.3461 - val_accuracy: 0.8723\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2296 - accuracy: 0.9245 - val_loss: 0.3433 - val_accuracy: 0.8723\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2182 - accuracy: 0.8868 - val_loss: 0.3410 - val_accuracy: 0.8723\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3152 - accuracy: 0.9057 - val_loss: 0.3412 - val_accuracy: 0.8511\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3529 - accuracy: 0.8491 - val_loss: 0.3449 - val_accuracy: 0.8511\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3346 - accuracy: 0.8491 - val_loss: 0.3536 - val_accuracy: 0.8723\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2359 - accuracy: 0.9245 - val_loss: 0.3622 - val_accuracy: 0.8723\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2021 - accuracy: 0.9245 - val_loss: 0.3700 - val_accuracy: 0.8723\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2747 - accuracy: 0.8868 - val_loss: 0.3780 - val_accuracy: 0.8511\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2708 - accuracy: 0.8868 - val_loss: 0.3800 - val_accuracy: 0.8511\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2261 - accuracy: 0.8868 - val_loss: 0.3819 - val_accuracy: 0.8511\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2358 - accuracy: 0.8868 - val_loss: 0.3812 - val_accuracy: 0.8511\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3351 - accuracy: 0.8868 - val_loss: 0.3810 - val_accuracy: 0.8511\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2430 - accuracy: 0.9057 - val_loss: 0.3841 - val_accuracy: 0.8511\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2396 - accuracy: 0.8868 - val_loss: 0.3858 - val_accuracy: 0.8511\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2865 - accuracy: 0.8868 - val_loss: 0.3883 - val_accuracy: 0.8511\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2721 - accuracy: 0.9057 - val_loss: 0.3811 - val_accuracy: 0.8511\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2591 - accuracy: 0.9057 - val_loss: 0.3774 - val_accuracy: 0.8511\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3176 - accuracy: 0.8302 - val_loss: 0.3743 - val_accuracy: 0.8511\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1314 - accuracy: 0.9434 - val_loss: 0.3737 - val_accuracy: 0.8511\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2317 - accuracy: 0.9245 - val_loss: 0.3704 - val_accuracy: 0.8511\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2077 - accuracy: 0.9057 - val_loss: 0.3659 - val_accuracy: 0.8511\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2356 - accuracy: 0.8679 - val_loss: 0.3654 - val_accuracy: 0.8511\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2306 - accuracy: 0.8868 - val_loss: 0.3662 - val_accuracy: 0.8511\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3070 - accuracy: 0.8868 - val_loss: 0.3675 - val_accuracy: 0.8511\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.90 - 0s 734us/step - loss: 0.2508 - accuracy: 0.9245 - val_loss: 0.3657 - val_accuracy: 0.8511\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1757 - accuracy: 0.9623 - val_loss: 0.3613 - val_accuracy: 0.8511\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2016 - accuracy: 0.9245 - val_loss: 0.3546 - val_accuracy: 0.8298\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2629 - accuracy: 0.8491 - val_loss: 0.3468 - val_accuracy: 0.8298\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1784 - accuracy: 0.9623 - val_loss: 0.3417 - val_accuracy: 0.8298\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2746 - accuracy: 0.8679 - val_loss: 0.3369 - val_accuracy: 0.8298\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1865 - accuracy: 0.9245 - val_loss: 0.3360 - val_accuracy: 0.8298\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2321 - accuracy: 0.9245 - val_loss: 0.3328 - val_accuracy: 0.8298\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2075 - accuracy: 0.9057 - val_loss: 0.3284 - val_accuracy: 0.8511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3461 - accuracy: 0.8113 - val_loss: 0.3284 - val_accuracy: 0.8723\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2159 - accuracy: 0.9245 - val_loss: 0.3379 - val_accuracy: 0.8723\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2639 - accuracy: 0.9057 - val_loss: 0.3526 - val_accuracy: 0.8723\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1888 - accuracy: 0.9057 - val_loss: 0.3650 - val_accuracy: 0.8511\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3176 - accuracy: 0.8679 - val_loss: 0.3731 - val_accuracy: 0.8511\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2758 - accuracy: 0.8868 - val_loss: 0.3786 - val_accuracy: 0.8511\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1884 - accuracy: 0.9434 - val_loss: 0.3775 - val_accuracy: 0.8511\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2384 - accuracy: 0.8679 - val_loss: 0.3696 - val_accuracy: 0.8511\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1874 - accuracy: 0.9057 - val_loss: 0.3706 - val_accuracy: 0.8511\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.1482 - accuracy: 0.9623 - val_loss: 0.3689 - val_accuracy: 0.8511\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3087 - accuracy: 0.8868 - val_loss: 0.3720 - val_accuracy: 0.8511\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3912 - accuracy: 0.8491 - val_loss: 0.3723 - val_accuracy: 0.8511\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2425 - accuracy: 0.8679 - val_loss: 0.3631 - val_accuracy: 0.8511\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1791 - accuracy: 0.9245 - val_loss: 0.3551 - val_accuracy: 0.8723\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2975 - accuracy: 0.8679 - val_loss: 0.3462 - val_accuracy: 0.8723\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2639 - accuracy: 0.8868 - val_loss: 0.3375 - val_accuracy: 0.8723\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3669 - accuracy: 0.8302 - val_loss: 0.3332 - val_accuracy: 0.8723\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2380 - accuracy: 0.9057 - val_loss: 0.3332 - val_accuracy: 0.8511\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1943 - accuracy: 0.9434 - val_loss: 0.3341 - val_accuracy: 0.8511\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1568 - accuracy: 0.9245 - val_loss: 0.3358 - val_accuracy: 0.8511\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1831 - accuracy: 0.9245 - val_loss: 0.3353 - val_accuracy: 0.8511\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2465 - accuracy: 0.8679 - val_loss: 0.3327 - val_accuracy: 0.8298\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2262 - accuracy: 0.9057 - val_loss: 0.3317 - val_accuracy: 0.8298\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3441 - accuracy: 0.8868 - val_loss: 0.3319 - val_accuracy: 0.8298\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2926 - accuracy: 0.8868 - val_loss: 0.3368 - val_accuracy: 0.8298\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2392 - accuracy: 0.9245 - val_loss: 0.3439 - val_accuracy: 0.8298\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2707 - accuracy: 0.8868 - val_loss: 0.3531 - val_accuracy: 0.8298\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2073 - accuracy: 0.8679 - val_loss: 0.3587 - val_accuracy: 0.8298\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2000 - accuracy: 0.9245 - val_loss: 0.3615 - val_accuracy: 0.8298\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.2571 - accuracy: 0.8868 - val_loss: 0.3565 - val_accuracy: 0.8298\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2436 - accuracy: 0.9057 - val_loss: 0.3517 - val_accuracy: 0.8298\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2070 - accuracy: 0.9245 - val_loss: 0.3448 - val_accuracy: 0.8298\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.2685 - accuracy: 0.9057 - val_loss: 0.3418 - val_accuracy: 0.8298\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.2268 - accuracy: 0.8868 - val_loss: 0.3408 - val_accuracy: 0.8298\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2288 - accuracy: 0.9245 - val_loss: 0.3436 - val_accuracy: 0.8298\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2884 - accuracy: 0.8868 - val_loss: 0.3457 - val_accuracy: 0.8511\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2601 - accuracy: 0.9057 - val_loss: 0.3491 - val_accuracy: 0.8511\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1897 - accuracy: 0.9434 - val_loss: 0.3540 - val_accuracy: 0.8723\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2620 - accuracy: 0.9245 - val_loss: 0.3608 - val_accuracy: 0.8723\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2152 - accuracy: 0.9434 - val_loss: 0.3652 - val_accuracy: 0.8511\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1750 - accuracy: 0.9057 - val_loss: 0.3669 - val_accuracy: 0.8511\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1907 - accuracy: 0.9057 - val_loss: 0.3589 - val_accuracy: 0.8723\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2909 - accuracy: 0.8868 - val_loss: 0.3464 - val_accuracy: 0.8511\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1789 - accuracy: 0.9245 - val_loss: 0.3285 - val_accuracy: 0.8298\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2483 - accuracy: 0.8679 - val_loss: 0.3122 - val_accuracy: 0.8298\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1823 - accuracy: 0.9245 - val_loss: 0.3035 - val_accuracy: 0.8298\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2823 - accuracy: 0.9245 - val_loss: 0.3027 - val_accuracy: 0.8298\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2995 - accuracy: 0.8868 - val_loss: 0.3065 - val_accuracy: 0.8298\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1900 - accuracy: 0.9057 - val_loss: 0.3076 - val_accuracy: 0.8723\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2053 - accuracy: 0.9057 - val_loss: 0.3058 - val_accuracy: 0.8723\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2025 - accuracy: 0.9434 - val_loss: 0.3060 - val_accuracy: 0.8723\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2549 - accuracy: 0.8679 - val_loss: 0.3059 - val_accuracy: 0.8723\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2037 - accuracy: 0.9245 - val_loss: 0.3010 - val_accuracy: 0.8723\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1967 - accuracy: 0.9057 - val_loss: 0.2922 - val_accuracy: 0.8511\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1168 - accuracy: 0.9434 - val_loss: 0.2851 - val_accuracy: 0.8298\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2437 - accuracy: 0.8491 - val_loss: 0.2806 - val_accuracy: 0.8298\n",
      "Epoch 602/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.3818 - accuracy: 0.8868 - val_loss: 0.2809 - val_accuracy: 0.8298\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2389 - accuracy: 0.8868 - val_loss: 0.2810 - val_accuracy: 0.8511\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2503 - accuracy: 0.9057 - val_loss: 0.2842 - val_accuracy: 0.8723\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2526 - accuracy: 0.8868 - val_loss: 0.2913 - val_accuracy: 0.8723\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2066 - accuracy: 0.9057 - val_loss: 0.2982 - val_accuracy: 0.8723\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2072 - accuracy: 0.9434 - val_loss: 0.3021 - val_accuracy: 0.8723\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1836 - accuracy: 0.9245 - val_loss: 0.3051 - val_accuracy: 0.8723\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.1865 - accuracy: 0.9057 - val_loss: 0.3073 - val_accuracy: 0.8723\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1818 - accuracy: 0.9245 - val_loss: 0.3081 - val_accuracy: 0.8723\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1929 - accuracy: 0.9245 - val_loss: 0.3021 - val_accuracy: 0.8723\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3110 - accuracy: 0.7925 - val_loss: 0.2947 - val_accuracy: 0.8723\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2978 - accuracy: 0.8868 - val_loss: 0.2965 - val_accuracy: 0.8723\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1918 - accuracy: 0.9434 - val_loss: 0.3023 - val_accuracy: 0.8723\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2785 - accuracy: 0.8679 - val_loss: 0.3126 - val_accuracy: 0.8723\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2168 - accuracy: 0.9245 - val_loss: 0.3165 - val_accuracy: 0.8723\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2530 - accuracy: 0.8868 - val_loss: 0.3164 - val_accuracy: 0.8723\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2460 - accuracy: 0.9057 - val_loss: 0.3042 - val_accuracy: 0.8723\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2261 - accuracy: 0.8868 - val_loss: 0.2891 - val_accuracy: 0.8723\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1816 - accuracy: 0.9245 - val_loss: 0.2791 - val_accuracy: 0.8723\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2344 - accuracy: 0.9057 - val_loss: 0.2758 - val_accuracy: 0.8723\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1971 - accuracy: 0.9245 - val_loss: 0.2742 - val_accuracy: 0.8723\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2500 - accuracy: 0.8868 - val_loss: 0.2760 - val_accuracy: 0.8723\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3729 - accuracy: 0.8302 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2977 - accuracy: 0.8868 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1991 - accuracy: 0.9057 - val_loss: 0.3180 - val_accuracy: 0.8723\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2226 - accuracy: 0.9057 - val_loss: 0.3328 - val_accuracy: 0.8723\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2795 - accuracy: 0.8679 - val_loss: 0.3487 - val_accuracy: 0.8723\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 658us/step - loss: 0.1786 - accuracy: 0.9434 - val_loss: 0.3613 - val_accuracy: 0.8723\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2580 - accuracy: 0.9057 - val_loss: 0.3613 - val_accuracy: 0.8723\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1882 - accuracy: 0.9245 - val_loss: 0.3564 - val_accuracy: 0.8723\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3025 - accuracy: 0.8868 - val_loss: 0.3561 - val_accuracy: 0.8723\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2527 - accuracy: 0.8868 - val_loss: 0.3505 - val_accuracy: 0.8723\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1807 - accuracy: 0.9434 - val_loss: 0.3444 - val_accuracy: 0.8723\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2099 - accuracy: 0.9623 - val_loss: 0.3431 - val_accuracy: 0.8723\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2011 - accuracy: 0.9245 - val_loss: 0.3385 - val_accuracy: 0.8723\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2021 - accuracy: 0.9057 - val_loss: 0.3325 - val_accuracy: 0.8723\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1939 - accuracy: 0.9245 - val_loss: 0.3311 - val_accuracy: 0.8723\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2027 - accuracy: 0.8868 - val_loss: 0.3267 - val_accuracy: 0.8723\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1960 - accuracy: 0.9434 - val_loss: 0.3229 - val_accuracy: 0.8723\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2830 - accuracy: 0.8679 - val_loss: 0.3162 - val_accuracy: 0.8723\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2158 - accuracy: 0.9434 - val_loss: 0.3153 - val_accuracy: 0.8723\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2923 - accuracy: 0.8868 - val_loss: 0.3234 - val_accuracy: 0.8723\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1951 - accuracy: 0.9057 - val_loss: 0.3335 - val_accuracy: 0.8723\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2082 - accuracy: 0.8868 - val_loss: 0.3449 - val_accuracy: 0.8723\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1861 - accuracy: 0.8868 - val_loss: 0.3585 - val_accuracy: 0.8723\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2333 - accuracy: 0.9434 - val_loss: 0.3692 - val_accuracy: 0.8723\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1512 - accuracy: 0.9245 - val_loss: 0.3736 - val_accuracy: 0.8511\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2798 - accuracy: 0.8679 - val_loss: 0.3716 - val_accuracy: 0.8511\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2467 - accuracy: 0.8868 - val_loss: 0.3639 - val_accuracy: 0.8723\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2373 - accuracy: 0.9245 - val_loss: 0.3541 - val_accuracy: 0.8723\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1754 - accuracy: 0.9245 - val_loss: 0.3389 - val_accuracy: 0.8723\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1630 - accuracy: 0.9434 - val_loss: 0.3243 - val_accuracy: 0.8723\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2253 - accuracy: 0.8679 - val_loss: 0.3114 - val_accuracy: 0.8298\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3643 - accuracy: 0.8113 - val_loss: 0.3141 - val_accuracy: 0.8723\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2442 - accuracy: 0.9057 - val_loss: 0.3266 - val_accuracy: 0.8723\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2485 - accuracy: 0.8868 - val_loss: 0.3420 - val_accuracy: 0.8723\n",
      "Epoch 658/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.2236 - accuracy: 0.8868 - val_loss: 0.3591 - val_accuracy: 0.8723\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.90 - 0s 715us/step - loss: 0.1969 - accuracy: 0.9057 - val_loss: 0.3747 - val_accuracy: 0.8511\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3153 - accuracy: 0.9057 - val_loss: 0.3921 - val_accuracy: 0.8511\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2121 - accuracy: 0.9434 - val_loss: 0.3997 - val_accuracy: 0.8511\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3147 - accuracy: 0.8679 - val_loss: 0.4036 - val_accuracy: 0.8511\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1538 - accuracy: 0.9434 - val_loss: 0.4098 - val_accuracy: 0.8511\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2592 - accuracy: 0.9057 - val_loss: 0.4052 - val_accuracy: 0.8511\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2510 - accuracy: 0.8868 - val_loss: 0.3974 - val_accuracy: 0.8511\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.1951 - accuracy: 0.9434 - val_loss: 0.3842 - val_accuracy: 0.8511\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2671 - accuracy: 0.9057 - val_loss: 0.3736 - val_accuracy: 0.8723\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2428 - accuracy: 0.9245 - val_loss: 0.3580 - val_accuracy: 0.8723\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1961 - accuracy: 0.9245 - val_loss: 0.3401 - val_accuracy: 0.8723\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1946 - accuracy: 0.9434 - val_loss: 0.3245 - val_accuracy: 0.8723\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2443 - accuracy: 0.8868 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2548 - accuracy: 0.8679 - val_loss: 0.3081 - val_accuracy: 0.8723\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2433 - accuracy: 0.8868 - val_loss: 0.3047 - val_accuracy: 0.8723\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1977 - accuracy: 0.9434 - val_loss: 0.3006 - val_accuracy: 0.8723\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1756 - accuracy: 0.9434 - val_loss: 0.2997 - val_accuracy: 0.8723\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3265 - accuracy: 0.8868 - val_loss: 0.3009 - val_accuracy: 0.8723\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3533 - accuracy: 0.8679 - val_loss: 0.3114 - val_accuracy: 0.8723\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2253 - accuracy: 0.9057 - val_loss: 0.3184 - val_accuracy: 0.8723\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2415 - accuracy: 0.9245 - val_loss: 0.3215 - val_accuracy: 0.8723\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1893 - accuracy: 0.9245 - val_loss: 0.3257 - val_accuracy: 0.8723\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2517 - accuracy: 0.9245 - val_loss: 0.3322 - val_accuracy: 0.8723\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2442 - accuracy: 0.9057 - val_loss: 0.3444 - val_accuracy: 0.8723\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1916 - accuracy: 0.9623 - val_loss: 0.3569 - val_accuracy: 0.8723\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1676 - accuracy: 0.9623 - val_loss: 0.3627 - val_accuracy: 0.8723\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1796 - accuracy: 0.9245 - val_loss: 0.3638 - val_accuracy: 0.8723\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2146 - accuracy: 0.9245 - val_loss: 0.3646 - val_accuracy: 0.8723\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2631 - accuracy: 0.9057 - val_loss: 0.3635 - val_accuracy: 0.8723\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2490 - accuracy: 0.8679 - val_loss: 0.3639 - val_accuracy: 0.8723\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2462 - accuracy: 0.9057 - val_loss: 0.3632 - val_accuracy: 0.8723\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2390 - accuracy: 0.8868 - val_loss: 0.3594 - val_accuracy: 0.8723\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3133 - accuracy: 0.8679 - val_loss: 0.3550 - val_accuracy: 0.8723\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1794 - accuracy: 0.9245 - val_loss: 0.3492 - val_accuracy: 0.8723\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1931 - accuracy: 0.9057 - val_loss: 0.3417 - val_accuracy: 0.8723\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2985 - accuracy: 0.8868 - val_loss: 0.3370 - val_accuracy: 0.8723\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2924 - accuracy: 0.8868 - val_loss: 0.3318 - val_accuracy: 0.8723\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1577 - accuracy: 0.9057 - val_loss: 0.3222 - val_accuracy: 0.8723\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2103 - accuracy: 0.9057 - val_loss: 0.3144 - val_accuracy: 0.8723\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1439 - accuracy: 0.9623 - val_loss: 0.3098 - val_accuracy: 0.8723\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.1575 - accuracy: 0.9245 - val_loss: 0.3057 - val_accuracy: 0.8723\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2165 - accuracy: 0.9057 - val_loss: 0.3096 - val_accuracy: 0.8723\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1677 - accuracy: 0.9245 - val_loss: 0.3152 - val_accuracy: 0.8723\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1539 - accuracy: 0.9434 - val_loss: 0.3173 - val_accuracy: 0.8723\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2301 - accuracy: 0.9245 - val_loss: 0.3211 - val_accuracy: 0.8723\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2124 - accuracy: 0.9057 - val_loss: 0.3239 - val_accuracy: 0.8723\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2382 - accuracy: 0.9057 - val_loss: 0.3270 - val_accuracy: 0.8723\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2486 - accuracy: 0.8868 - val_loss: 0.3271 - val_accuracy: 0.8723\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2893 - accuracy: 0.9057 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2635 - accuracy: 0.9245 - val_loss: 0.3303 - val_accuracy: 0.8723\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2194 - accuracy: 0.8679 - val_loss: 0.3287 - val_accuracy: 0.8723\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2080 - accuracy: 0.9057 - val_loss: 0.3216 - val_accuracy: 0.8723\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2211 - accuracy: 0.9057 - val_loss: 0.3116 - val_accuracy: 0.8723\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2850 - accuracy: 0.8679 - val_loss: 0.3099 - val_accuracy: 0.8723\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1996 - accuracy: 0.9245 - val_loss: 0.3066 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2330 - accuracy: 0.9057 - val_loss: 0.3047 - val_accuracy: 0.8723\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2677 - accuracy: 0.8868 - val_loss: 0.3035 - val_accuracy: 0.8723\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3591 - accuracy: 0.8302 - val_loss: 0.3026 - val_accuracy: 0.8723\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2143 - accuracy: 0.9245 - val_loss: 0.3011 - val_accuracy: 0.8723\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3322 - accuracy: 0.8302 - val_loss: 0.3021 - val_accuracy: 0.8723\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2158 - accuracy: 0.8868 - val_loss: 0.3065 - val_accuracy: 0.8723\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1470 - accuracy: 0.9434 - val_loss: 0.3068 - val_accuracy: 0.8723\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2630 - accuracy: 0.8868 - val_loss: 0.3070 - val_accuracy: 0.8723\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2161 - accuracy: 0.8868 - val_loss: 0.3054 - val_accuracy: 0.8723\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2959 - accuracy: 0.8679 - val_loss: 0.3047 - val_accuracy: 0.8723\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1814 - accuracy: 0.9057 - val_loss: 0.3016 - val_accuracy: 0.8723\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2275 - accuracy: 0.9434 - val_loss: 0.3023 - val_accuracy: 0.8723\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2156 - accuracy: 0.9434 - val_loss: 0.3050 - val_accuracy: 0.8723\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1702 - accuracy: 0.9245 - val_loss: 0.3123 - val_accuracy: 0.8723\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1920 - accuracy: 0.9057 - val_loss: 0.3197 - val_accuracy: 0.8723\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2129 - accuracy: 0.9434 - val_loss: 0.3274 - val_accuracy: 0.8723\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2056 - accuracy: 0.9057 - val_loss: 0.3332 - val_accuracy: 0.8723\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3293 - accuracy: 0.8491 - val_loss: 0.3319 - val_accuracy: 0.8723\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2634 - accuracy: 0.8868 - val_loss: 0.3322 - val_accuracy: 0.8723\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2419 - accuracy: 0.9245 - val_loss: 0.3296 - val_accuracy: 0.8723\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2670 - accuracy: 0.8491 - val_loss: 0.3265 - val_accuracy: 0.8723\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2465 - accuracy: 0.8868 - val_loss: 0.3266 - val_accuracy: 0.8723\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1693 - accuracy: 0.9245 - val_loss: 0.3215 - val_accuracy: 0.8723\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2735 - accuracy: 0.8868 - val_loss: 0.3200 - val_accuracy: 0.8723\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2148 - accuracy: 0.9245 - val_loss: 0.3233 - val_accuracy: 0.8723\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2564 - accuracy: 0.9245 - val_loss: 0.3292 - val_accuracy: 0.8723\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2169 - accuracy: 0.8868 - val_loss: 0.3307 - val_accuracy: 0.8723\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2515 - accuracy: 0.9057 - val_loss: 0.3333 - val_accuracy: 0.8723\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1658 - accuracy: 0.9623 - val_loss: 0.3360 - val_accuracy: 0.8723\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2429 - accuracy: 0.9245 - val_loss: 0.3351 - val_accuracy: 0.8723\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1965 - accuracy: 0.8868 - val_loss: 0.3373 - val_accuracy: 0.8723\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1804 - accuracy: 0.9434 - val_loss: 0.3400 - val_accuracy: 0.8723\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2283 - accuracy: 0.9245 - val_loss: 0.3407 - val_accuracy: 0.8723\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2877 - accuracy: 0.8868 - val_loss: 0.3364 - val_accuracy: 0.8723\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1340 - accuracy: 0.9434 - val_loss: 0.3288 - val_accuracy: 0.8723\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2012 - accuracy: 0.9245 - val_loss: 0.3194 - val_accuracy: 0.8723\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3027 - accuracy: 0.8302 - val_loss: 0.3166 - val_accuracy: 0.8723\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1626 - accuracy: 0.9623 - val_loss: 0.3169 - val_accuracy: 0.8723\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1610 - accuracy: 0.9245 - val_loss: 0.3169 - val_accuracy: 0.8723\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1960 - accuracy: 0.9245 - val_loss: 0.3153 - val_accuracy: 0.8723\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2895 - accuracy: 0.8868 - val_loss: 0.3231 - val_accuracy: 0.8723\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2206 - accuracy: 0.8868 - val_loss: 0.3304 - val_accuracy: 0.8723\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2270 - accuracy: 0.8679 - val_loss: 0.3361 - val_accuracy: 0.8723\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1993 - accuracy: 0.8679 - val_loss: 0.3376 - val_accuracy: 0.8723\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2223 - accuracy: 0.9057 - val_loss: 0.3380 - val_accuracy: 0.8723\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2402 - accuracy: 0.8868 - val_loss: 0.3294 - val_accuracy: 0.8723\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1990 - accuracy: 0.9245 - val_loss: 0.3160 - val_accuracy: 0.8723\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1783 - accuracy: 0.9434 - val_loss: 0.3037 - val_accuracy: 0.8723\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2247 - accuracy: 0.9245 - val_loss: 0.2905 - val_accuracy: 0.8723\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2899 - accuracy: 0.9057 - val_loss: 0.2822 - val_accuracy: 0.8723\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1961 - accuracy: 0.9057 - val_loss: 0.2725 - val_accuracy: 0.8723\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2839 - accuracy: 0.9057 - val_loss: 0.2658 - val_accuracy: 0.8723\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1942 - accuracy: 0.9245 - val_loss: 0.2652 - val_accuracy: 0.8723\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2242 - accuracy: 0.9245 - val_loss: 0.2724 - val_accuracy: 0.8723\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1856 - accuracy: 0.9245 - val_loss: 0.2789 - val_accuracy: 0.8723\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2078 - accuracy: 0.9057 - val_loss: 0.2881 - val_accuracy: 0.8723\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.2036 - accuracy: 0.8868 - val_loss: 0.2943 - val_accuracy: 0.8723\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3444 - accuracy: 0.7925 - val_loss: 0.2949 - val_accuracy: 0.8723\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2186 - accuracy: 0.8679 - val_loss: 0.2906 - val_accuracy: 0.8723\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2174 - accuracy: 0.9245 - val_loss: 0.2835 - val_accuracy: 0.8723\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2241 - accuracy: 0.9245 - val_loss: 0.2796 - val_accuracy: 0.8723\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2259 - accuracy: 0.9057 - val_loss: 0.2735 - val_accuracy: 0.8723\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1842 - accuracy: 0.9434 - val_loss: 0.2670 - val_accuracy: 0.8723\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1737 - accuracy: 0.9245 - val_loss: 0.2551 - val_accuracy: 0.8723\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2394 - accuracy: 0.9057 - val_loss: 0.2425 - val_accuracy: 0.8723\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2234 - accuracy: 0.8868 - val_loss: 0.2324 - val_accuracy: 0.8723\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1537 - accuracy: 0.9245 - val_loss: 0.2279 - val_accuracy: 0.8723\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2012 - accuracy: 0.9245 - val_loss: 0.2266 - val_accuracy: 0.8723\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1307 - accuracy: 0.9434 - val_loss: 0.2247 - val_accuracy: 0.8936\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2580 - accuracy: 0.9245 - val_loss: 0.2270 - val_accuracy: 0.8723\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2174 - accuracy: 0.9057 - val_loss: 0.2304 - val_accuracy: 0.8723\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1998 - accuracy: 0.9245 - val_loss: 0.2352 - val_accuracy: 0.8723\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2053 - accuracy: 0.9057 - val_loss: 0.2472 - val_accuracy: 0.8723\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2376 - accuracy: 0.8868 - val_loss: 0.2579 - val_accuracy: 0.8723\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2046 - accuracy: 0.9057 - val_loss: 0.2649 - val_accuracy: 0.8723\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1919 - accuracy: 0.9245 - val_loss: 0.2681 - val_accuracy: 0.8723\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1827 - accuracy: 0.9245 - val_loss: 0.2780 - val_accuracy: 0.8723\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1786 - accuracy: 0.9434 - val_loss: 0.2850 - val_accuracy: 0.8723\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2743 - accuracy: 0.8868 - val_loss: 0.2923 - val_accuracy: 0.8723\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1123 - accuracy: 1.0000 - val_loss: 0.2962 - val_accuracy: 0.8723\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1910 - accuracy: 0.9434 - val_loss: 0.2985 - val_accuracy: 0.8723\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1696 - accuracy: 0.9245 - val_loss: 0.3014 - val_accuracy: 0.8723\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2870 - accuracy: 0.9057 - val_loss: 0.3116 - val_accuracy: 0.8723\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1915 - accuracy: 0.8868 - val_loss: 0.3228 - val_accuracy: 0.8723\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2202 - accuracy: 0.9245 - val_loss: 0.3341 - val_accuracy: 0.8723\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1763 - accuracy: 0.9245 - val_loss: 0.3381 - val_accuracy: 0.8723\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2057 - accuracy: 0.9245 - val_loss: 0.3348 - val_accuracy: 0.8723\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2082 - accuracy: 0.9057 - val_loss: 0.3311 - val_accuracy: 0.8723\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2236 - accuracy: 0.8679 - val_loss: 0.3209 - val_accuracy: 0.8723\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1864 - accuracy: 0.9434 - val_loss: 0.3071 - val_accuracy: 0.8723\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2688 - accuracy: 0.9057 - val_loss: 0.2957 - val_accuracy: 0.8723\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2073 - accuracy: 0.9245 - val_loss: 0.2829 - val_accuracy: 0.8723\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2323 - accuracy: 0.8679 - val_loss: 0.2755 - val_accuracy: 0.8723\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2070 - accuracy: 0.9245 - val_loss: 0.2731 - val_accuracy: 0.8723\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2180 - accuracy: 0.8679 - val_loss: 0.2686 - val_accuracy: 0.8723\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3174 - accuracy: 0.8868 - val_loss: 0.2680 - val_accuracy: 0.8723\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2761 - accuracy: 0.8868 - val_loss: 0.2762 - val_accuracy: 0.8723\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1375 - accuracy: 0.9434 - val_loss: 0.2850 - val_accuracy: 0.8723\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2071 - accuracy: 0.9245 - val_loss: 0.2879 - val_accuracy: 0.8723\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2288 - accuracy: 0.9434 - val_loss: 0.2870 - val_accuracy: 0.8723\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2831 - accuracy: 0.8868 - val_loss: 0.2941 - val_accuracy: 0.8723\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2430 - accuracy: 0.9057 - val_loss: 0.3071 - val_accuracy: 0.8723\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1534 - accuracy: 0.9623 - val_loss: 0.3170 - val_accuracy: 0.8723\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1711 - accuracy: 0.9245 - val_loss: 0.3192 - val_accuracy: 0.8723\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1954 - accuracy: 0.9057 - val_loss: 0.3158 - val_accuracy: 0.8723\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2163 - accuracy: 0.9245 - val_loss: 0.3138 - val_accuracy: 0.8723\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2893 - accuracy: 0.9057 - val_loss: 0.3107 - val_accuracy: 0.8723\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1236 - accuracy: 0.9811 - val_loss: 0.3064 - val_accuracy: 0.8723\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1860 - accuracy: 0.9245 - val_loss: 0.3023 - val_accuracy: 0.8723\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.3098 - accuracy: 0.8868 - val_loss: 0.2981 - val_accuracy: 0.8723\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1673 - accuracy: 0.9434 - val_loss: 0.2948 - val_accuracy: 0.8723\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3231 - accuracy: 0.8868 - val_loss: 0.2964 - val_accuracy: 0.8723\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.2594 - accuracy: 0.9057 - val_loss: 0.3048 - val_accuracy: 0.8723\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2560 - accuracy: 0.8868 - val_loss: 0.3149 - val_accuracy: 0.8723\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2148 - accuracy: 0.9245 - val_loss: 0.3244 - val_accuracy: 0.8723\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2948 - accuracy: 0.8868 - val_loss: 0.3272 - val_accuracy: 0.8723\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2789 - accuracy: 0.9245 - val_loss: 0.3254 - val_accuracy: 0.8723\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2263 - accuracy: 0.9245 - val_loss: 0.3211 - val_accuracy: 0.8723\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1661 - accuracy: 0.9245 - val_loss: 0.3107 - val_accuracy: 0.8723\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2145 - accuracy: 0.9245 - val_loss: 0.3042 - val_accuracy: 0.8723\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1670 - accuracy: 0.9434 - val_loss: 0.3028 - val_accuracy: 0.8723\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3443 - accuracy: 0.8491 - val_loss: 0.3207 - val_accuracy: 0.8723\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1859 - accuracy: 0.9434 - val_loss: 0.3413 - val_accuracy: 0.8723\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1480 - accuracy: 0.9434 - val_loss: 0.3589 - val_accuracy: 0.8723\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1133 - accuracy: 0.9811 - val_loss: 0.3734 - val_accuracy: 0.8723\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1420 - accuracy: 0.9811 - val_loss: 0.3793 - val_accuracy: 0.8723\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2112 - accuracy: 0.9057 - val_loss: 0.3785 - val_accuracy: 0.8723\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2204 - accuracy: 0.9245 - val_loss: 0.3747 - val_accuracy: 0.8723\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.1943 - accuracy: 0.8868 - val_loss: 0.3641 - val_accuracy: 0.8723\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2419 - accuracy: 0.8868 - val_loss: 0.3467 - val_accuracy: 0.8723\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2215 - accuracy: 0.8868 - val_loss: 0.3326 - val_accuracy: 0.8723\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1692 - accuracy: 0.9434 - val_loss: 0.3195 - val_accuracy: 0.8723\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1870 - accuracy: 0.9057 - val_loss: 0.3066 - val_accuracy: 0.8723\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2475 - accuracy: 0.8679 - val_loss: 0.2996 - val_accuracy: 0.8723\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1912 - accuracy: 0.9245 - val_loss: 0.2983 - val_accuracy: 0.8723\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1501 - accuracy: 0.9245 - val_loss: 0.2986 - val_accuracy: 0.8723\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2225 - accuracy: 0.9057 - val_loss: 0.3044 - val_accuracy: 0.8723\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1970 - accuracy: 0.9245 - val_loss: 0.3090 - val_accuracy: 0.8723\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2634 - accuracy: 0.8868 - val_loss: 0.3145 - val_accuracy: 0.8723\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3251 - accuracy: 0.8679 - val_loss: 0.3231 - val_accuracy: 0.8723\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1758 - accuracy: 0.9434 - val_loss: 0.3286 - val_accuracy: 0.8723\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1955 - accuracy: 0.9434 - val_loss: 0.3318 - val_accuracy: 0.8723\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2343 - accuracy: 0.9057 - val_loss: 0.3329 - val_accuracy: 0.8723\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2000 - accuracy: 0.8868 - val_loss: 0.3297 - val_accuracy: 0.8723\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3470 - accuracy: 0.9057 - val_loss: 0.3210 - val_accuracy: 0.8723\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2294 - accuracy: 0.8679 - val_loss: 0.3134 - val_accuracy: 0.8723\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1397 - accuracy: 0.9434 - val_loss: 0.3108 - val_accuracy: 0.8723\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2784 - accuracy: 0.8868 - val_loss: 0.3115 - val_accuracy: 0.8723\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1445 - accuracy: 0.9434 - val_loss: 0.3124 - val_accuracy: 0.8723\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1487 - accuracy: 0.9434 - val_loss: 0.3105 - val_accuracy: 0.8723\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1799 - accuracy: 0.9434 - val_loss: 0.3109 - val_accuracy: 0.8723\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.2259 - accuracy: 0.8491 - val_loss: 0.3131 - val_accuracy: 0.8723\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1871 - accuracy: 0.9434 - val_loss: 0.3201 - val_accuracy: 0.8723\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1670 - accuracy: 0.9434 - val_loss: 0.3228 - val_accuracy: 0.8723\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2187 - accuracy: 0.9245 - val_loss: 0.3238 - val_accuracy: 0.8723\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.3251 - val_accuracy: 0.8723\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2561 - accuracy: 0.8868 - val_loss: 0.3254 - val_accuracy: 0.8723\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2401 - accuracy: 0.9057 - val_loss: 0.3330 - val_accuracy: 0.8723\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2292 - accuracy: 0.9057 - val_loss: 0.3363 - val_accuracy: 0.8723\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2539 - accuracy: 0.8868 - val_loss: 0.3413 - val_accuracy: 0.8723\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1291 - accuracy: 0.9623 - val_loss: 0.3452 - val_accuracy: 0.8723\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1383 - accuracy: 0.9623 - val_loss: 0.3467 - val_accuracy: 0.8511\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1762 - accuracy: 0.9245 - val_loss: 0.3455 - val_accuracy: 0.8723\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1787 - accuracy: 0.9057 - val_loss: 0.3420 - val_accuracy: 0.8723\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1444 - accuracy: 0.9434 - val_loss: 0.3349 - val_accuracy: 0.8723\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1523 - accuracy: 0.9057 - val_loss: 0.3252 - val_accuracy: 0.8723\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2063 - accuracy: 0.9057 - val_loss: 0.3171 - val_accuracy: 0.8723\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1645 - accuracy: 0.9245 - val_loss: 0.3110 - val_accuracy: 0.8723\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 753us/step - loss: 0.1885 - accuracy: 0.9245 - val_loss: 0.3024 - val_accuracy: 0.8723\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2385 - accuracy: 0.8679 - val_loss: 0.2972 - val_accuracy: 0.8723\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1571 - accuracy: 0.9057 - val_loss: 0.2920 - val_accuracy: 0.8723\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2521 - accuracy: 0.8868 - val_loss: 0.2812 - val_accuracy: 0.8723\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1543 - accuracy: 0.9811 - val_loss: 0.2731 - val_accuracy: 0.8723\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4353 - accuracy: 0.8491 - val_loss: 0.2775 - val_accuracy: 0.8723\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1606 - accuracy: 0.9245 - val_loss: 0.2839 - val_accuracy: 0.8723\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1060 - accuracy: 0.9623 - val_loss: 0.2862 - val_accuracy: 0.8723\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2925 - accuracy: 0.8491 - val_loss: 0.2987 - val_accuracy: 0.8723\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2403 - accuracy: 0.8868 - val_loss: 0.3120 - val_accuracy: 0.8723\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2203 - accuracy: 0.9623 - val_loss: 0.3200 - val_accuracy: 0.8723\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1961 - accuracy: 0.9245 - val_loss: 0.3273 - val_accuracy: 0.8723\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2182 - accuracy: 0.9245 - val_loss: 0.3318 - val_accuracy: 0.8723\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1953 - accuracy: 0.9245 - val_loss: 0.3296 - val_accuracy: 0.8723\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1954 - accuracy: 0.8679 - val_loss: 0.3180 - val_accuracy: 0.8723\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1846 - accuracy: 0.8868 - val_loss: 0.3110 - val_accuracy: 0.8723\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2257 - accuracy: 0.9245 - val_loss: 0.3016 - val_accuracy: 0.8723\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2884 - accuracy: 0.8679 - val_loss: 0.3008 - val_accuracy: 0.8723\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2097 - accuracy: 0.9245 - val_loss: 0.3018 - val_accuracy: 0.8723\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1866 - accuracy: 0.9057 - val_loss: 0.3117 - val_accuracy: 0.8723\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.3623 - accuracy: 0.8679 - val_loss: 0.3246 - val_accuracy: 0.8723\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2207 - accuracy: 0.9434 - val_loss: 0.3356 - val_accuracy: 0.8723\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2276 - accuracy: 0.8679 - val_loss: 0.3416 - val_accuracy: 0.8723\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1455 - accuracy: 0.9434 - val_loss: 0.3440 - val_accuracy: 0.8723\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1623 - accuracy: 0.9434 - val_loss: 0.3438 - val_accuracy: 0.8723\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2021 - accuracy: 0.8868 - val_loss: 0.3376 - val_accuracy: 0.8723\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1953 - accuracy: 0.9245 - val_loss: 0.3328 - val_accuracy: 0.8723\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2109 - accuracy: 0.8679 - val_loss: 0.3349 - val_accuracy: 0.8723\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1601 - accuracy: 0.9245 - val_loss: 0.3350 - val_accuracy: 0.8723\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2446 - accuracy: 0.8868 - val_loss: 0.3403 - val_accuracy: 0.8723\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2278 - accuracy: 0.9245 - val_loss: 0.3498 - val_accuracy: 0.8723\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2217 - accuracy: 0.9057 - val_loss: 0.3561 - val_accuracy: 0.8723\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1526 - accuracy: 0.9434 - val_loss: 0.3566 - val_accuracy: 0.8723\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2147 - accuracy: 0.9057 - val_loss: 0.3529 - val_accuracy: 0.8723\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3218 - accuracy: 0.8491 - val_loss: 0.3473 - val_accuracy: 0.8723\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2165 - accuracy: 0.8868 - val_loss: 0.3381 - val_accuracy: 0.8723\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1278 - accuracy: 0.9811 - val_loss: 0.3228 - val_accuracy: 0.8723\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1799 - accuracy: 0.9434 - val_loss: 0.3087 - val_accuracy: 0.8723\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2420 - accuracy: 0.8679 - val_loss: 0.3066 - val_accuracy: 0.8723\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1603 - accuracy: 0.9434 - val_loss: 0.3038 - val_accuracy: 0.8723\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2687 - accuracy: 0.9057 - val_loss: 0.2950 - val_accuracy: 0.8723\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2577 - accuracy: 0.9245 - val_loss: 0.2882 - val_accuracy: 0.8723\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2136 - accuracy: 0.9057 - val_loss: 0.2870 - val_accuracy: 0.8723\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3305 - accuracy: 0.8113 - val_loss: 0.3038 - val_accuracy: 0.8723\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.2558 - accuracy: 0.8868 - val_loss: 0.3198 - val_accuracy: 0.8723\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2471 - accuracy: 0.9434 - val_loss: 0.3282 - val_accuracy: 0.8723\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1402 - accuracy: 0.9623 - val_loss: 0.3298 - val_accuracy: 0.8723\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1960 - accuracy: 0.9245 - val_loss: 0.3202 - val_accuracy: 0.8723\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.3098 - val_accuracy: 0.8723\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2723 - accuracy: 0.8302 - val_loss: 0.3031 - val_accuracy: 0.8723\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1787 - accuracy: 0.8868 - val_loss: 0.2977 - val_accuracy: 0.8723\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.1349 - accuracy: 0.9434 - val_loss: 0.2945 - val_accuracy: 0.8723\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1919 - accuracy: 0.9245 - val_loss: 0.2881 - val_accuracy: 0.8723\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.1505 - accuracy: 0.9434 - val_loss: 0.2843 - val_accuracy: 0.8723\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1832 - accuracy: 0.9245 - val_loss: 0.2805 - val_accuracy: 0.8723\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2041 - accuracy: 0.9434 - val_loss: 0.2762 - val_accuracy: 0.8723\n",
      "Epoch 938/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.1620 - accuracy: 0.9434 - val_loss: 0.2717 - val_accuracy: 0.8723\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2838 - accuracy: 0.8679 - val_loss: 0.2692 - val_accuracy: 0.8723\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2060 - accuracy: 0.9057 - val_loss: 0.2673 - val_accuracy: 0.8723\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2709 - accuracy: 0.8868 - val_loss: 0.2700 - val_accuracy: 0.8723\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2004 - accuracy: 0.9245 - val_loss: 0.2784 - val_accuracy: 0.8723\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2408 - accuracy: 0.9057 - val_loss: 0.2858 - val_accuracy: 0.8723\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2305 - accuracy: 0.9057 - val_loss: 0.2852 - val_accuracy: 0.8723\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1375 - accuracy: 0.9434 - val_loss: 0.2817 - val_accuracy: 0.8723\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1954 - accuracy: 0.9434 - val_loss: 0.2759 - val_accuracy: 0.8723\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1206 - accuracy: 0.9811 - val_loss: 0.2650 - val_accuracy: 0.8723\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2710 - accuracy: 0.9057 - val_loss: 0.2576 - val_accuracy: 0.8723\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1633 - accuracy: 0.9434 - val_loss: 0.2537 - val_accuracy: 0.8723\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2300 - accuracy: 0.9245 - val_loss: 0.2547 - val_accuracy: 0.8723\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1476 - accuracy: 0.9434 - val_loss: 0.2539 - val_accuracy: 0.8723\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2992 - accuracy: 0.9057 - val_loss: 0.2494 - val_accuracy: 0.8723\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2011 - accuracy: 0.9245 - val_loss: 0.2447 - val_accuracy: 0.8723\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1813 - accuracy: 0.8679 - val_loss: 0.2388 - val_accuracy: 0.8723\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1274 - accuracy: 0.8868 - val_loss: 0.2303 - val_accuracy: 0.8723\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4912 - accuracy: 0.7547 - val_loss: 0.2233 - val_accuracy: 0.8723\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1693 - accuracy: 0.9245 - val_loss: 0.2178 - val_accuracy: 0.8723\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2150 - accuracy: 0.9057 - val_loss: 0.2132 - val_accuracy: 0.9149\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2476 - accuracy: 0.8868 - val_loss: 0.2129 - val_accuracy: 0.9149\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2258 - accuracy: 0.9245 - val_loss: 0.2257 - val_accuracy: 0.8723\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3339 - accuracy: 0.8679 - val_loss: 0.2562 - val_accuracy: 0.8723\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2119 - accuracy: 0.9057 - val_loss: 0.2933 - val_accuracy: 0.8723\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.3402 - val_accuracy: 0.8723\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1816 - accuracy: 0.9245 - val_loss: 0.3762 - val_accuracy: 0.8723\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1265 - accuracy: 0.9623 - val_loss: 0.4009 - val_accuracy: 0.8511\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2380 - accuracy: 0.8679 - val_loss: 0.4096 - val_accuracy: 0.8511\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2423 - accuracy: 0.9057 - val_loss: 0.4159 - val_accuracy: 0.8511\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2067 - accuracy: 0.9057 - val_loss: 0.4140 - val_accuracy: 0.8511\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2093 - accuracy: 0.9245 - val_loss: 0.4108 - val_accuracy: 0.8511\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.2211 - accuracy: 0.9057 - val_loss: 0.4040 - val_accuracy: 0.8511\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1388 - accuracy: 0.9623 - val_loss: 0.3913 - val_accuracy: 0.8511\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2941 - accuracy: 0.8679 - val_loss: 0.3712 - val_accuracy: 0.8723\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2093 - accuracy: 0.9057 - val_loss: 0.3529 - val_accuracy: 0.8723\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2947 - accuracy: 0.8679 - val_loss: 0.3551 - val_accuracy: 0.8723\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1882 - accuracy: 0.9245 - val_loss: 0.3648 - val_accuracy: 0.8723\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1562 - accuracy: 0.9623 - val_loss: 0.3770 - val_accuracy: 0.8723\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1904 - accuracy: 0.9245 - val_loss: 0.3842 - val_accuracy: 0.8723\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1564 - accuracy: 0.9245 - val_loss: 0.3842 - val_accuracy: 0.8723\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2290 - accuracy: 0.9434 - val_loss: 0.3783 - val_accuracy: 0.8723\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1750 - accuracy: 0.9245 - val_loss: 0.3718 - val_accuracy: 0.8723\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1900 - accuracy: 0.9434 - val_loss: 0.3679 - val_accuracy: 0.8723\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1650 - accuracy: 0.9245 - val_loss: 0.3607 - val_accuracy: 0.8723\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2052 - accuracy: 0.9057 - val_loss: 0.3524 - val_accuracy: 0.8723\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2103 - accuracy: 0.9057 - val_loss: 0.3442 - val_accuracy: 0.8723\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1255 - accuracy: 0.9623 - val_loss: 0.3331 - val_accuracy: 0.8723\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1634 - accuracy: 0.9245 - val_loss: 0.3220 - val_accuracy: 0.8723\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.2395 - accuracy: 0.8868 - val_loss: 0.3168 - val_accuracy: 0.8723\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2632 - accuracy: 0.9245 - val_loss: 0.3112 - val_accuracy: 0.8723\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1736 - accuracy: 0.9245 - val_loss: 0.3061 - val_accuracy: 0.8723\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1112 - accuracy: 0.9623 - val_loss: 0.3030 - val_accuracy: 0.8723\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1583 - accuracy: 0.9057 - val_loss: 0.2997 - val_accuracy: 0.8723\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1778 - accuracy: 0.9245 - val_loss: 0.2974 - val_accuracy: 0.8723\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.1445 - accuracy: 0.9434 - val_loss: 0.2995 - val_accuracy: 0.8723\n",
      "Epoch 994/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 659us/step - loss: 0.1380 - accuracy: 0.9623 - val_loss: 0.3029 - val_accuracy: 0.8723\n",
      "Epoch 995/1000\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.1235 - accuracy: 0.9623 - val_loss: 0.3031 - val_accuracy: 0.8723\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1527 - accuracy: 0.9057 - val_loss: 0.3074 - val_accuracy: 0.8723\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.1253 - accuracy: 0.9623 - val_loss: 0.3100 - val_accuracy: 0.8723\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2027 - accuracy: 0.9057 - val_loss: 0.3093 - val_accuracy: 0.8723\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.1927 - accuracy: 0.8679 - val_loss: 0.3019 - val_accuracy: 0.8723\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2249 - accuracy: 0.9057 - val_loss: 0.2972 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27265c5ad30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, use_bias=False,input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(500, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(200, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "plt.plot(history_Adam_1.history['loss'], label = \"tarina BN\")\n",
    "plt.plot(history_Adam_1.history['val_loss'], label = \"test BN\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from help_plot import plot_decision_regions\n",
    "plot_decision_regions(X_test, y_test, model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 1000)              2000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 500)               500000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               100000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 609,001\n",
      "Trainable params: 605,601\n",
      "Non-trainable params: 3,400\n",
      "_________________________________________________________________\n",
      "Train on 53 samples, validate on 47 samples\n",
      "Epoch 1/1000\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.7227 - accuracy: 0.5472 - val_loss: 0.7034 - val_accuracy: 0.5532\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.5158 - accuracy: 0.7170 - val_loss: 0.6884 - val_accuracy: 0.5532\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.4439 - accuracy: 0.7925 - val_loss: 0.6776 - val_accuracy: 0.5532\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.3875 - accuracy: 0.7547 - val_loss: 0.6690 - val_accuracy: 0.5532\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3615 - accuracy: 0.8491 - val_loss: 0.6629 - val_accuracy: 0.5532\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.3410 - accuracy: 0.8679 - val_loss: 0.6581 - val_accuracy: 0.5532\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.3551 - accuracy: 0.8491 - val_loss: 0.6547 - val_accuracy: 0.6170\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2876 - accuracy: 0.8491 - val_loss: 0.6520 - val_accuracy: 0.7447\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2732 - accuracy: 0.8868 - val_loss: 0.6486 - val_accuracy: 0.7447\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 0s 960us/step - loss: 0.3156 - accuracy: 0.8868 - val_loss: 0.6464 - val_accuracy: 0.7660\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.2897 - accuracy: 0.8491 - val_loss: 0.6443 - val_accuracy: 0.7660\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.3135 - accuracy: 0.8302 - val_loss: 0.6420 - val_accuracy: 0.7660\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.2482 - accuracy: 0.9057 - val_loss: 0.6394 - val_accuracy: 0.7660\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 0s 846us/step - loss: 0.2843 - accuracy: 0.8868 - val_loss: 0.6371 - val_accuracy: 0.7447\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2795 - accuracy: 0.8868 - val_loss: 0.6348 - val_accuracy: 0.7447\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 0s 884us/step - loss: 0.3475 - accuracy: 0.9057 - val_loss: 0.6325 - val_accuracy: 0.7447\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.3137 - accuracy: 0.8679 - val_loss: 0.6302 - val_accuracy: 0.7447\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 0s 922us/step - loss: 0.2472 - accuracy: 0.9057 - val_loss: 0.6281 - val_accuracy: 0.7447\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.3048 - accuracy: 0.8302 - val_loss: 0.6263 - val_accuracy: 0.7447\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2633 - accuracy: 0.8679 - val_loss: 0.6250 - val_accuracy: 0.7447\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2560 - accuracy: 0.9057 - val_loss: 0.6238 - val_accuracy: 0.7447\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.3462 - accuracy: 0.8302 - val_loss: 0.6226 - val_accuracy: 0.7447\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.2966 - accuracy: 0.8679 - val_loss: 0.6212 - val_accuracy: 0.7447\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.1971 - accuracy: 0.9245 - val_loss: 0.6199 - val_accuracy: 0.7447\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2445 - accuracy: 0.9057 - val_loss: 0.6186 - val_accuracy: 0.7447\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2541 - accuracy: 0.8868 - val_loss: 0.6174 - val_accuracy: 0.7447\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 0s 979us/step - loss: 0.2931 - accuracy: 0.8491 - val_loss: 0.6163 - val_accuracy: 0.7447\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2592 - accuracy: 0.9057 - val_loss: 0.6151 - val_accuracy: 0.7447\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3097 - accuracy: 0.8679 - val_loss: 0.6141 - val_accuracy: 0.7447\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2853 - accuracy: 0.8868 - val_loss: 0.6130 - val_accuracy: 0.7447\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3272 - accuracy: 0.8302 - val_loss: 0.6119 - val_accuracy: 0.7447\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2979 - accuracy: 0.8679 - val_loss: 0.6108 - val_accuracy: 0.7447\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2887 - accuracy: 0.8868 - val_loss: 0.6098 - val_accuracy: 0.7447\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3201 - accuracy: 0.8868 - val_loss: 0.6087 - val_accuracy: 0.7447\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2571 - accuracy: 0.8868 - val_loss: 0.6077 - val_accuracy: 0.7447\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2776 - accuracy: 0.8679 - val_loss: 0.6066 - val_accuracy: 0.7447\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3459 - accuracy: 0.9057 - val_loss: 0.6055 - val_accuracy: 0.7447\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3081 - accuracy: 0.8868 - val_loss: 0.6046 - val_accuracy: 0.7447\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2563 - accuracy: 0.8491 - val_loss: 0.6037 - val_accuracy: 0.7447\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2482 - accuracy: 0.8868 - val_loss: 0.6027 - val_accuracy: 0.7447\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3171 - accuracy: 0.8679 - val_loss: 0.6016 - val_accuracy: 0.7447\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3498 - accuracy: 0.8302 - val_loss: 0.6005 - val_accuracy: 0.7447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2968 - accuracy: 0.8491 - val_loss: 0.5994 - val_accuracy: 0.7660\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2445 - accuracy: 0.9245 - val_loss: 0.5983 - val_accuracy: 0.7660\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2510 - accuracy: 0.9057 - val_loss: 0.5973 - val_accuracy: 0.7660\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2544 - accuracy: 0.9245 - val_loss: 0.5962 - val_accuracy: 0.7660\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3570 - accuracy: 0.8491 - val_loss: 0.5952 - val_accuracy: 0.7660\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3093 - accuracy: 0.8868 - val_loss: 0.5940 - val_accuracy: 0.7660\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2773 - accuracy: 0.8679 - val_loss: 0.5930 - val_accuracy: 0.7660\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2391 - accuracy: 0.9057 - val_loss: 0.5919 - val_accuracy: 0.7660\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3071 - accuracy: 0.8868 - val_loss: 0.5909 - val_accuracy: 0.7660\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2286 - accuracy: 0.9057 - val_loss: 0.5898 - val_accuracy: 0.7660\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2707 - accuracy: 0.8868 - val_loss: 0.5887 - val_accuracy: 0.7660\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3559 - accuracy: 0.8868 - val_loss: 0.5877 - val_accuracy: 0.7660\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2891 - accuracy: 0.9245 - val_loss: 0.5866 - val_accuracy: 0.7660\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3427 - accuracy: 0.8491 - val_loss: 0.5854 - val_accuracy: 0.7660\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2915 - accuracy: 0.8679 - val_loss: 0.5843 - val_accuracy: 0.7660\n",
      "Epoch 58/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2300 - accuracy: 0.8868 - val_loss: 0.5832 - val_accuracy: 0.7660\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2727 - accuracy: 0.9245 - val_loss: 0.5820 - val_accuracy: 0.7660\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3735 - accuracy: 0.8491 - val_loss: 0.5809 - val_accuracy: 0.7660\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2366 - accuracy: 0.9245 - val_loss: 0.5798 - val_accuracy: 0.7660\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2602 - accuracy: 0.8868 - val_loss: 0.5787 - val_accuracy: 0.7660\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2681 - accuracy: 0.9057 - val_loss: 0.5775 - val_accuracy: 0.7660\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3472 - accuracy: 0.8302 - val_loss: 0.5762 - val_accuracy: 0.7447\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2413 - accuracy: 0.8868 - val_loss: 0.5750 - val_accuracy: 0.7447\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3003 - accuracy: 0.9057 - val_loss: 0.5739 - val_accuracy: 0.7447\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3048 - accuracy: 0.8679 - val_loss: 0.5727 - val_accuracy: 0.7447\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2803 - accuracy: 0.8868 - val_loss: 0.5716 - val_accuracy: 0.7447\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3056 - accuracy: 0.8491 - val_loss: 0.5704 - val_accuracy: 0.7447\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2439 - accuracy: 0.9245 - val_loss: 0.5693 - val_accuracy: 0.7447\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3461 - accuracy: 0.8491 - val_loss: 0.5681 - val_accuracy: 0.7447\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2831 - accuracy: 0.8868 - val_loss: 0.5669 - val_accuracy: 0.7447\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3550 - accuracy: 0.8679 - val_loss: 0.5657 - val_accuracy: 0.7447\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2904 - accuracy: 0.8679 - val_loss: 0.5645 - val_accuracy: 0.7447\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2760 - accuracy: 0.8679 - val_loss: 0.5634 - val_accuracy: 0.7447\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3151 - accuracy: 0.8868 - val_loss: 0.5622 - val_accuracy: 0.7660\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4187 - accuracy: 0.8302 - val_loss: 0.5609 - val_accuracy: 0.7660\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2472 - accuracy: 0.8868 - val_loss: 0.5597 - val_accuracy: 0.7660\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3351 - accuracy: 0.8491 - val_loss: 0.5585 - val_accuracy: 0.7660\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2568 - accuracy: 0.8679 - val_loss: 0.5573 - val_accuracy: 0.7660\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.2306 - accuracy: 0.9057 - val_loss: 0.5561 - val_accuracy: 0.7660\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2952 - accuracy: 0.8868 - val_loss: 0.5548 - val_accuracy: 0.7660\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2712 - accuracy: 0.8679 - val_loss: 0.5537 - val_accuracy: 0.7660\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2831 - accuracy: 0.8868 - val_loss: 0.5525 - val_accuracy: 0.7660\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2541 - accuracy: 0.9057 - val_loss: 0.5514 - val_accuracy: 0.7872\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2815 - accuracy: 0.8679 - val_loss: 0.5502 - val_accuracy: 0.7660\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2670 - accuracy: 0.8491 - val_loss: 0.5490 - val_accuracy: 0.7660\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2672 - accuracy: 0.8868 - val_loss: 0.5479 - val_accuracy: 0.7872\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 0s 752us/step - loss: 0.3290 - accuracy: 0.8679 - val_loss: 0.5467 - val_accuracy: 0.7872\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2721 - accuracy: 0.8868 - val_loss: 0.5455 - val_accuracy: 0.7872\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2697 - accuracy: 0.8679 - val_loss: 0.5443 - val_accuracy: 0.7872\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2334 - accuracy: 0.9057 - val_loss: 0.5431 - val_accuracy: 0.7872\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 0s 959us/step - loss: 0.4415 - accuracy: 0.7736 - val_loss: 0.5419 - val_accuracy: 0.7872\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2922 - accuracy: 0.8679 - val_loss: 0.5406 - val_accuracy: 0.7872\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2494 - accuracy: 0.8868 - val_loss: 0.5394 - val_accuracy: 0.7872\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3281 - accuracy: 0.9057 - val_loss: 0.5381 - val_accuracy: 0.7872\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3279 - accuracy: 0.8868 - val_loss: 0.5368 - val_accuracy: 0.7872\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2850 - accuracy: 0.8679 - val_loss: 0.5356 - val_accuracy: 0.7872\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.3454 - accuracy: 0.8491 - val_loss: 0.5344 - val_accuracy: 0.7872\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3251 - accuracy: 0.8868 - val_loss: 0.5332 - val_accuracy: 0.7872\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3000 - accuracy: 0.9057 - val_loss: 0.5319 - val_accuracy: 0.7872\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2707 - accuracy: 0.8868 - val_loss: 0.5306 - val_accuracy: 0.7872\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2508 - accuracy: 0.9245 - val_loss: 0.5295 - val_accuracy: 0.7872\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2923 - accuracy: 0.8868 - val_loss: 0.5282 - val_accuracy: 0.7872\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2722 - accuracy: 0.9057 - val_loss: 0.5270 - val_accuracy: 0.7872\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2694 - accuracy: 0.9057 - val_loss: 0.5258 - val_accuracy: 0.7872\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2501 - accuracy: 0.9057 - val_loss: 0.5246 - val_accuracy: 0.7872\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2525 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7872\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2468 - accuracy: 0.8679 - val_loss: 0.5223 - val_accuracy: 0.7872\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2518 - accuracy: 0.8868 - val_loss: 0.5211 - val_accuracy: 0.7872\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3397 - accuracy: 0.8868 - val_loss: 0.5199 - val_accuracy: 0.7872\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2650 - accuracy: 0.9057 - val_loss: 0.5187 - val_accuracy: 0.7872\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3542 - accuracy: 0.8491 - val_loss: 0.5175 - val_accuracy: 0.7872\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3270 - accuracy: 0.8491 - val_loss: 0.5164 - val_accuracy: 0.7872\n",
      "Epoch 115/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2637 - accuracy: 0.8868 - val_loss: 0.5151 - val_accuracy: 0.7872\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2844 - accuracy: 0.9057 - val_loss: 0.5139 - val_accuracy: 0.8085\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3136 - accuracy: 0.8113 - val_loss: 0.5126 - val_accuracy: 0.8085\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2625 - accuracy: 0.8679 - val_loss: 0.5116 - val_accuracy: 0.8085\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2435 - accuracy: 0.9057 - val_loss: 0.5102 - val_accuracy: 0.8085\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2086 - accuracy: 0.8868 - val_loss: 0.5090 - val_accuracy: 0.8085\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3147 - accuracy: 0.8679 - val_loss: 0.5078 - val_accuracy: 0.8085\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2611 - accuracy: 0.8868 - val_loss: 0.5066 - val_accuracy: 0.8085\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3050 - accuracy: 0.8491 - val_loss: 0.5053 - val_accuracy: 0.8085\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2262 - accuracy: 0.9057 - val_loss: 0.5040 - val_accuracy: 0.8085\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2853 - accuracy: 0.8679 - val_loss: 0.5028 - val_accuracy: 0.8085\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3332 - accuracy: 0.8868 - val_loss: 0.5017 - val_accuracy: 0.8085\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2733 - accuracy: 0.8868 - val_loss: 0.5006 - val_accuracy: 0.8085\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2898 - accuracy: 0.8868 - val_loss: 0.4994 - val_accuracy: 0.8085\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.2813 - accuracy: 0.9057 - val_loss: 0.4982 - val_accuracy: 0.8085\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 0s 811us/step - loss: 0.2895 - accuracy: 0.8868 - val_loss: 0.4970 - val_accuracy: 0.8085\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2247 - accuracy: 0.9245 - val_loss: 0.4959 - val_accuracy: 0.8085\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2743 - accuracy: 0.8679 - val_loss: 0.4948 - val_accuracy: 0.8085\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2948 - accuracy: 0.9057 - val_loss: 0.4936 - val_accuracy: 0.8085\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3420 - accuracy: 0.8868 - val_loss: 0.4924 - val_accuracy: 0.8085\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2949 - accuracy: 0.8868 - val_loss: 0.4914 - val_accuracy: 0.8085\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3094 - accuracy: 0.8491 - val_loss: 0.4903 - val_accuracy: 0.8085\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3178 - accuracy: 0.8679 - val_loss: 0.4891 - val_accuracy: 0.8085\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3485 - accuracy: 0.8302 - val_loss: 0.4879 - val_accuracy: 0.8085\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2832 - accuracy: 0.8868 - val_loss: 0.4868 - val_accuracy: 0.8085\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2670 - accuracy: 0.8868 - val_loss: 0.4857 - val_accuracy: 0.8085\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2625 - accuracy: 0.9057 - val_loss: 0.4847 - val_accuracy: 0.8085\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2696 - accuracy: 0.8679 - val_loss: 0.4836 - val_accuracy: 0.8085\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2773 - accuracy: 0.8679 - val_loss: 0.4826 - val_accuracy: 0.8085\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2593 - accuracy: 0.9245 - val_loss: 0.4815 - val_accuracy: 0.8085\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2971 - accuracy: 0.8679 - val_loss: 0.4804 - val_accuracy: 0.8085\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2578 - accuracy: 0.9057 - val_loss: 0.4795 - val_accuracy: 0.8085\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2915 - accuracy: 0.8679 - val_loss: 0.4784 - val_accuracy: 0.8085\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3285 - accuracy: 0.8302 - val_loss: 0.4774 - val_accuracy: 0.8085\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2720 - accuracy: 0.8679 - val_loss: 0.4765 - val_accuracy: 0.8085\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2806 - accuracy: 0.8679 - val_loss: 0.4754 - val_accuracy: 0.8085\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3690 - accuracy: 0.8679 - val_loss: 0.4743 - val_accuracy: 0.8085\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2417 - accuracy: 0.8679 - val_loss: 0.4733 - val_accuracy: 0.8085\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2788 - accuracy: 0.8868 - val_loss: 0.4723 - val_accuracy: 0.8085\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2824 - accuracy: 0.8679 - val_loss: 0.4712 - val_accuracy: 0.8085\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 790us/step - loss: 0.3218 - accuracy: 0.8302 - val_loss: 0.4702 - val_accuracy: 0.8085\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2940 - accuracy: 0.8302 - val_loss: 0.4692 - val_accuracy: 0.8085\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2943 - accuracy: 0.8868 - val_loss: 0.4683 - val_accuracy: 0.8085\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2097 - accuracy: 0.9057 - val_loss: 0.4674 - val_accuracy: 0.8085\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3128 - accuracy: 0.8868 - val_loss: 0.4665 - val_accuracy: 0.8085\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2835 - accuracy: 0.9057 - val_loss: 0.4656 - val_accuracy: 0.8085\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2631 - accuracy: 0.9057 - val_loss: 0.4648 - val_accuracy: 0.8085\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2805 - accuracy: 0.9245 - val_loss: 0.4639 - val_accuracy: 0.8085\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3039 - accuracy: 0.8868 - val_loss: 0.4629 - val_accuracy: 0.8085\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3392 - accuracy: 0.8679 - val_loss: 0.4621 - val_accuracy: 0.8085\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2789 - accuracy: 0.8679 - val_loss: 0.4614 - val_accuracy: 0.8085\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2772 - accuracy: 0.9245 - val_loss: 0.4606 - val_accuracy: 0.8085\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3178 - accuracy: 0.8679 - val_loss: 0.4599 - val_accuracy: 0.8085\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2419 - accuracy: 0.9057 - val_loss: 0.4591 - val_accuracy: 0.8085\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2930 - accuracy: 0.8491 - val_loss: 0.4584 - val_accuracy: 0.8085\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3326 - accuracy: 0.8679 - val_loss: 0.4575 - val_accuracy: 0.8085\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2615 - accuracy: 0.8679 - val_loss: 0.4569 - val_accuracy: 0.8085\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2208 - accuracy: 0.8679 - val_loss: 0.4563 - val_accuracy: 0.7872\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3225 - accuracy: 0.8868 - val_loss: 0.4556 - val_accuracy: 0.7872\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2626 - accuracy: 0.9057 - val_loss: 0.4549 - val_accuracy: 0.7872\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2618 - accuracy: 0.8868 - val_loss: 0.4543 - val_accuracy: 0.7872\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2821 - accuracy: 0.8679 - val_loss: 0.4536 - val_accuracy: 0.7872\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2681 - accuracy: 0.9057 - val_loss: 0.4529 - val_accuracy: 0.7872\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2830 - accuracy: 0.9057 - val_loss: 0.4521 - val_accuracy: 0.7872\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3107 - accuracy: 0.9057 - val_loss: 0.4515 - val_accuracy: 0.7872\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3122 - accuracy: 0.9057 - val_loss: 0.4510 - val_accuracy: 0.7872\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2871 - accuracy: 0.8868 - val_loss: 0.4503 - val_accuracy: 0.7872\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2670 - accuracy: 0.8868 - val_loss: 0.4496 - val_accuracy: 0.7872\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2604 - accuracy: 0.8679 - val_loss: 0.4490 - val_accuracy: 0.7872\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2940 - accuracy: 0.8679 - val_loss: 0.4486 - val_accuracy: 0.7872\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3029 - accuracy: 0.8868 - val_loss: 0.4480 - val_accuracy: 0.7872\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.4101 - accuracy: 0.8113 - val_loss: 0.4473 - val_accuracy: 0.7872\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3189 - accuracy: 0.8679 - val_loss: 0.4469 - val_accuracy: 0.7872\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3195 - accuracy: 0.8679 - val_loss: 0.4463 - val_accuracy: 0.7872\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3819 - accuracy: 0.8491 - val_loss: 0.4456 - val_accuracy: 0.7872\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2446 - accuracy: 0.8868 - val_loss: 0.4451 - val_accuracy: 0.7872\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2241 - accuracy: 0.9245 - val_loss: 0.4446 - val_accuracy: 0.7872\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3242 - accuracy: 0.8868 - val_loss: 0.4441 - val_accuracy: 0.7872\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2896 - accuracy: 0.8679 - val_loss: 0.4438 - val_accuracy: 0.7872\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3252 - accuracy: 0.8491 - val_loss: 0.4429 - val_accuracy: 0.7872\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2691 - accuracy: 0.8868 - val_loss: 0.4424 - val_accuracy: 0.7872\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3316 - accuracy: 0.8679 - val_loss: 0.4418 - val_accuracy: 0.7872\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2868 - accuracy: 0.8679 - val_loss: 0.4415 - val_accuracy: 0.7872\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2936 - accuracy: 0.8491 - val_loss: 0.4412 - val_accuracy: 0.7872\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2842 - accuracy: 0.8679 - val_loss: 0.4410 - val_accuracy: 0.7872\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2558 - accuracy: 0.9245 - val_loss: 0.4407 - val_accuracy: 0.7872\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2675 - accuracy: 0.9057 - val_loss: 0.4405 - val_accuracy: 0.7872\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3119 - accuracy: 0.8868 - val_loss: 0.4402 - val_accuracy: 0.7872\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2562 - accuracy: 0.9057 - val_loss: 0.4398 - val_accuracy: 0.7872\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3098 - accuracy: 0.8491 - val_loss: 0.4396 - val_accuracy: 0.7872\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2703 - accuracy: 0.9057 - val_loss: 0.4393 - val_accuracy: 0.7872\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3767 - accuracy: 0.8679 - val_loss: 0.4388 - val_accuracy: 0.7872\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.4387 - val_accuracy: 0.7872\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2207 - accuracy: 0.9245 - val_loss: 0.4383 - val_accuracy: 0.7872\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2597 - accuracy: 0.9057 - val_loss: 0.4380 - val_accuracy: 0.7872\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3665 - accuracy: 0.8302 - val_loss: 0.4380 - val_accuracy: 0.7872\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.2506 - accuracy: 0.8868 - val_loss: 0.4382 - val_accuracy: 0.7872\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2653 - accuracy: 0.9245 - val_loss: 0.4381 - val_accuracy: 0.7872\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3196 - accuracy: 0.8491 - val_loss: 0.4380 - val_accuracy: 0.7872\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2525 - accuracy: 0.9245 - val_loss: 0.4378 - val_accuracy: 0.7872\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3065 - accuracy: 0.9057 - val_loss: 0.4376 - val_accuracy: 0.7872\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3793 - accuracy: 0.8302 - val_loss: 0.4378 - val_accuracy: 0.7872\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3142 - accuracy: 0.8302 - val_loss: 0.4377 - val_accuracy: 0.7872\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2596 - accuracy: 0.8679 - val_loss: 0.4379 - val_accuracy: 0.7872\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3511 - accuracy: 0.8302 - val_loss: 0.4376 - val_accuracy: 0.7872\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2607 - accuracy: 0.8868 - val_loss: 0.4375 - val_accuracy: 0.7872\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2580 - accuracy: 0.8868 - val_loss: 0.4374 - val_accuracy: 0.7872\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3164 - accuracy: 0.8679 - val_loss: 0.4375 - val_accuracy: 0.7872\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3210 - accuracy: 0.8868 - val_loss: 0.4375 - val_accuracy: 0.7872\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3034 - accuracy: 0.8679 - val_loss: 0.4374 - val_accuracy: 0.7872\n",
      "Epoch 225/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2801 - accuracy: 0.9057 - val_loss: 0.4374 - val_accuracy: 0.7872\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2341 - accuracy: 0.8868 - val_loss: 0.4375 - val_accuracy: 0.7872\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2593 - accuracy: 0.8491 - val_loss: 0.4374 - val_accuracy: 0.7872\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2575 - accuracy: 0.8491 - val_loss: 0.4375 - val_accuracy: 0.7872\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 0s 697us/step - loss: 0.3184 - accuracy: 0.9057 - val_loss: 0.4378 - val_accuracy: 0.7872\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2841 - accuracy: 0.8868 - val_loss: 0.4379 - val_accuracy: 0.7872\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3034 - accuracy: 0.8868 - val_loss: 0.4380 - val_accuracy: 0.7872\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2695 - accuracy: 0.8868 - val_loss: 0.4384 - val_accuracy: 0.7872\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3451 - accuracy: 0.8491 - val_loss: 0.4389 - val_accuracy: 0.7872\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2356 - accuracy: 0.9057 - val_loss: 0.4393 - val_accuracy: 0.7872\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3085 - accuracy: 0.8491 - val_loss: 0.4394 - val_accuracy: 0.7872\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2958 - accuracy: 0.8679 - val_loss: 0.4395 - val_accuracy: 0.7872\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3509 - accuracy: 0.8491 - val_loss: 0.4398 - val_accuracy: 0.7872\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3808 - accuracy: 0.8868 - val_loss: 0.4398 - val_accuracy: 0.7872\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3121 - accuracy: 0.8679 - val_loss: 0.4401 - val_accuracy: 0.7872\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2772 - accuracy: 0.8679 - val_loss: 0.4402 - val_accuracy: 0.7872\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3990 - accuracy: 0.8302 - val_loss: 0.4413 - val_accuracy: 0.7660\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3107 - accuracy: 0.8679 - val_loss: 0.4416 - val_accuracy: 0.7660\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2924 - accuracy: 0.8868 - val_loss: 0.4418 - val_accuracy: 0.7660\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.4420 - val_accuracy: 0.7660\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2720 - accuracy: 0.8679 - val_loss: 0.4424 - val_accuracy: 0.7660\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2207 - accuracy: 0.9057 - val_loss: 0.4427 - val_accuracy: 0.7660\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2730 - accuracy: 0.8679 - val_loss: 0.4429 - val_accuracy: 0.7660\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3911 - accuracy: 0.8491 - val_loss: 0.4430 - val_accuracy: 0.7660\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3049 - accuracy: 0.9057 - val_loss: 0.4434 - val_accuracy: 0.7660\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2646 - accuracy: 0.8868 - val_loss: 0.4437 - val_accuracy: 0.7660\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3661 - accuracy: 0.8679 - val_loss: 0.4438 - val_accuracy: 0.7660\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2775 - accuracy: 0.9245 - val_loss: 0.4443 - val_accuracy: 0.7660\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4209 - accuracy: 0.8302 - val_loss: 0.4450 - val_accuracy: 0.7660\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2897 - accuracy: 0.9057 - val_loss: 0.4453 - val_accuracy: 0.7660\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2746 - accuracy: 0.8868 - val_loss: 0.4460 - val_accuracy: 0.7660\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3027 - accuracy: 0.8868 - val_loss: 0.4462 - val_accuracy: 0.7660\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2838 - accuracy: 0.9057 - val_loss: 0.4467 - val_accuracy: 0.7660\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2517 - accuracy: 0.8868 - val_loss: 0.4473 - val_accuracy: 0.7660\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2153 - accuracy: 0.9245 - val_loss: 0.4478 - val_accuracy: 0.7660\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3354 - accuracy: 0.8302 - val_loss: 0.4483 - val_accuracy: 0.7660\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2842 - accuracy: 0.9057 - val_loss: 0.4485 - val_accuracy: 0.7660\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2372 - accuracy: 0.8868 - val_loss: 0.4491 - val_accuracy: 0.7660\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2735 - accuracy: 0.8868 - val_loss: 0.4498 - val_accuracy: 0.7660\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2408 - accuracy: 0.8868 - val_loss: 0.4502 - val_accuracy: 0.7660\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2866 - accuracy: 0.8679 - val_loss: 0.4505 - val_accuracy: 0.7660\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2867 - accuracy: 0.9245 - val_loss: 0.4513 - val_accuracy: 0.7660\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.2377 - accuracy: 0.8868 - val_loss: 0.4519 - val_accuracy: 0.7660\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2685 - accuracy: 0.9057 - val_loss: 0.4524 - val_accuracy: 0.7660\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3068 - accuracy: 0.9057 - val_loss: 0.4530 - val_accuracy: 0.7660\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2929 - accuracy: 0.8868 - val_loss: 0.4535 - val_accuracy: 0.7660\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 0s 740us/step - loss: 0.3058 - accuracy: 0.8491 - val_loss: 0.4541 - val_accuracy: 0.7660\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2629 - accuracy: 0.8868 - val_loss: 0.4545 - val_accuracy: 0.7660\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2982 - accuracy: 0.8868 - val_loss: 0.4554 - val_accuracy: 0.7660\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2857 - accuracy: 0.9057 - val_loss: 0.4560 - val_accuracy: 0.7660\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2400 - accuracy: 0.8868 - val_loss: 0.4566 - val_accuracy: 0.7660\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2546 - accuracy: 0.9057 - val_loss: 0.4576 - val_accuracy: 0.7660\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2541 - accuracy: 0.9245 - val_loss: 0.4583 - val_accuracy: 0.7660\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2985 - accuracy: 0.8868 - val_loss: 0.4584 - val_accuracy: 0.7660\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3852 - accuracy: 0.8491 - val_loss: 0.4589 - val_accuracy: 0.7660\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1721 - accuracy: 0.9434 - val_loss: 0.4590 - val_accuracy: 0.7660\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3373 - accuracy: 0.7925 - val_loss: 0.4601 - val_accuracy: 0.7660\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2715 - accuracy: 0.8679 - val_loss: 0.4609 - val_accuracy: 0.7660\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2835 - accuracy: 0.9057 - val_loss: 0.4613 - val_accuracy: 0.7660\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 0s 773us/step - loss: 0.2677 - accuracy: 0.8868 - val_loss: 0.4621 - val_accuracy: 0.7660\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3068 - accuracy: 0.8868 - val_loss: 0.4624 - val_accuracy: 0.7660\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2528 - accuracy: 0.8868 - val_loss: 0.4630 - val_accuracy: 0.7660\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3875 - accuracy: 0.8491 - val_loss: 0.4633 - val_accuracy: 0.7660\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.4641 - val_accuracy: 0.7660\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3080 - accuracy: 0.8679 - val_loss: 0.4646 - val_accuracy: 0.7660\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2555 - accuracy: 0.9245 - val_loss: 0.4658 - val_accuracy: 0.7660\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3038 - accuracy: 0.8491 - val_loss: 0.4667 - val_accuracy: 0.7660\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2680 - accuracy: 0.8679 - val_loss: 0.4673 - val_accuracy: 0.7660\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2478 - accuracy: 0.9057 - val_loss: 0.4683 - val_accuracy: 0.7660\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2701 - accuracy: 0.9057 - val_loss: 0.4688 - val_accuracy: 0.7660\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2937 - accuracy: 0.8868 - val_loss: 0.4694 - val_accuracy: 0.7660\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2916 - accuracy: 0.9057 - val_loss: 0.4696 - val_accuracy: 0.7660\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2925 - accuracy: 0.8491 - val_loss: 0.4705 - val_accuracy: 0.7660\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2642 - accuracy: 0.9245 - val_loss: 0.4713 - val_accuracy: 0.7660\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2422 - accuracy: 0.9057 - val_loss: 0.4722 - val_accuracy: 0.7660\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2628 - accuracy: 0.9057 - val_loss: 0.4726 - val_accuracy: 0.7660\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2714 - accuracy: 0.8868 - val_loss: 0.4731 - val_accuracy: 0.7660\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2890 - accuracy: 0.8679 - val_loss: 0.4744 - val_accuracy: 0.7660\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2731 - accuracy: 0.8868 - val_loss: 0.4747 - val_accuracy: 0.7660\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2843 - accuracy: 0.9057 - val_loss: 0.4751 - val_accuracy: 0.7660\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3164 - accuracy: 0.8491 - val_loss: 0.4757 - val_accuracy: 0.7660\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3038 - accuracy: 0.8679 - val_loss: 0.4767 - val_accuracy: 0.7660\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2782 - accuracy: 0.8679 - val_loss: 0.4770 - val_accuracy: 0.7660\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3395 - accuracy: 0.8679 - val_loss: 0.4776 - val_accuracy: 0.7660\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2806 - accuracy: 0.8868 - val_loss: 0.4781 - val_accuracy: 0.7660\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2702 - accuracy: 0.9245 - val_loss: 0.4790 - val_accuracy: 0.7660\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2870 - accuracy: 0.8679 - val_loss: 0.4803 - val_accuracy: 0.7660\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2760 - accuracy: 0.8868 - val_loss: 0.4805 - val_accuracy: 0.7660\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2840 - accuracy: 0.8868 - val_loss: 0.4811 - val_accuracy: 0.7660\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2841 - accuracy: 0.8491 - val_loss: 0.4816 - val_accuracy: 0.7660\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2881 - accuracy: 0.8302 - val_loss: 0.4822 - val_accuracy: 0.7660\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2426 - accuracy: 0.9245 - val_loss: 0.4826 - val_accuracy: 0.7660\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 0s 869us/step - loss: 0.2008 - accuracy: 0.9057 - val_loss: 0.4832 - val_accuracy: 0.7660\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3007 - accuracy: 0.9057 - val_loss: 0.4831 - val_accuracy: 0.7660\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2613 - accuracy: 0.8679 - val_loss: 0.4839 - val_accuracy: 0.7660\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2194 - accuracy: 0.9245 - val_loss: 0.4844 - val_accuracy: 0.7660\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3078 - accuracy: 0.8491 - val_loss: 0.4850 - val_accuracy: 0.7660\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2731 - accuracy: 0.8868 - val_loss: 0.4852 - val_accuracy: 0.7660\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.2722 - accuracy: 0.8868 - val_loss: 0.4856 - val_accuracy: 0.7660\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2752 - accuracy: 0.8679 - val_loss: 0.4862 - val_accuracy: 0.7660\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3274 - accuracy: 0.8868 - val_loss: 0.4867 - val_accuracy: 0.7660\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2523 - accuracy: 0.8868 - val_loss: 0.4870 - val_accuracy: 0.7660\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2849 - accuracy: 0.8868 - val_loss: 0.4875 - val_accuracy: 0.7660\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2708 - accuracy: 0.8491 - val_loss: 0.4880 - val_accuracy: 0.7660\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2999 - accuracy: 0.8868 - val_loss: 0.4892 - val_accuracy: 0.7660\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2722 - accuracy: 0.8868 - val_loss: 0.4896 - val_accuracy: 0.7660\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2657 - accuracy: 0.8679 - val_loss: 0.4907 - val_accuracy: 0.7660\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3122 - accuracy: 0.8491 - val_loss: 0.4912 - val_accuracy: 0.7660\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2913 - accuracy: 0.8679 - val_loss: 0.4911 - val_accuracy: 0.7660\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3600 - accuracy: 0.8868 - val_loss: 0.4915 - val_accuracy: 0.7660\n",
      "Epoch 335/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2932 - accuracy: 0.8868 - val_loss: 0.4920 - val_accuracy: 0.7660\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2504 - accuracy: 0.9057 - val_loss: 0.4927 - val_accuracy: 0.7660\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2850 - accuracy: 0.8679 - val_loss: 0.4930 - val_accuracy: 0.7660\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3096 - accuracy: 0.8868 - val_loss: 0.4935 - val_accuracy: 0.7660\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2347 - accuracy: 0.9057 - val_loss: 0.4942 - val_accuracy: 0.7660\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3374 - accuracy: 0.9057 - val_loss: 0.4952 - val_accuracy: 0.7660\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3318 - accuracy: 0.8679 - val_loss: 0.4954 - val_accuracy: 0.7660\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2634 - accuracy: 0.9057 - val_loss: 0.4954 - val_accuracy: 0.7660\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2856 - accuracy: 0.8679 - val_loss: 0.4957 - val_accuracy: 0.7660\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2493 - accuracy: 0.8491 - val_loss: 0.4968 - val_accuracy: 0.7660\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2846 - accuracy: 0.8868 - val_loss: 0.4975 - val_accuracy: 0.7660\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2232 - accuracy: 0.8679 - val_loss: 0.4983 - val_accuracy: 0.7660\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3303 - accuracy: 0.8679 - val_loss: 0.4992 - val_accuracy: 0.7660\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3335 - accuracy: 0.8491 - val_loss: 0.4999 - val_accuracy: 0.7660\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4008 - accuracy: 0.8302 - val_loss: 0.5007 - val_accuracy: 0.7660\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3275 - accuracy: 0.8679 - val_loss: 0.5005 - val_accuracy: 0.7660\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2985 - accuracy: 0.8679 - val_loss: 0.5013 - val_accuracy: 0.7660\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2738 - accuracy: 0.8868 - val_loss: 0.5018 - val_accuracy: 0.7660\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2983 - accuracy: 0.8679 - val_loss: 0.5024 - val_accuracy: 0.7660\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3156 - accuracy: 0.8679 - val_loss: 0.5027 - val_accuracy: 0.7660\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3181 - accuracy: 0.8491 - val_loss: 0.5028 - val_accuracy: 0.7660\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3322 - accuracy: 0.8491 - val_loss: 0.5036 - val_accuracy: 0.7660\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3135 - accuracy: 0.8302 - val_loss: 0.5038 - val_accuracy: 0.7660\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2497 - accuracy: 0.8868 - val_loss: 0.5045 - val_accuracy: 0.7660\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3225 - accuracy: 0.8679 - val_loss: 0.5053 - val_accuracy: 0.7660\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2924 - accuracy: 0.8302 - val_loss: 0.5065 - val_accuracy: 0.7660\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3121 - accuracy: 0.9057 - val_loss: 0.5065 - val_accuracy: 0.7660\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2835 - accuracy: 0.9245 - val_loss: 0.5070 - val_accuracy: 0.7660\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3375 - accuracy: 0.8491 - val_loss: 0.5073 - val_accuracy: 0.7660\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2905 - accuracy: 0.8302 - val_loss: 0.5071 - val_accuracy: 0.7660\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2289 - accuracy: 0.9245 - val_loss: 0.5070 - val_accuracy: 0.7660\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2845 - accuracy: 0.8868 - val_loss: 0.5069 - val_accuracy: 0.7660\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2932 - accuracy: 0.8491 - val_loss: 0.5066 - val_accuracy: 0.7660\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2685 - accuracy: 0.8868 - val_loss: 0.5062 - val_accuracy: 0.7660\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3115 - accuracy: 0.8491 - val_loss: 0.5069 - val_accuracy: 0.7660\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3160 - accuracy: 0.8491 - val_loss: 0.5072 - val_accuracy: 0.7660\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2941 - accuracy: 0.8491 - val_loss: 0.5077 - val_accuracy: 0.7660\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2536 - accuracy: 0.8679 - val_loss: 0.5083 - val_accuracy: 0.7660\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2714 - accuracy: 0.8868 - val_loss: 0.5092 - val_accuracy: 0.7660\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2837 - accuracy: 0.8679 - val_loss: 0.5099 - val_accuracy: 0.7660\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2382 - accuracy: 0.9057 - val_loss: 0.5101 - val_accuracy: 0.7660\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3112 - accuracy: 0.8679 - val_loss: 0.5106 - val_accuracy: 0.7660\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.5106 - val_accuracy: 0.7660\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2911 - accuracy: 0.8679 - val_loss: 0.5109 - val_accuracy: 0.7660\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.3079 - accuracy: 0.9057 - val_loss: 0.5108 - val_accuracy: 0.7660\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2809 - accuracy: 0.9245 - val_loss: 0.5112 - val_accuracy: 0.7660\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2964 - accuracy: 0.8679 - val_loss: 0.5113 - val_accuracy: 0.7660\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2809 - accuracy: 0.8868 - val_loss: 0.5112 - val_accuracy: 0.7660\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2663 - accuracy: 0.8868 - val_loss: 0.5109 - val_accuracy: 0.7660\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2664 - accuracy: 0.8679 - val_loss: 0.5111 - val_accuracy: 0.7660\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2475 - accuracy: 0.9057 - val_loss: 0.5111 - val_accuracy: 0.7660\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3088 - accuracy: 0.8679 - val_loss: 0.5110 - val_accuracy: 0.7660\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3619 - accuracy: 0.8302 - val_loss: 0.5109 - val_accuracy: 0.7660\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3510 - accuracy: 0.9057 - val_loss: 0.5107 - val_accuracy: 0.7660\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2934 - accuracy: 0.9057 - val_loss: 0.5106 - val_accuracy: 0.7660\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2567 - accuracy: 0.8868 - val_loss: 0.5113 - val_accuracy: 0.7660\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2902 - accuracy: 0.8868 - val_loss: 0.5111 - val_accuracy: 0.7660\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2959 - accuracy: 0.8679 - val_loss: 0.5112 - val_accuracy: 0.7660\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2178 - accuracy: 0.9245 - val_loss: 0.5118 - val_accuracy: 0.7660\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2273 - accuracy: 0.9057 - val_loss: 0.5120 - val_accuracy: 0.7660\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2550 - accuracy: 0.8679 - val_loss: 0.5125 - val_accuracy: 0.7660\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2777 - accuracy: 0.8868 - val_loss: 0.5121 - val_accuracy: 0.7660\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3610 - accuracy: 0.8302 - val_loss: 0.5119 - val_accuracy: 0.7660\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3321 - accuracy: 0.8679 - val_loss: 0.5116 - val_accuracy: 0.7660\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2557 - accuracy: 0.9057 - val_loss: 0.5112 - val_accuracy: 0.7660\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 0s 747us/step - loss: 0.2179 - accuracy: 0.9245 - val_loss: 0.5116 - val_accuracy: 0.7660\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 0s 716us/step - loss: 0.2480 - accuracy: 0.9057 - val_loss: 0.5126 - val_accuracy: 0.7660\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2787 - accuracy: 0.8868 - val_loss: 0.5130 - val_accuracy: 0.7660\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2758 - accuracy: 0.8491 - val_loss: 0.5136 - val_accuracy: 0.7660\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2881 - accuracy: 0.8868 - val_loss: 0.5140 - val_accuracy: 0.7660\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2977 - accuracy: 0.8679 - val_loss: 0.5141 - val_accuracy: 0.7660\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2823 - accuracy: 0.8868 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2780 - accuracy: 0.8868 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2706 - accuracy: 0.8679 - val_loss: 0.5146 - val_accuracy: 0.7660\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2849 - accuracy: 0.8868 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3322 - accuracy: 0.8491 - val_loss: 0.5145 - val_accuracy: 0.7660\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2440 - accuracy: 0.9057 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2981 - accuracy: 0.8491 - val_loss: 0.5150 - val_accuracy: 0.7660\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2659 - accuracy: 0.9057 - val_loss: 0.5149 - val_accuracy: 0.7660\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3068 - accuracy: 0.9057 - val_loss: 0.5153 - val_accuracy: 0.7660\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2809 - accuracy: 0.8679 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2550 - accuracy: 0.8868 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2798 - accuracy: 0.9057 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2974 - accuracy: 0.8868 - val_loss: 0.5151 - val_accuracy: 0.7660\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2234 - accuracy: 0.8868 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2426 - accuracy: 0.8679 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2678 - accuracy: 0.8868 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2545 - accuracy: 0.9057 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3050 - accuracy: 0.8868 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3220 - accuracy: 0.8868 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3096 - accuracy: 0.8868 - val_loss: 0.5154 - val_accuracy: 0.7660\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3282 - accuracy: 0.8302 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2439 - accuracy: 0.9057 - val_loss: 0.5156 - val_accuracy: 0.7660\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3377 - accuracy: 0.8302 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2962 - accuracy: 0.8679 - val_loss: 0.5157 - val_accuracy: 0.7660\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3522 - accuracy: 0.8868 - val_loss: 0.5156 - val_accuracy: 0.7660\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2938 - accuracy: 0.8868 - val_loss: 0.5159 - val_accuracy: 0.7660\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2289 - accuracy: 0.8868 - val_loss: 0.5161 - val_accuracy: 0.7660\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2644 - accuracy: 0.9057 - val_loss: 0.5157 - val_accuracy: 0.7660\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2913 - accuracy: 0.8679 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 435/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 809us/step - loss: 0.2954 - accuracy: 0.8679 - val_loss: 0.5155 - val_accuracy: 0.7660\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2784 - accuracy: 0.8491 - val_loss: 0.5150 - val_accuracy: 0.7660\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2539 - accuracy: 0.9245 - val_loss: 0.5152 - val_accuracy: 0.7660\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3148 - accuracy: 0.8302 - val_loss: 0.5156 - val_accuracy: 0.7660\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2657 - accuracy: 0.8679 - val_loss: 0.5162 - val_accuracy: 0.7660\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3139 - accuracy: 0.8679 - val_loss: 0.5161 - val_accuracy: 0.7660\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2564 - accuracy: 0.9057 - val_loss: 0.5163 - val_accuracy: 0.7660\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2574 - accuracy: 0.9057 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2489 - accuracy: 0.9245 - val_loss: 0.5169 - val_accuracy: 0.7660\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3030 - accuracy: 0.8868 - val_loss: 0.5166 - val_accuracy: 0.7660\n",
      "Epoch 445/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2449 - accuracy: 0.9057 - val_loss: 0.5165 - val_accuracy: 0.7660\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2351 - accuracy: 0.8679 - val_loss: 0.5165 - val_accuracy: 0.7660\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2812 - accuracy: 0.8868 - val_loss: 0.5172 - val_accuracy: 0.7660\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3087 - accuracy: 0.9057 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2796 - accuracy: 0.9057 - val_loss: 0.5181 - val_accuracy: 0.7660\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2339 - accuracy: 0.9057 - val_loss: 0.5178 - val_accuracy: 0.7660\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3367 - accuracy: 0.8679 - val_loss: 0.5175 - val_accuracy: 0.7660\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2996 - accuracy: 0.8679 - val_loss: 0.5170 - val_accuracy: 0.7660\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3186 - accuracy: 0.8868 - val_loss: 0.5173 - val_accuracy: 0.7660\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2729 - accuracy: 0.8679 - val_loss: 0.5175 - val_accuracy: 0.7660\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2612 - accuracy: 0.9057 - val_loss: 0.5171 - val_accuracy: 0.7660\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2692 - accuracy: 0.9057 - val_loss: 0.5167 - val_accuracy: 0.7660\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2535 - accuracy: 0.8868 - val_loss: 0.5173 - val_accuracy: 0.7660\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2804 - accuracy: 0.9057 - val_loss: 0.5181 - val_accuracy: 0.7660\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2302 - accuracy: 0.9434 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2303 - accuracy: 0.9057 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2526 - accuracy: 0.9245 - val_loss: 0.5178 - val_accuracy: 0.7660\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3423 - accuracy: 0.8679 - val_loss: 0.5176 - val_accuracy: 0.7660\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2648 - accuracy: 0.9057 - val_loss: 0.5173 - val_accuracy: 0.7660\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 0s 735us/step - loss: 0.3692 - accuracy: 0.8491 - val_loss: 0.5169 - val_accuracy: 0.7660\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2704 - accuracy: 0.8679 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3061 - accuracy: 0.8679 - val_loss: 0.5167 - val_accuracy: 0.7660\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3240 - accuracy: 0.8868 - val_loss: 0.5165 - val_accuracy: 0.7660\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2499 - accuracy: 0.9057 - val_loss: 0.5164 - val_accuracy: 0.7660\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2686 - accuracy: 0.8679 - val_loss: 0.5166 - val_accuracy: 0.7660\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2390 - accuracy: 0.9057 - val_loss: 0.5166 - val_accuracy: 0.7660\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3122 - accuracy: 0.8868 - val_loss: 0.5170 - val_accuracy: 0.7660\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2873 - accuracy: 0.8491 - val_loss: 0.5175 - val_accuracy: 0.7660\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2390 - accuracy: 0.8679 - val_loss: 0.5178 - val_accuracy: 0.7660\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2950 - accuracy: 0.9057 - val_loss: 0.5177 - val_accuracy: 0.7660\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3972 - accuracy: 0.7736 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3067 - accuracy: 0.8491 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2495 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2531 - accuracy: 0.9057 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2916 - accuracy: 0.8679 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2456 - accuracy: 0.9245 - val_loss: 0.5179 - val_accuracy: 0.7660\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2883 - accuracy: 0.8868 - val_loss: 0.5180 - val_accuracy: 0.7660\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2434 - accuracy: 0.8679 - val_loss: 0.5178 - val_accuracy: 0.7660\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2707 - accuracy: 0.9057 - val_loss: 0.5176 - val_accuracy: 0.7660\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2497 - accuracy: 0.8868 - val_loss: 0.5184 - val_accuracy: 0.7660\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2297 - accuracy: 0.8868 - val_loss: 0.5182 - val_accuracy: 0.7660\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3328 - accuracy: 0.8868 - val_loss: 0.5181 - val_accuracy: 0.7660\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2618 - accuracy: 0.8868 - val_loss: 0.5181 - val_accuracy: 0.7660\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2173 - accuracy: 0.9057 - val_loss: 0.5183 - val_accuracy: 0.7660\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3049 - accuracy: 0.8679 - val_loss: 0.5187 - val_accuracy: 0.7660\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2684 - accuracy: 0.8679 - val_loss: 0.5188 - val_accuracy: 0.7660\n",
      "Epoch 491/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 775us/step - loss: 0.2732 - accuracy: 0.8679 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2727 - accuracy: 0.8868 - val_loss: 0.5192 - val_accuracy: 0.7660\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2756 - accuracy: 0.8868 - val_loss: 0.5192 - val_accuracy: 0.7660\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3002 - accuracy: 0.8868 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3524 - accuracy: 0.8113 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2715 - accuracy: 0.9057 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2548 - accuracy: 0.9057 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3053 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2333 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2214 - accuracy: 0.9245 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2678 - accuracy: 0.8679 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3017 - accuracy: 0.8679 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2378 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2583 - accuracy: 0.8868 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2984 - accuracy: 0.9057 - val_loss: 0.5187 - val_accuracy: 0.7660\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2991 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2459 - accuracy: 0.9434 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2991 - accuracy: 0.8868 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2703 - accuracy: 0.9057 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2470 - accuracy: 0.9057 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2971 - accuracy: 0.8679 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3202 - accuracy: 0.8491 - val_loss: 0.5211 - val_accuracy: 0.7660\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 0s 941us/step - loss: 0.3245 - accuracy: 0.9057 - val_loss: 0.5207 - val_accuracy: 0.7660\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2876 - accuracy: 0.8679 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2960 - accuracy: 0.8679 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2766 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3119 - accuracy: 0.8679 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3409 - accuracy: 0.8679 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2853 - accuracy: 0.8679 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3442 - accuracy: 0.8491 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2952 - accuracy: 0.8679 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2172 - accuracy: 0.9245 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3788 - accuracy: 0.8491 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2424 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3829 - accuracy: 0.8679 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4428 - accuracy: 0.8113 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3203 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2447 - accuracy: 0.8868 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2851 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3335 - accuracy: 0.8679 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2539 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2999 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3177 - accuracy: 0.8491 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2860 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3378 - accuracy: 0.8302 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2539 - accuracy: 0.8679 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2792 - accuracy: 0.8679 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.4062 - accuracy: 0.8302 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3274 - accuracy: 0.8491 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3010 - accuracy: 0.9057 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3055 - accuracy: 0.7925 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 0s 742us/step - loss: 0.2968 - accuracy: 0.8679 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3793 - accuracy: 0.8491 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2542 - accuracy: 0.9057 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2702 - accuracy: 0.8868 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2723 - accuracy: 0.8868 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 734us/step - loss: 0.3073 - accuracy: 0.8868 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2683 - accuracy: 0.9245 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2459 - accuracy: 0.9057 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2811 - accuracy: 0.8868 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2339 - accuracy: 0.9057 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2371 - accuracy: 0.9245 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2964 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1918 - accuracy: 0.9245 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 555/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2788 - accuracy: 0.8679 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3008 - accuracy: 0.8679 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2854 - accuracy: 0.9057 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2760 - accuracy: 0.8868 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2748 - accuracy: 0.9057 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2501 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2764 - accuracy: 0.8868 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3443 - accuracy: 0.8491 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2870 - accuracy: 0.9057 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2392 - accuracy: 0.8868 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3613 - accuracy: 0.8113 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3392 - accuracy: 0.8679 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2486 - accuracy: 0.9245 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3826 - accuracy: 0.8113 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2303 - accuracy: 0.9245 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2807 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3696 - accuracy: 0.8679 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2845 - accuracy: 0.8679 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2751 - accuracy: 0.9057 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2672 - accuracy: 0.8679 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2972 - accuracy: 0.8679 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2537 - accuracy: 0.9057 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2957 - accuracy: 0.8679 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2897 - accuracy: 0.8491 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2691 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 0s 781us/step - loss: 0.2902 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.4318 - accuracy: 0.8113 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2524 - accuracy: 0.9057 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2703 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2416 - accuracy: 0.9057 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3005 - accuracy: 0.8491 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3261 - accuracy: 0.8491 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2963 - accuracy: 0.9057 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3129 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2513 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3547 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2612 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2514 - accuracy: 0.9057 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2993 - accuracy: 0.8679 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2903 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2662 - accuracy: 0.8868 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2553 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2609 - accuracy: 0.9057 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2618 - accuracy: 0.8868 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2812 - accuracy: 0.8679 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2704 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3108 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 603/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 715us/step - loss: 0.2621 - accuracy: 0.9057 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3504 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3096 - accuracy: 0.8679 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2799 - accuracy: 0.8679 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2573 - accuracy: 0.8868 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3030 - accuracy: 0.9057 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2614 - accuracy: 0.8679 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2290 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3437 - accuracy: 0.8491 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2199 - accuracy: 0.9057 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2784 - accuracy: 0.8868 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3037 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2399 - accuracy: 0.8868 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2601 - accuracy: 0.8868 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3148 - accuracy: 0.8491 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2673 - accuracy: 0.9057 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2975 - accuracy: 0.8491 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2341 - accuracy: 0.8868 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2563 - accuracy: 0.9057 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3255 - accuracy: 0.9057 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3042 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2826 - accuracy: 0.9057 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2437 - accuracy: 0.8868 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2632 - accuracy: 0.8679 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2927 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3014 - accuracy: 0.8491 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2579 - accuracy: 0.9245 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2455 - accuracy: 0.9245 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2719 - accuracy: 0.8679 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2706 - accuracy: 0.8868 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2714 - accuracy: 0.9057 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2929 - accuracy: 0.8679 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2569 - accuracy: 0.8868 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2853 - accuracy: 0.9245 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3231 - accuracy: 0.8491 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2913 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3049 - accuracy: 0.8868 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2743 - accuracy: 0.9245 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2385 - accuracy: 0.8868 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2600 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2703 - accuracy: 0.9057 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2764 - accuracy: 0.8679 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3047 - accuracy: 0.8491 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2909 - accuracy: 0.8679 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3179 - accuracy: 0.8491 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2584 - accuracy: 0.9245 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3099 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2939 - accuracy: 0.8868 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3120 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2730 - accuracy: 0.9057 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2630 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2549 - accuracy: 0.8679 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2408 - accuracy: 0.9057 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2807 - accuracy: 0.8868 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2836 - accuracy: 0.8868 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2548 - accuracy: 0.9057 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 734us/step - loss: 0.2584 - accuracy: 0.9057 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2660 - accuracy: 0.9057 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3174 - accuracy: 0.8679 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2481 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2878 - accuracy: 0.8491 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2541 - accuracy: 0.9245 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 665/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3137 - accuracy: 0.8113 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2713 - accuracy: 0.8491 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2893 - accuracy: 0.8679 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3700 - accuracy: 0.8491 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3447 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2712 - accuracy: 0.8868 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2601 - accuracy: 0.9057 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2693 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2903 - accuracy: 0.9057 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2703 - accuracy: 0.8679 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3212 - accuracy: 0.9057 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2772 - accuracy: 0.8679 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3315 - accuracy: 0.8113 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2956 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2533 - accuracy: 0.8679 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2894 - accuracy: 0.8868 - val_loss: 0.5244 - val_accuracy: 0.7660\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3177 - accuracy: 0.8679 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3227 - accuracy: 0.8491 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3366 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.3577 - accuracy: 0.8491 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3134 - accuracy: 0.8491 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3823 - accuracy: 0.8679 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3830 - accuracy: 0.8113 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3156 - accuracy: 0.8491 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3015 - accuracy: 0.9057 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2621 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3136 - accuracy: 0.8113 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2984 - accuracy: 0.8868 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2644 - accuracy: 0.9057 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2731 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2725 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2319 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2774 - accuracy: 0.8679 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2365 - accuracy: 0.9057 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2725 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2904 - accuracy: 0.8491 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3178 - accuracy: 0.8679 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2817 - accuracy: 0.8868 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2829 - accuracy: 0.8679 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2664 - accuracy: 0.9057 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2658 - accuracy: 0.8302 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2565 - accuracy: 0.9057 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2521 - accuracy: 0.8868 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2996 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3767 - accuracy: 0.8679 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 0s 762us/step - loss: 0.3087 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2907 - accuracy: 0.8679 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2502 - accuracy: 0.8491 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2307 - accuracy: 0.9057 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3600 - accuracy: 0.8302 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 715/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 753us/step - loss: 0.2720 - accuracy: 0.9057 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2652 - accuracy: 0.8868 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3127 - accuracy: 0.8679 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2686 - accuracy: 0.8868 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2806 - accuracy: 0.9057 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3207 - accuracy: 0.8868 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2762 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3206 - accuracy: 0.8491 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2509 - accuracy: 0.9057 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2478 - accuracy: 0.9057 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2446 - accuracy: 0.9057 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3039 - accuracy: 0.8302 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3413 - accuracy: 0.8302 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2901 - accuracy: 0.8679 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3108 - accuracy: 0.8679 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2570 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2997 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2694 - accuracy: 0.9245 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2944 - accuracy: 0.8868 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3882 - accuracy: 0.8491 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2746 - accuracy: 0.8679 - val_loss: 0.5252 - val_accuracy: 0.7660\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3277 - accuracy: 0.8679 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2528 - accuracy: 0.9245 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2694 - accuracy: 0.9057 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2461 - accuracy: 0.9057 - val_loss: 0.5260 - val_accuracy: 0.7660\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4157 - accuracy: 0.8491 - val_loss: 0.5263 - val_accuracy: 0.7660\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3579 - accuracy: 0.8302 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3020 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2680 - accuracy: 0.8868 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2742 - accuracy: 0.8679 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2849 - accuracy: 0.8868 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2926 - accuracy: 0.8679 - val_loss: 0.5254 - val_accuracy: 0.7660\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3816 - accuracy: 0.8113 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2726 - accuracy: 0.8868 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2482 - accuracy: 0.8868 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2294 - accuracy: 0.9245 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.3140 - accuracy: 0.9057 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2737 - accuracy: 0.9057 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2941 - accuracy: 0.8491 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2895 - accuracy: 0.8491 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3031 - accuracy: 0.8679 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2950 - accuracy: 0.8679 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5255 - val_accuracy: 0.7660\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2380 - accuracy: 0.9057 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3380 - accuracy: 0.8679 - val_loss: 0.5264 - val_accuracy: 0.7660\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3523 - accuracy: 0.8868 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2554 - accuracy: 0.8679 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.4186 - accuracy: 0.8491 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2129 - accuracy: 0.8868 - val_loss: 0.5258 - val_accuracy: 0.7660\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2956 - accuracy: 0.9057 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2247 - accuracy: 0.9245 - val_loss: 0.5257 - val_accuracy: 0.7660\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2899 - accuracy: 0.8868 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2882 - accuracy: 0.8491 - val_loss: 0.5250 - val_accuracy: 0.7660\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3216 - accuracy: 0.9057 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2135 - accuracy: 0.8868 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2586 - accuracy: 0.9057 - val_loss: 0.5253 - val_accuracy: 0.7660\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 677us/step - loss: 0.2630 - accuracy: 0.8679 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3237 - accuracy: 0.8868 - val_loss: 0.5251 - val_accuracy: 0.7660\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2798 - accuracy: 0.9057 - val_loss: 0.5249 - val_accuracy: 0.7660\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2493 - accuracy: 0.8868 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 775/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2448 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3208 - accuracy: 0.8868 - val_loss: 0.5244 - val_accuracy: 0.7660\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2989 - accuracy: 0.8491 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2636 - accuracy: 0.8679 - val_loss: 0.5247 - val_accuracy: 0.7660\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2289 - accuracy: 0.9057 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2852 - accuracy: 0.8679 - val_loss: 0.5242 - val_accuracy: 0.7660\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2577 - accuracy: 0.9057 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2310 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2475 - accuracy: 0.8491 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.5244 - val_accuracy: 0.7660\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2766 - accuracy: 0.8491 - val_loss: 0.5248 - val_accuracy: 0.7660\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2821 - accuracy: 0.8868 - val_loss: 0.5246 - val_accuracy: 0.7660\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.3314 - accuracy: 0.8491 - val_loss: 0.5245 - val_accuracy: 0.7660\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3133 - accuracy: 0.8679 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2775 - accuracy: 0.9245 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3067 - accuracy: 0.8679 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2520 - accuracy: 0.9057 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2696 - accuracy: 0.8679 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3049 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2800 - accuracy: 0.8868 - val_loss: 0.5244 - val_accuracy: 0.7660\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3048 - accuracy: 0.8491 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3006 - accuracy: 0.8491 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2548 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2911 - accuracy: 0.9057 - val_loss: 0.5239 - val_accuracy: 0.7660\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2355 - accuracy: 0.9245 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2420 - accuracy: 0.8868 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2218 - accuracy: 0.9057 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2428 - accuracy: 0.9434 - val_loss: 0.5238 - val_accuracy: 0.7660\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3227 - accuracy: 0.8491 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3205 - accuracy: 0.9245 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2793 - accuracy: 0.9057 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2861 - accuracy: 0.9057 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3179 - accuracy: 0.8868 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2833 - accuracy: 0.9057 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2969 - accuracy: 0.8679 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 0s 771us/step - loss: 0.2299 - accuracy: 0.9057 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3254 - accuracy: 0.8302 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2645 - accuracy: 0.8868 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2892 - accuracy: 0.8868 - val_loss: 0.5226 - val_accuracy: 0.7660\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.4209 - accuracy: 0.8113 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2657 - accuracy: 0.9434 - val_loss: 0.5223 - val_accuracy: 0.7660\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3128 - accuracy: 0.8491 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2930 - accuracy: 0.8868 - val_loss: 0.5211 - val_accuracy: 0.7660\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2845 - accuracy: 0.8679 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3276 - accuracy: 0.8679 - val_loss: 0.5218 - val_accuracy: 0.7660\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2644 - accuracy: 0.9057 - val_loss: 0.5217 - val_accuracy: 0.7660\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2605 - accuracy: 0.8868 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3000 - accuracy: 0.8868 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3038 - accuracy: 0.8679 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 0s 725us/step - loss: 0.3163 - accuracy: 0.8113 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 0s 695us/step - loss: 0.2625 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 753us/step - loss: 0.2775 - accuracy: 0.8679 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3162 - accuracy: 0.8679 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3415 - accuracy: 0.8302 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3473 - accuracy: 0.8679 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3010 - accuracy: 0.8868 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2355 - accuracy: 0.9245 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2716 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3652 - accuracy: 0.8302 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2665 - accuracy: 0.8868 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2379 - accuracy: 0.9057 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2599 - accuracy: 0.8868 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2785 - accuracy: 0.9057 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3309 - accuracy: 0.8679 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2700 - accuracy: 0.8868 - val_loss: 0.5211 - val_accuracy: 0.7660\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2277 - accuracy: 0.8679 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3427 - accuracy: 0.8302 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3659 - accuracy: 0.8113 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2415 - accuracy: 0.9057 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2590 - accuracy: 0.9245 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.2955 - accuracy: 0.8679 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3294 - accuracy: 0.8868 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2481 - accuracy: 0.9057 - val_loss: 0.5216 - val_accuracy: 0.7660\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2537 - accuracy: 0.9245 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2428 - accuracy: 0.8868 - val_loss: 0.5207 - val_accuracy: 0.7660\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2596 - accuracy: 0.9057 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2884 - accuracy: 0.8868 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2703 - accuracy: 0.9057 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3187 - accuracy: 0.8679 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2691 - accuracy: 0.9057 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2934 - accuracy: 0.9057 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2784 - accuracy: 0.8679 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2761 - accuracy: 0.8491 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2922 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2752 - accuracy: 0.8868 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3377 - accuracy: 0.8679 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2802 - accuracy: 0.8868 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2929 - accuracy: 0.8679 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3458 - accuracy: 0.8679 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 0s 683us/step - loss: 0.2774 - accuracy: 0.9057 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2574 - accuracy: 0.9057 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3495 - accuracy: 0.8491 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2648 - accuracy: 0.8868 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2682 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2895 - accuracy: 0.9245 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2708 - accuracy: 0.8679 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3380 - accuracy: 0.8302 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.1702 - accuracy: 0.9057 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2452 - accuracy: 0.9245 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2841 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3110 - accuracy: 0.8679 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 0s 849us/step - loss: 0.2951 - accuracy: 0.9057 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2354 - accuracy: 0.8868 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2757 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.1903 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2709 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2512 - accuracy: 0.9057 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 696us/step - loss: 0.3263 - accuracy: 0.8491 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2882 - accuracy: 0.8491 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 885/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2849 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2850 - accuracy: 0.8868 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2614 - accuracy: 0.9245 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2995 - accuracy: 0.8868 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.4074 - accuracy: 0.8491 - val_loss: 0.5204 - val_accuracy: 0.7660\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2418 - accuracy: 0.9434 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3054 - accuracy: 0.8491 - val_loss: 0.5204 - val_accuracy: 0.7660\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3192 - accuracy: 0.8868 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2485 - accuracy: 0.9057 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2614 - accuracy: 0.9057 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3936 - accuracy: 0.8491 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3100 - accuracy: 0.8679 - val_loss: 0.5196 - val_accuracy: 0.7660\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3158 - accuracy: 0.8302 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2851 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2572 - accuracy: 0.8491 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2764 - accuracy: 0.8868 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 0s 791us/step - loss: 0.3665 - accuracy: 0.8302 - val_loss: 0.5195 - val_accuracy: 0.7660\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2930 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2826 - accuracy: 0.8679 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3031 - accuracy: 0.8868 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2811 - accuracy: 0.8679 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2274 - accuracy: 0.9057 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2872 - accuracy: 0.8868 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2730 - accuracy: 0.8679 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2850 - accuracy: 0.8868 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2857 - accuracy: 0.8868 - val_loss: 0.5214 - val_accuracy: 0.7660\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2712 - accuracy: 0.9057 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.3193 - accuracy: 0.8679 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3655 - accuracy: 0.8113 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3452 - accuracy: 0.8302 - val_loss: 0.5210 - val_accuracy: 0.7660\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 0s 736us/step - loss: 0.2776 - accuracy: 0.8868 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2756 - accuracy: 0.8679 - val_loss: 0.5204 - val_accuracy: 0.7660\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.2984 - accuracy: 0.8491 - val_loss: 0.5204 - val_accuracy: 0.7660\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2533 - accuracy: 0.8868 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.1986 - accuracy: 0.9245 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2795 - accuracy: 0.9057 - val_loss: 0.5205 - val_accuracy: 0.7660\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2809 - accuracy: 0.8868 - val_loss: 0.5209 - val_accuracy: 0.7660\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 0s 678us/step - loss: 0.2811 - accuracy: 0.8868 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2905 - accuracy: 0.9057 - val_loss: 0.5208 - val_accuracy: 0.7660\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3167 - accuracy: 0.8302 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2949 - accuracy: 0.8868 - val_loss: 0.5202 - val_accuracy: 0.7660\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2431 - accuracy: 0.8868 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 0s 757us/step - loss: 0.2746 - accuracy: 0.8868 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2580 - accuracy: 0.8679 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3198 - accuracy: 0.8868 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2732 - accuracy: 0.9057 - val_loss: 0.5200 - val_accuracy: 0.7660\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3529 - accuracy: 0.8491 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2958 - accuracy: 0.9057 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3045 - accuracy: 0.8679 - val_loss: 0.5197 - val_accuracy: 0.7660\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2783 - accuracy: 0.8868 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2711 - accuracy: 0.9057 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.2504 - accuracy: 0.8679 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 939/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 734us/step - loss: 0.2640 - accuracy: 0.9057 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.3591 - accuracy: 0.8491 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2139 - accuracy: 0.9245 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3206 - accuracy: 0.8679 - val_loss: 0.5188 - val_accuracy: 0.7660\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2816 - accuracy: 0.9245 - val_loss: 0.5187 - val_accuracy: 0.7660\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2728 - accuracy: 0.9057 - val_loss: 0.5189 - val_accuracy: 0.7660\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 0s 866us/step - loss: 0.2247 - accuracy: 0.9057 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2395 - accuracy: 0.9057 - val_loss: 0.5198 - val_accuracy: 0.7660\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3791 - accuracy: 0.8491 - val_loss: 0.5187 - val_accuracy: 0.7660\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2944 - accuracy: 0.8868 - val_loss: 0.5190 - val_accuracy: 0.7660\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2883 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2772 - accuracy: 0.9057 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2574 - accuracy: 0.8868 - val_loss: 0.5194 - val_accuracy: 0.7660\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2975 - accuracy: 0.8868 - val_loss: 0.5188 - val_accuracy: 0.7660\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2804 - accuracy: 0.8868 - val_loss: 0.5192 - val_accuracy: 0.7660\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2698 - accuracy: 0.8868 - val_loss: 0.5191 - val_accuracy: 0.7660\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2482 - accuracy: 0.9057 - val_loss: 0.5193 - val_accuracy: 0.7660\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2448 - accuracy: 0.8868 - val_loss: 0.5199 - val_accuracy: 0.7660\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2023 - accuracy: 0.8868 - val_loss: 0.5203 - val_accuracy: 0.7660\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2585 - accuracy: 0.9057 - val_loss: 0.5201 - val_accuracy: 0.7660\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2398 - accuracy: 0.9057 - val_loss: 0.5206 - val_accuracy: 0.7660\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2507 - accuracy: 0.9057 - val_loss: 0.5211 - val_accuracy: 0.7660\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2648 - accuracy: 0.8679 - val_loss: 0.5213 - val_accuracy: 0.7660\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2774 - accuracy: 0.9057 - val_loss: 0.5212 - val_accuracy: 0.7660\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3828 - accuracy: 0.8113 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2645 - accuracy: 0.8679 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3047 - accuracy: 0.8868 - val_loss: 0.5220 - val_accuracy: 0.7660\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2876 - accuracy: 0.8302 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3021 - accuracy: 0.8113 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.2620 - accuracy: 0.8868 - val_loss: 0.5227 - val_accuracy: 0.7660\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3559 - accuracy: 0.8302 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3204 - accuracy: 0.8491 - val_loss: 0.5229 - val_accuracy: 0.7660\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.3094 - accuracy: 0.8679 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2701 - accuracy: 0.8868 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3301 - accuracy: 0.8679 - val_loss: 0.5240 - val_accuracy: 0.7660\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3084 - accuracy: 0.8491 - val_loss: 0.5237 - val_accuracy: 0.7660\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2696 - accuracy: 0.9434 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3053 - accuracy: 0.8868 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.3212 - accuracy: 0.8679 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2542 - accuracy: 0.8868 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2855 - accuracy: 0.8679 - val_loss: 0.5243 - val_accuracy: 0.7660\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2588 - accuracy: 0.8868 - val_loss: 0.5241 - val_accuracy: 0.7660\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2476 - accuracy: 0.9057 - val_loss: 0.5236 - val_accuracy: 0.7660\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2900 - accuracy: 0.8491 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2218 - accuracy: 0.9245 - val_loss: 0.5235 - val_accuracy: 0.7660\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2567 - accuracy: 0.9057 - val_loss: 0.5233 - val_accuracy: 0.7660\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2750 - accuracy: 0.8868 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2664 - accuracy: 0.9245 - val_loss: 0.5231 - val_accuracy: 0.7660\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.3172 - accuracy: 0.8491 - val_loss: 0.5232 - val_accuracy: 0.7660\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.3159 - accuracy: 0.8679 - val_loss: 0.5230 - val_accuracy: 0.7660\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.3608 - accuracy: 0.8302 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2675 - accuracy: 0.8868 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.2732 - accuracy: 0.9245 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.2493 - accuracy: 0.8679 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.2587 - accuracy: 0.9057 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.2638 - accuracy: 0.9057 - val_loss: 0.5219 - val_accuracy: 0.7660\n",
      "Epoch 995/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 809us/step - loss: 0.3090 - accuracy: 0.9245 - val_loss: 0.5221 - val_accuracy: 0.7660\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.2906 - accuracy: 0.9057 - val_loss: 0.5215 - val_accuracy: 0.7660\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 0s 828us/step - loss: 0.3335 - accuracy: 0.8679 - val_loss: 0.5224 - val_accuracy: 0.7660\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.2961 - accuracy: 0.8679 - val_loss: 0.5222 - val_accuracy: 0.7660\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 0s 772us/step - loss: 0.3461 - accuracy: 0.8679 - val_loss: 0.5228 - val_accuracy: 0.7660\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.2820 - accuracy: 0.8679 - val_loss: 0.5227 - val_accuracy: 0.7660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27271242ef0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "history_Adam_1_l = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, use_bias=False,input_shape=(X_train.shape[1],)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(500, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(200, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), epochs=1000, callbacks=[history_Adam_1_l, lrate])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history_Adam.history['loss'], label = \"tarina\")\n",
    "# plt.plot(history_Adam.history['val_loss'], label = \"test \")\n",
    "\n",
    "# plt.plot(history_Adam_1.history['loss'], label = \"tarina BN\")\n",
    "# plt.plot(history_Adam_1.history['val_loss'], label = \"test BN\")\n",
    "\n",
    "plt.plot(history_Adam_1_l.history['loss'], label = \"tarina BN\")\n",
    "plt.plot(history_Adam_1_l.history['val_loss'], label = \"test BN\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
